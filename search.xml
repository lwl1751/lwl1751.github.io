<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>how to build up a blog</title>
    <url>/2024/05/12/how-to-build-up-a-blog/</url>
    <content><![CDATA[<span id="more"></span>
<p>登录root用户</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">su root</span><br></pre></td></tr></table></figure>
<p>切换路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd /Users/lwl/Blog</span><br></pre></td></tr></table></figure>
<p>博客文章发布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;title&quot;</span> <span class="comment"># 新建文章</span></span><br><span class="line"><span class="comment"># 编辑对应的markdown文件</span></span><br><span class="line">hexo g <span class="comment"># 渲染md文件为博客页面</span></span><br><span class="line">hexo s <span class="comment"># 执行后打开http://localhost:4000/预览</span></span><br><span class="line">hexo d <span class="comment"># 预览并编辑无误后再部署，也可以直接部署</span></span><br></pre></td></tr></table></figure>
<p>有时部署会失败，此时尝试下面命令清除缓存后再执行部署命令。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hexo clean </span><br></pre></td></tr></table></figure>
<p>更换端口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">hexo s -p <span class="number">8888</span> <span class="comment"># 示例</span></span><br></pre></td></tr></table></figure>
<p>释放端口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lsof -i :端口号 <span class="comment"># 查找占用指定端口的进程ID（PID）</span></span><br><span class="line">kill -<span class="number">9</span> 进程ID</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>基于策略梯度的强化学习</title>
    <url>/2024/05/15/%E5%9F%BA%E4%BA%8E%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>强化学习可分为两大类：</p>
<ul>
<li>
<p><strong>value-based method</strong>(DP,MC,TD)</p>
<p>通过价值函数求解最优策略，求解出来的策略是确定性的，虽然可以通过$\epsilon$-贪心策略来获取一定的随机性。要求动作空间离散。</p>
</li>
<li>
<p><strong>policy-based method</strong></p>
<p>适用场景：随机策略；动作空间连续。</p>
<p>优点：具有更好的收敛性质。</p>
<p>缺点：通常会收敛到局部最优而非全局最优；评估一个策略通常不够高效并且具有较大的方差。</p>
</li>
</ul>
<span id="more"></span>
<h2 id="1-基本原理">1.基本原理</h2>
<p>由于策略实际上是一个概率分布，可以将策略参数化 $\pi(a|s,\theta)$ ，其中$\theta$ 是策略的参数。通过这种方式，可以将可见的已知状态泛化到未知的状态上。</p>
<h3 id="1-1-策略目标函数">1.1 策略目标函数</h3>
<p>在片段式的环境中，使用每个经历片段(episode)的平均总回报。在连续性的环境中，使用每一步的平均奖励。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%AD%96%E7%95%A5%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B01.png" alt="图1"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%AD%96%E7%95%A5%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B02.png" alt="图2"></p>
<p>希望能够找到最大化$J(\theta)$的$\theta$，属于最优化问题，求解方法如下：</p>
<ul>
<li>不使用梯度的方法(Hill climbing, Simplex, 模拟退火, 遗传算法)</li>
<li>使用梯度的方法更高效(梯度下降, 共轭梯度, 拟牛顿法)</li>
</ul>
<h3 id="1-2-策略函数">1.2 策略函数</h3>
<ul>
<li>softmax策略，离散型动作空间</li>
<li>高斯函数策略，连续型动作空间</li>
<li>线性函数策略，连续型动作空间，表示给定状态下确定性的动作，$a=\pi(s,\theta)$</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/score%E5%87%BD%E6%95%B0.png" alt="图3"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/softmax%E7%AD%96%E7%95%A52.png" alt="图4"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/softmax%E7%AD%96%E7%95%A5.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E9%AB%98%E6%96%AF%E7%AD%96%E7%95%A5.png" alt="图6"></p>
<h3 id="1-3-单步马尔可夫决策过程">1.3 单步马尔可夫决策过程</h3>
<p>从一个分布d(s)中采样得到一个状态s，从s开始，按照策略𝜋采取一个行为a，得到即时奖励$r=R_{s,a}$。由于是单步过程，目标函数为<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%95%E6%AD%A5%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E5%85%AC%E5%BC%8F.png" alt="图7"></p>
<h2 id="2-策略梯度定理">2.策略梯度定理</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%AD%96%E7%95%A5%E6%8E%A8%E7%90%861.png" alt="图8"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%AD%96%E7%95%A5%E6%8E%A8%E7%90%862.png" alt="图9"></p>
<p>由于状态转移函数的存在，虽然训练用的轨迹都是由同一个策略生成的，但其两两差异仍十分显著，并且显然轨迹越长差异越大，决策中每一个微小的差异累积起来都会导致最后结果的极大差异。也就是数据有着较大的方差，这会导致使用均值计算期望的效果变差，并使算法难以收敛。</p>
<p><strong>改进方法：使用时序因果关系；加入基线。</strong></p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%97%B6%E9%97%B4%E8%BF%9E%E7%BB%AD%E6%80%A71.png" alt="图10"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%97%B6%E9%97%B4%E8%BF%9E%E7%BB%AD%E6%80%A72.png" alt="图11"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8A%A0%E5%85%A5%E5%9F%BA%E7%BA%BF1.png" alt="图12"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8A%A0%E5%85%A5%E5%9F%BA%E7%BA%BF2.png" alt="图13"></p>
<h2 id="3-蒙特卡洛策略梯度-REINFORCE">3.蒙特卡洛策略梯度(REINFORCE)</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/REINFORCE-1.png" alt="图14"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/REINFORCE2.png" alt="图15"></p>
<h2 id="4-Actor-Critic-算法">4. Actor-Critic 算法</h2>
<p><strong>actor --&gt; policy network</strong>，决定采取哪个动作</p>
<ul>
<li>$\pi(a|s;\theta)$</li>
<li>input: state s</li>
<li>output: probability distribution over the actions</li>
<li>训练目标： 增加状态值函数 state-value</li>
</ul>
<p>c<strong>ritic --&gt; value network</strong>，只负责评估动作的好坏</p>
<ul>
<li>$q(s,a;w)$</li>
<li>input: state s and action a</li>
<li>output: approximate action-value(scalar)</li>
<li>训练目标： 使价值评估的更精准，接近于实际环境的return</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/A3C-1.png" alt="图16"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/A3C-2.png" alt="图17"></p>
<p><strong>参考资料</strong>：</p>
<p>中国科学院大学林姝老师 强化学习课程课件</p>
<p>深度强化学习：基础、研究与应用 (董豪 等)</p>
<p><a href="https://www.bilibili.com/video/BV16Y411f7Hp/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d">https://www.bilibili.com/video/BV16Y411f7Hp/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
<p><a href="https://mp.weixin.qq.com/s/y1Rj3fIaXkNjEyakCqRSIg">https://mp.weixin.qq.com/s/y1Rj3fIaXkNjEyakCqRSIg</a></p>
<p>Reinforcement Learning An Introduction (Adaptive Computation and Machine Learning series) (Sutton, Richard S., Barto, Andrew G.)</p>
<p><a href="https://www.bilibili.com/video/BV1Sq4y1q7sw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d">https://www.bilibili.com/video/BV1Sq4y1q7sw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态知识图谱应用</title>
    <url>/2024/05/15/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<p>相比于单模态知识图谱，多模态知识图谱能够综合多种类型的数据，从而可以让智能体更深入的感知和理解真实的数据场景，因而多模态知识图谱在各个领域都有广泛的应用。如图像检索、模型推理与生成、模型预训练等。以电子商务为例，通过多模态产品图谱，可以对产品进行更细致的表示，再通过预训练，可以增强大型模型对电子商务领域的多模态知识理解，从而推动电子商务平台的发展。</p>
<span id="more"></span>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%BA%94%E7%94%A81.png" alt="图1"></p>
<p>AliMe MKG是阿里提出的一种面向直播的知识图谱，与传统的知识图谱不同，它的目标是向顾客种草某一产品，而非解决顾客的问题。因此，它需要构建逻辑思维链，引导用户需求。例如，在该左图1的知识图谱示例中，“熬夜&quot;导致&quot;皮肤暗沉&quot;问题，这就需要&quot;皮肤白皙”，而含有&quot;甘草酸二钾&quot;成分的&quot;面膜&quot;产品适合相应的用户。</p>
<p>在电商直播领域，这种知识图谱有两种应用：智能辅播和虚拟主播。智能辅播是在真人直播间构造了一个智能助理机器人，来协助主播去做商品介绍。比如说用户问的是口红，直播间内有多个口红，智能辅播就会将相关的信息展示出来给用户进行浏览，当用户点击确认，选择一个感兴趣的口红之后，辅播就会从知识图谱中抽取相应信息，以商品卡片信息的方式让用户和图片进行交互。除此之外，智能辅播还可以回答用户丰富的产品相关问题。比如用户问尺码的时候，辅播可以去推出文本介绍和对应的尺码图，用文本及图片来回答用户的咨询。</p>
<p>虚拟主播则是一个智能的直播间虚拟人，通过自动生成图文剧本介绍商品，生成具有吸引力和认知的知识型短视频，从而可以影响客户的购买决策。因此，多模态的知识图谱可以促进电商的发展。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%BA%94%E7%94%A82.png" alt="图2"></p>
<p>另一个是医疗诊断的案例，这是一个基于多模态知识图谱的医疗健康问答系统示例。它首先利用多种方法获取用户提交数据的关键信息，并确定用户查询的主题意图，建立用户的知识需求模型。在知识匹配阶段，我们计算用户需求与医疗健康知识的相关度，并消除可能的歧义，最终向用户提供匹配度高的医疗健康知识。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%BA%94%E7%94%A83.png" alt="图3"></p>
<p><strong>参考资料</strong>:</p>
<p>Chen Z, Zhang Y, Fang Y, et al. Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey[J]. arXiv preprint arXiv:2402.05391, 2024.</p>
<p>Xu G, Chen H, Li F L, et al. Alime mkg: A multi-modal knowledge graph for live-streaming e-commerce[C]//Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management. 2021: 4808-4812.</p>
<p><a href="https://mp.weixin.qq.com/s/rW9ezfkAgOHAsICYuiPq6A">https://mp.weixin.qq.com/s/rW9ezfkAgOHAsICYuiPq6A</a></p>
<p><a href="https://mp.weixin.qq.com/s/bTqr5EEQD5_rModP8NR99g">https://mp.weixin.qq.com/s/bTqr5EEQD5_rModP8NR99g</a></p>
<p>韩普,叶东宇,陈文祺,等.面向多模态医疗健康数据的知识组织模式研究[J].现代情报,2023,43(10):27-34+151.</p>
]]></content>
      <tags>
        <tag>多模态</tag>
        <tag>知识图谱</tag>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型知识分析、萃取与增强</title>
    <url>/2024/05/25/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9F%A5%E8%AF%86%E5%88%86%E6%9E%90%E3%80%81%E8%90%83%E5%8F%96%E4%B8%8E%E5%A2%9E%E5%BC%BA/</url>
    <content><![CDATA[<pre><code>大模型中蕴含着大量的知识，但是知识的类型、数量和质量并不可控。

知识分析实验表明，大模型自发学到了一些世界知识、常识知识，这些知识隐式地存储于模型参数中。

课程考试复习使用。</code></pre>
<span id="more"></span>
<h2 id="大模型的知识分析">1.大模型的知识分析</h2>
<h3 id="知识探测">1.1 知识探测</h3>
<ul>
<li><p><strong>知识探测</strong>：探测预训练语言模型掌握的知识。</p></li>
<li><p><strong>实现方式</strong>：将三元组或问答对形式的世界知识转化为自然语言填空的形式，从而判断语言模型掌握知识的准确性。</p></li>
<li><p><strong>预训练模型知识探测的良好性能主要来源于</strong>：</p>
<ul>
<li>提示语偏差，预测结果会受到提示词的影响，如 was born in [Mask] ,
模型会猜测下一个词应该为地名。</li>
<li>类别指导，类似于few shot learning，模型已经见过类似的问题。</li>
<li>答案泄漏，基于上下文的推理。</li>
</ul></li>
</ul>
<h3 id="知识定位">1.2 知识定位</h3>
<ul>
<li><strong>知识定位</strong>：分析预训练语言模型中的知识存储机制，可分为层粒度与神经元粒度。</li>
<li>大量事实知识存储在<strong>FNN模块</strong>中。</li>
</ul>
<h3 id="知识学习机理分析">1.3 知识学习机理分析</h3>
<p>分析影响预训练语言模型学习效果的因素。</p>
<ul>
<li><strong>长尾知识</strong>：信息出现次数非常少，甚至只出现了一次。LLM对长尾知识的掌握并不充分，回答问题的准确度就会降低，可以通过扩大模型规模(scaling
low)、检索增强来解决该问题。</li>
<li><strong>共现频率</strong>：LLM更加倾向于预测共现频率更高的答案。如，对于问题“加拿大的首都是？”，在预训练语料中，（加拿大，多伦多）共同出现的频率要大于（加拿大，渥太华）出现的频率，于是模型倾向于输出共现频率更高的“多伦多”，而不是正确答案“渥太华”。</li>
<li><strong>逆转诅咒</strong>，模型很难逆转思考，如 A is B 不能推出 B is
A.</li>
</ul>
<h2 id="大模型的知识萃取">2.大模型的知识萃取</h2>
<p>知识萃取是指利用特定方式诱导大模型，从中萃取出有用的显式符号化知识。</p>
<h2 id="大模型的知识增强">3.大模型的知识增强</h2>
<ul>
<li>幻觉可以分为事实性现象（生成的内容不忠于既定的事实知识）和忠实性幻觉（生成的内容前后冲突）。</li>
<li><strong>幻觉消除</strong>：清洗训练数据，解码方式改进，指令数据优化，外部知识增强。</li>
<li><strong>知识增强</strong>：RAG，Fine-tuning。</li>
<li>关于幻觉的知识，可以查看文献综述：《Survey on Factuality in Large
Language Models: Knowledge, Retrieval and Domain-Specificity》</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识增强_1.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h3 id="rag">3.1 RAG</h3>
<ul>
<li><strong>检索知识源</strong>
<ul>
<li>文档：检索粒度粗，知识覆盖度高，存在冗余信息。</li>
<li>知识图谱：提供丰富的结构化信息，受限于图谱的覆盖度。</li>
</ul></li>
<li><strong>检索方式</strong>
<ul>
<li>稀疏检索：简单词汇匹配，缺少上下文理解能力（BM25）</li>
<li>稠密检索：将问题和文档编码为稠密向量，计算点积作为相似度（DPR）</li>
<li>生成检索：直接使用大模型为问题生成相关文档，而不需要检索库</li>
</ul></li>
<li><strong>检索时间</strong>
<ul>
<li>推理前检索一次：效率高，但相关度低</li>
<li>推理过程中自适应地检索：平衡知识和效率，但是难以判断模型何时需要知识</li>
<li>推理过程中每隔N个token检索一次：效率低，信息量大</li>
</ul></li>
<li><strong>利用检索得到的知识进行推理</strong>
<ul>
<li>输入增强：使用简单，受限于上下文长度</li>
<li>中间增强：需要重新训练模型，支持处理更多文档</li>
<li>输出增强：对输出进行后修改，需要两次推理模型：第一次，模型直接输出答案。第二次，根据问题和答案，进行检索，对输出答案进行修改。</li>
</ul></li>
<li><strong>知识拉锯战</strong>：由于错误信息，观点不同，以及知识进化的本质，知识冲突问题广泛存在于检索增强语言模型中。</li>
<li><strong>知识冲突形式</strong>：
<ul>
<li>模型内部参数化知识和外部非参数化知识之间存在冲突。其中，使用外部知识回答的模型作为专家模型，依靠内部知识回答的模型作为业余模型。</li>
<li>非参数化知识中真实、虚假以及无关证据之间存在冲突。其中，通过指令微调，使用真实证据回答的模型作为专家模型，使用虚假证据回答的模型作为业余模型。</li>
</ul></li>
<li>Dunning-Kruger现象：人对于某些欠缺的能力反而会过度自信，对模型也同样适用。</li>
</ul>
<h2 id="大模型的工具增强">4.大模型的工具增强</h2>
<ul>
<li><strong>工具增强</strong>：让模型学会使用外部工具，以补充模型相关知识。</li>
<li>相关论文：
<ul>
<li>Timo Schick, Toolformer: Language Models Can Teach Themselves to Use
Tools, NeurIPS 2023。</li>
<li>Yujia Qin, ToolLLM: Facilitating Large Language Models to Master
16000+ Real-world APIs, ICLR2024。</li>
</ul></li>
</ul>
<h2 id="参考资料">5.参考资料</h2>
<p>中国科学院大学赵军老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习基础知识</title>
    <url>/2024/05/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p><strong>知识点：马尔科夫决策过程，动态规划。</strong></p>
<hr>
<span id="more"></span>
<h2 id="马尔科夫决策过程">马尔科夫决策过程</h2>
<p><strong><span style="color:purple;">马尔科夫过程</span></strong>: 一个具备马尔科夫性质的离散随机过程。</p>
<p><strong><span style="color:purple;">马尔科夫性</span></strong>: 下一时刻的状态只与当前状态有关。即$P[S_{t+1}|S_{1},…,S_{t}]=P[S_{t+1}|S_{t}]$</p>
<p><strong><span style="color:purple;">马尔科夫奖励函数</span></strong>: 把马尔科夫过程从 &lt;S, P&gt; 拓展到 &lt;S, P, R, γ&gt;。其中P 为状态转移矩阵，R 和 γ 分别表示奖励函数和奖励折扣因子。折扣因子越大，代表了智能体对长期性能指标考虑的程度越高（远视）；折扣因子越小，代表了智能体对长期性能指标考虑的程度越低（近视）。</p>
<p><strong><span style="color:purple;">回报</span></strong>: 回报是一个轨迹的累积奖励，$G_{t} = R_{t+1} + \gamma R_{t+2} = \sum_{k=0}^{\infty } \gamma ^{k}R_{t+k+1}$</p>
<p><strong><span style="color:purple;">价值函数</span></strong>：状态s的期望回报，$V(s) = E[G_{t}|S_{t}=s]$。</p>
<p><strong><span style="color:purple;">马尔科夫决策过程</span></strong>: 马尔可夫奖励过程的立即奖励只取决于状态(奖励值在节点上)，而马尔可夫决策过程的立即奖励与状态和动作都有关。即把马尔科夫过程从 &lt;S, P, R, γ&gt; 拓展到 &lt;S, A, P, R, γ&gt;。A是有限动作的集合。</p>
<p><strong><span style="color:purple;">动作价值函数</span></strong>: 依赖于状态和刚刚执行的动作，是基于状态和动作的期望回报。$Q(s,a) = E[G_{t}|S_{t}=s, A_{t}=a]$。易知$V(s)=E_{a}[Q(s,a)]$。</p>
<p><strong><span style="color:purple;">策略</span></strong>: 状态到行为的映射。</p>
<blockquote>
<p>对于任何马尔科夫决策过程：</p>
<ul>
<li>总是存在一个最优策略$\pi^*$，比任何其他策略更好或至少相等。</li>
<li>所有的最优策略有相同且最优的价值。</li>
<li>所有的最优策略具有相同且最优的动作价值。</li>
</ul>
</blockquote>
<p><strong><span style="color:purple;">贝尔曼方程</span></strong>：用于计算给定策略 π 时价值函数在策略指引下所采轨迹上的期望。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%88%AA%E5%B1%8F2024-05-16%2013.18.14.png" alt="图1"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%88%AA%E5%B1%8F2024-05-16%2013.18.34.png" alt="图2"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%88%AA%E5%B1%8F2024-05-16%2013.27.29.png" alt="图3"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%88%AA%E5%B1%8F2024-05-16%2013.27.43.png" alt="图4"></p>
<p><strong><span style="color:purple;">最优价值函数</span></strong>:</p>
<p>即使是在相同的状态和动作集合上，不同的策略也将会带来不同的价值函数。定义最优价值函数为</p>
<p>$$v_*(s) = \max_{π} v_π(s), ∀s ∈ S$$</p>
<p>最优动作价值函数：</p>
<p>$$q_*(s,a) = \max_{\pi} q_π(s,a), ∀s ∈ S, a ∈ A$$</p>
<p>则</p>
<p>$$v*(s) = \max_{a\sim \mathbf{A}} q_*(s, a)$$</p>
<p>$$q_<em>(s, a) = E[R_t + γv_</em>(S_{t+1}) | S_t = s, A_t = a]$$</p>
<p><strong><span style="color:purple;">逆矩阵法求解贝尔曼方程</span></strong>：</p>
<p>$$\mathbf{v}  = \mathbf{r} + γP\mathbf{v} $$</p>
<p>其中 <strong>v</strong> 和 <strong>r</strong> 矢量，P是状态转移概率矩阵。求解如下：</p>
<p>$$\mathbf{v} = (I − γP )^{-1}\mathbf{r}$$</p>
<p>复杂度为$O(n^{3})$，考虑其他方法进行求解，如<span style="color:red;">动态规划、蒙特卡洛估计、时序差分法</span>等。</p>
<h2 id="动态规划">动态规划</h2>
<p>用动态规划算法在 能够获取MDP完整的环境信息（包括状态动作空间、转移矩阵、奖励等）的基础上 求解最优策略。</p>
<p><strong><span style="color:purple;">预测</span></strong>：给定一个MDP &lt;𝒮, 𝒜, 𝒫, ℛ, 𝛾&gt;和策略𝜋，输出基于当前策略𝜋的价值函数v。</p>
<p><strong><span style="color:purple;">控制</span></strong>：给定一个MDP &lt;𝒮, 𝒜, 𝒫, ℛ, 𝛾&gt;，输出最优价值函数𝑣∗以及最优策略𝜋∗</p>
<p><strong><span style="color:purple;">迭代策略评估</span></strong>： 预测问题，评估一个给定的策略$\pi$。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E8%BF%AD%E4%BB%A3%E7%AD%96%E7%95%A5%E8%AF%84%E4%BC%B0.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AD%96%E7%95%A5%E8%AF%84%E4%BC%B0.png" alt="图6"></p>
<p><strong><span style="color:purple;">策略迭代</span></strong>：</p>
<ul>
<li>策略评估，在当前策略𝜋上迭代地计算𝑣值</li>
<li>策略更新，根据𝑣值贪婪地更新策略</li>
<li>如此反复多次，最终得到最优策略𝜋∗和最优状态价值函数𝑣∗<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3.png" alt="图7"></li>
</ul>
<p><strong><span style="color:purple;">价值迭代</span></strong>：<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%BB%B7%E5%80%BC%E8%BF%AD%E4%BB%A3.png" alt="图8"></p>
<p><strong>参考资料</strong>：</p>
<p>中国科学院大学 林姝老师 强化学习课程课件</p>
<p>深度强化学习：基础、研究与应用 (董豪 等)</p>
<p>Reinforcement Learning An Introduction (Adaptive Computation and Machine Learning series) (Sutton, Richard S., Barto, Andrew G.)</p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索</title>
    <url>/2024/05/15/%E6%90%9C%E7%B4%A2/</url>
    <content><![CDATA[<pre><code>知识点：

经典搜索算法：基于路径的搜索的问题。如盲目搜索，启发式搜索。

局部搜索算法：最优化问题，没有初始状态，也没有终止状；并不需要到达这些解的路径。如爬山法，元启发算法。

元启发式算法是启发式算法的改进，它是随机算法与局部搜索算法相结合的产物。如禁忌搜索算法(Tabu Search)，模拟退火算法(Simulated annealing)，遗传算法(Geneticalgorithm)。

对抗搜索算法：也被称为博弈搜索，在一个竞争的环境中，智能体(agents)之间通过竞争实现相反的利益，一方最大化利益，另外一方最小化这个利益。如mini-max算法，Alpha-Beta算法、蒙特卡洛树。
</code></pre><h2 id="1-搜索算法基础"><a href="#1-搜索算法基础" class="headerlink" title="1.搜索算法基础"></a>1.搜索算法基础</h2><p>树搜索：</p>
<ul>
<li>结点：n.state, n.parent, n.action(父节点生成该节点时所采取的行动), n.path-cost(从初始状态到达该结点的路径消耗g(n))</li>
<li>搜索策略：节点扩展到顺序</li>
<li>策略评价标注：完备性（是否能找到存在的解），时间复杂度，空间复杂度，最优性</li>
<li>复杂度表示：分支因子b，搜索树的中节点的最大分支树；深度d，目标结点所在的最浅深度；m，状态空间中，任何路径的最大长度</li>
</ul>
<p>图搜索：</p>
<ul>
<li>边缘(fringe)：待扩展的叶子结点，将状态空间分成已探索区域和未被探索区域。</li>
</ul>
<h2 id="2-盲目搜索"><a href="#2-盲目搜索" class="headerlink" title="2.盲目搜索"></a>2.盲目搜索</h2><p>只能使用访问过的结点的信息。如<strong>宽度优先搜索</strong>，<strong>深度优先搜索</strong>，<strong>一致代价搜索</strong>（扩展路径消耗g(n)最小的结点），<strong>深度受限搜索</strong>（对深度优先搜索设置最大深度的界限），<strong>迭代加深的深度优先搜索</strong>（不断增大深度限制，并且每次重新开始深度受限搜索）。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/盲目搜索.png" alt="图片"></p>
<h2 id="3-启发式搜索"><a href="#3-启发式搜索" class="headerlink" title="3.启发式搜索"></a>3.启发式搜索</h2><p>优先扩展最优的结点。评价函数：f = g + h。其中，g为一致代价，h为启发式函数，指的是结点n到目标结点的最小代价路径的代价估计值。</p>
<ul>
<li>贪婪算法：扩展离目标最近的结点，以期望很快找到解。f(n)=h(n)</li>
<li>A* 算法：避免扩展代价已经很高的路径。f(n) = g(n) + h(n)</li>
</ul>
<blockquote>
<p><strong>A* 算法:</strong></p>
<p><strong>可采纳启发式</strong>：永远不会高估代价，即$h(n)\le h^<em>(n)$，且要求$h(n)\ge 0$。其中，$h^</em>(n)$为实际的代价。</p>
<p>定理：<strong>如果h(n)是可采纳的，A*的树搜索版本是最优的。</strong></p>
<p><strong>一致的启发式</strong>：对于每个结点n和通过任一行动a生成的后继结点n’，从结点n到达目标的估计代价不大于从n到n’的单步代价与从n到目标的估计代价之和，即$h(n)\le c(n,a,n’) + h(n’)$。如果h(n)是一致的，那么沿着任何路径的f(n)是非递减的。</p>
<p>定理：<strong>如果h(n)是一致的，那么A*的图搜索版本是最优的。</strong></p>
<p>松弛问题：对原问题移除一些限制，一个松弛问题的最优解的代价是原问题的一个可采纳、一致的启发式。</p>
<p>松弛问题的最优解的代价不大于原问题最优解的代价。</p>
</blockquote>
<h2 id="4-局部搜索"><a href="#4-局部搜索" class="headerlink" title="4.局部搜索"></a>4.局部搜索</h2><p>局部搜索：找到满足条件的状态，不关心路径，从单个当前节点(而不是多条路径)出发，通常只移动到它的邻近状态。</p>
<h3 id="4-1-爬山法"><a href="#4-1-爬山法" class="headerlink" title="4.1 爬山法"></a>4.1 爬山法</h3><p>属于贪婪法，不断向值增加的方向移动，容易到达局部极大值。为了克服局部极大值，可以采用随机重启爬山法，完备的概率接近1。</p>
<h3 id="4-2-禁忌搜索算法"><a href="#4-2-禁忌搜索算法" class="headerlink" title="4.2 禁忌搜索算法"></a>4.2 禁忌搜索算法</h3><p>从一个初始可行解出发，选择一系列的特定搜索方向（移动）作为试探，选择实现让特定的<strong>目标函数值变化最多</strong>的移动。</p>
<p>为了避免陷入局部最优解，TS搜索中采用了一种灵活的“记忆”技术，对已经进行的优化过程进行记录和选择，指导下一步的搜索方向，这就是Tabu表的建立。</p>
<p>标记已经解得的局部最优解或求解过程，并在进一步的迭代中避开这些局部最优解或求解过程。局部搜索的缺点在于，太过于对某一局部区域以及其邻域的搜索，导致一叶障目。为了找到全局最优解，<strong>禁忌搜索就是对于找到的一部分局部最优解，有意识地避开它，从而或得更多的搜索区域。</strong></p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/禁忌搜索2.png" alt="图片2"><br><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/禁忌搜索3.png" alt="图片3"><br><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/禁忌搜索4.png" alt="图片4"><br><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/禁忌搜索5.png" alt="图片2"></p>
<h3 id="4-3-模拟退火算法"><a href="#4-3-模拟退火算法" class="headerlink" title="4.3 模拟退火算法"></a>4.3 模拟退火算法</h3><p>算法概述：</p>
<ul>
<li>若目标函数f在第i+1步移动后比第i步更优，即$f(Y(i+1))\le f(Y(i))$，则总是接受该移动。</li>
<li>若$f(Y(i+1))&gt;f(Y(i))$，（即移动后的解比当前解要差），则以一定的概率接受移动，而且这个概率随着时间推移逐渐降低（逐渐降低才能趋向稳定）。</li>
<li>Metroplis准则：温度越高，算法接受新解的概率就越高。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/模拟退火1.png" alt="图片1"><br><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/模拟退火2.png" alt="图片2"></p>
<h3 id="4-4-遗传算法"><a href="#4-4-遗传算法" class="headerlink" title="4.4 遗传算法"></a>4.4 遗传算法</h3><p>基本思想：从初始种群出发，采用优胜劣汰、适者生存的自然法则选择个体，并通过杂交、变异来产生新一代种群，如此逐代进化，直到满足目标为止。</p>
<ul>
<li>种群：组候选解的集合，遗传算法正是通过种群的迭代进化，实现了最优解或者近似最优解。</li>
<li>个体：一个个体对应一个解，也就是构成种群的基本单元。</li>
<li>适应度函数:用来对种群中各个个体的环境适应性进行度量的函数，函数值是遗传算法实现优胜劣汰的主要依据。</li>
<li>遗传操作：作用于种群而产生新的种群的操作。如选择、交叉、变异。</li>
</ul>
<p>遗传编码：</p>
<ul>
<li>二进制编码</li>
<li>格雷编码，要求两个连续整数的编码之间只能有一个码位不同，其余码位都是完全相同的。</li>
<li>符号编码，个体染色体编码串中的基因值取自一个无数值含义、而只有代码含义的符号集</li>
</ul>
<p>适应度函数：</p>
<ul>
<li>原始适应度函数，直接将待求解问题的目标函数f(x)定义为遗传算法的适应度函数。它能够直接反映出待求解问题的最初求解目标但是有可能出现适应度值为负的情况。</li>
<li>标准适应度函数。在遗传算法中，一般要求适应度函数非负，并其适应度值越大越好。这就往往需要对原始适应函数进行某种变换，将其转换为标准的度量方式，以满足进化操作的要求，这样所得到的适应度函数被称为标准适应度函数$f_{Normal}(x)$</li>
</ul>
<p>选择：各个个体被选中的概率与其适应度大小成正比</p>
<ul>
<li>比例选择</li>
<li>锦标赛选择，随机选择一组个体进行竞赛，然后从中选择最优秀的个体来进行繁殖。</li>
<li>轮盘赌选择，根据每个个体的选择概率$P(x_i)$将一个圆盘分成N 个扇区，其中第i 个扇区的中心角为:$2 \pi \frac{f\left(x_{i}\right)}{\sum_{j=1}^{N} f_{i}\left(x_{j}\right)}=2 \pi p\left(x_{i}\right)$，并再设立一个固定指针。当进行选择时，可以假想转动圆盘，若圆盘静止 时指针指向第i个扇区，则选择个体i。</li>
</ul>
<p>交叉：</p>
<ul>
<li>单点交叉，先在两个父代个体的编码串中随机设定一个交叉点，然后对这两个父代个体交叉点前面或后面部分的基因进行交换，并生成子代中的两个新的个体。</li>
<li>两点交叉，先在两个父代个体的编码串中随机设定两个交叉点，然后再按这两个交叉点进行部分基因交换，生成子代中的两个新的个体。</li>
<li>多点交叉，从两个父代个体中选择多个交叉点，然后交换这些交叉点之间的基因片段，从而产生新的个体。</li>
<li>均匀交叉，父串中的每一位都是以相同的概率随机进行交叉的。</li>
<li><p>实值交叉，在实数编码情况下所采用的交叉操作，可分为部分离散交叉、整体交叉。</p>
<p>  部分离散交叉: 先在两个父代个体的编码向量中随机选择一部分分量， 然后对这部分分量进行交换，生成子代中的两个新的个体。</p>
<p>  整体交叉: 对两个父代个体的编码向量中的所有分量，都以1/2的概率进行交换，从而生成子代中的两个新的个体。</p>
</li>
<li>洗牌交叉，打乱之后再选择交叉点，再进行复原</li>
</ul>
<p>变异：</p>
<ul>
<li>二进制变异，随机地产生一个变异位，0-&gt;1，1-&gt;0</li>
<li>实值变异，用另外一个在规定范围内的随机实数去替换原变异位置上的基因值，产生一个新的个体。</li>
</ul>
<h2 id="5-对抗搜索"><a href="#5-对抗搜索" class="headerlink" title="5.对抗搜索"></a>5.对抗搜索</h2><h3 id="5-1-Alpha-Beta算法"><a href="#5-1-Alpha-Beta算法" class="headerlink" title="5.1 Alpha-Beta算法"></a>5.1 Alpha-Beta算法</h3><p>对mini-max算法的改进。剪枝本身不影响算法输出结果，但节点先后次序会影响剪枝效率。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Alpha-Beta%20剪枝1.png" alt="图片1"><br><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Alpha-Beta%20剪枝2.png" alt="图片2"></p>
<h3 id="5-2-蒙特卡洛树"><a href="#5-2-蒙特卡洛树" class="headerlink" title="5.2 蒙特卡洛树"></a>5.2 蒙特卡洛树</h3><p>参看蒙特卡洛树搜索部分。</p>
<h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6.参考资料"></a>6.参考资料</h2><p>中国科学院大学李国荣老师 高级人工智能课程课件</p>
<p>高级算法设计与分析 启发式算法 林海老师</p>
]]></content>
      <tags>
        <tag>高级人工智能</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>无模型强化学习</title>
    <url>/2024/05/15/%E6%97%A0%E6%A8%A1%E5%9E%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p><strong>知识点</strong></p>
<p>1.无模型价值学习评估</p>
<ul>
<li>蒙特卡洛方法</li>
<li>时序差分学习</li>
<li>TD(𝝀)</li>
</ul>
<p>2.无模型策略优化控制</p>
<ul>
<li>蒙特卡洛策略迭代</li>
<li>时序差分策略迭代（SARSA）</li>
<li>Q值迭代 (Q-learning) <span id="more"></span></li>
</ul>
</blockquote>
<h2 id="无模型价值学习评估">1. 无模型价值学习评估</h2>
<h3 id="蒙特卡洛方法">1.1 蒙特卡洛方法</h3>
<p>蒙特卡洛方法是一种<strong>基于样本</strong>的方法，不需要知道环境的所有信息。只需基于过去的经验就可以学习。具体来说，给定一个策略
π，通过对 π 产生的回报取平均值来评估状态价值函数。这样就有两种估算方式:
<strong>首次蒙特卡罗</strong>(First-Visit Monte
Carlo)和<strong>每次蒙特卡罗</strong>(Every-Visit Monte
Carlo)。首次蒙特卡罗只考虑每一个回合中第一次到状态 s
的访问，而每次蒙特卡罗就是考虑每次到状态 s 的访问。</p>
<p>注意的是，和动态规划不同的是，蒙特卡罗不使用<strong>自举(Bootstrapping)</strong>，也就是说，它不用其他状态的估算来估算当前的状态值。
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/首次蒙特卡洛访问.png" alt="图片"></p>
<p>离线学习：智能体从预先收集好的数据中进行学习。</p>
<p>在线学习：智能体通过与环境实时交互来获取知识和经验。</p>
<h3 id="时序差分学习">1.2 时序差分学习</h3>
<p>时序差分学习方法同蒙特卡洛方法一样是不基于模型的，不需要马尔可夫决策过程的知识。但是时序差分学习方法可以直接从经历的不完整经历片段中学习，它通过<strong>自举(bootstrap)</strong>猜测经历片段的结果并不断更新猜测。即时序差分学习方法可以在每一次经历的过程中进行学习，而蒙特卡洛方法只能等到每次经历完全结束时才能进行学习。</p>
<p><span class="math display">\[𝑉(𝑆_{𝑡}) ← 𝑉(𝑆_{𝑡}) + 𝛼(𝐺_t −
𝑉(𝑆_{𝑡}))\]</span></p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TD.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>对TD(0)，即one-step TD:</p>
<p><span class="math display">\[𝑉(𝑆_{𝑡}) ← 𝑉(𝑆_{𝑡}) + 𝛼(𝑅_{𝑡+1} +
𝛾𝑉(𝑆_{t+1}) − 𝑉(𝑆_{𝑡}))\]</span></p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Sarsa价值评估.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>这个算法又被叫做<strong>SARSA</strong>，因为用到了 <span class="math inline">\((S_t, A_{𝑡}, R_{𝑡+1}, S_{𝑡+1},
A_{𝑡+1})\)</span>。</p>
<ul>
<li>蒙特卡洛方法没有偏倚，是对当前状态实际价值的无偏估计，但有着较高的变异性，且对初始值不敏感。</li>
<li>时序差分方法方差更低,
但有一定程度的偏差，对初始值较敏感，通常比蒙特卡洛方法更高效。</li>
</ul>
<h3 id="td𝝀">1.3 TD(𝝀)</h3>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/步数对TD的影响.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TDn_1.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TDn_2.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TDn_3.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/反向TD_补充1.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/反向TD_补充2.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TDn-4.png" alt="图片"></p>
<h2 id="无模型策略优化控制">2.无模型策略优化控制</h2>
<h3 id="蒙特卡洛策略迭代">2.1 蒙特卡洛策略迭代</h3>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/MTCS策略迭代.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h3 id="时序差分策略迭代sarsa">2.2 时序差分策略迭代（SARSA）</h3>
<p><span class="math display">\[G_{t:t+n} = R_{t+1} + γR_{t+2} + \dot +
γ^{n−1}R_{t+n} + γ^nQ_{t+n−1}(S_{t+n}, A_{t+n})\]</span></p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Sarsa价值评估.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/sarsa-n.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/sarsa-lambda.png" alt="图片"></p>
<h3 id="q值迭代-q-learning">2.3 Q值迭代 (Q-learning)</h3>
<p>Sarsa --&gt; on-policy</p>
<p>Q-learning --&gt; off-policy</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Q-learning策略迭代.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>参考资料</strong>：</p>
<p>中国科学院大学林姝老师 强化学习课程课件</p>
<p>深度强化学习：基础、研究与应用 (董豪 等)</p>
<p>强化学习入门——从原理到实践，叶强</p>
<p>Reinforcement Learning An Introduction (Adaptive Computation and
Machine Learning series) (Sutton, Richard S., Barto, Andrew G.)</p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度强化学习</title>
    <url>/2024/05/15/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>强化学习从深度学习角度出发的挑战：</p>
<ul>
<li>强化学习的奖励信号是有延迟的，而深度学习的输入输出是直接联系的</li>
<li>强化学习的序贯决策序列有很高的相关性，而深度学习的假设数据是独立同分布</li>
<li>强化学习的数据分布是会随着学习发生变化的，而深度学习的假设是底层分布固定的</li>
</ul>
<span id="more"></span>
<h2 id="1-DQN算法">1. DQN算法</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-4.png" alt="图1"></p>
<h3 id="1-1-DQN">1.1 DQN</h3>
<p>Deep Q-learning: DQN, <strong>Approximate $Q^*(s,a)$ by DQN,$Q(s,a;w)$</strong></p>
<p><strong>经历回放</strong>(experience replay): 在每个时间步t 中，DQN先将智能体获得的经验$(S_t, A_t, R_t, S_{t+1})$存入回放缓存中，然后从该缓存中均匀采样小批样本用于 Q-Learning 更新。主要作用是<strong>解决数据的相关性和非静态分布问题</strong>。</p>
<p>DQN2015的改进：<strong>增加目标网络</strong>。目标网络通过使用旧参数生成 Q-Learning 目标，使目标值的产生不受最新参数的影响，从而大大减少发散和震荡的情况。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-1.png" alt="图2"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-2.png" alt="图3"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-3.png" alt="图4"></p>
<h3 id="1-2-Double-DQN-DDQN">1.2 Double-DQN, DDQN</h3>
<p>Double DQN 是对 DQN 在减少过拟合方面的改进。这是由于DQN对动作值函数的max操作会引入一个正向的偏差，导致下一时刻的目标值存在过估计。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-5.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-6.png" alt="图6"></p>
<h3 id="1-3-Prioritized-Experience-Replay-优先经验回放">1.3 Prioritized Experience Replay, 优先经验回放</h3>
<p>采用优先级采样达到收敛所需的更新次数相比均匀采样要小很多，这也是进行优先经验池回放的原因。</p>
<p><strong>1.3.1 样本优先级</strong>:</p>
<p>样本优先级应满足两个条件：</p>
<ul>
<li>优先级在数值上应该和误差绝对值成单调递增关系，这是为了满足误差绝对值较大（即优先级较大）的样本获得更大的被抽样的机会；</li>
<li>优先级数值应大于0，这是为了保证每一个样本都有机会被抽样，即抽样概率大于0。</li>
</ul>
<p>优先级可以分为<strong>基于比例的样本优先级</strong>，<strong>基于排序的样本优先级</strong>。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-7.png" alt="图7"></p>
<p><strong>1.3.2 随机优先级采样</strong>:</p>
<p>采样方法：</p>
<ul>
<li>贪婪优先级采样，完全按照优先级去采样</li>
<li>一致随机采样，均匀采样</li>
<li>随机优先级采样，随机采样</li>
</ul>
<p>基本原则：</p>
<ul>
<li>样本被采样的概率应该和样本优先级成正相关关系</li>
<li>每一个样本都应该有机会被采样，即被采样的概率大于0</li>
</ul>
<p>Sum-Tree随机优先级采样，属于基于比例的样本优先级：</p>
<p>重要性采样: 用一个分布来计算当前分布的期望。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-8.png" alt="图8"></p>
<h3 id="1-4-Dueling-DQN">1.4 Dueling-DQN</h3>
<p>算法原理：将动作值的计算分解成状态值和优势函数，$Q(s,a)=V(s)+A(s,a)$。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-9.png" alt="图9"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DQN-10.png" alt="图10"></p>
<h2 id="2-策略梯度方法DDPG">2. 策略梯度方法DDPG</h2>
<h3 id="2-1-DPG-Deterministic-Policy-Gradient-确定性策略梯度">2.1 DPG, (Deterministic Policy Gradient) 确定性策略梯度</h3>
<p>确定性策略：每一步的动作都是确定的，即$a=\mu_\theta(s)$。确定性策略梯度算法正是使用了确定性策略的策略梯度算法。</p>
<h3 id="2-2-DDPG-Deep-Deterministic-Policy-Gradient">2.2 DDPG, (Deep Deterministic Policy Gradient)</h3>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/DDPG-1.png" alt="图11"></p>
<p>几个trick：</p>
<ul>
<li>$\mu^{\prime}(s_t)=\mu(s_t|\theta_{t}^{\mu} + N)$ 添加了一个随迭代次数衰减的随机噪声，增加了动作空间的探索</li>
<li>目标网络缓慢更新保证了训练的稳定性</li>
<li>batch normalization 使得可以在不同的环境中获取的特征统一</li>
</ul>
<p>问题：值函数过估计；自举造成的偏差传播</p>
<h3 id="2-3-PPO">2.3 PPO</h3>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/PPO-1.png" alt="图12"></p>
<h3 id="2-4-SAC-Soft-Actoe-Critic">2.4 SAC, (Soft Actoe Critic)</h3>
<p>熵：随机变量取各值时信息量的期望。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/SAC.png" alt="图13"></p>
<p><strong>参考资料</strong>：</p>
<p>中国科学院大学林姝老师 强化学习课程课件</p>
<p>深度强化学习：基础、研究与应用 (董豪 等)</p>
<p>Reinforcement Learning An Introduction (Adaptive Computation and Machine Learning series) (Sutton, Richard S., Barto, Andrew G.)</p>
<p><a href="https://github.com/QiangLong2017/Deep-Reiforcement-Learning">https://github.com/QiangLong2017/Deep-Reiforcement-Learning</a></p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱数据管理</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<pre><code>知识图谱的目标是构建一个能够刻画现实世界的知识库，为自动问答、信息检索等应用提供支撑。因此，对知识的持久化存储并提供对目标知识的高效检索/更新是合格的知识图谱（系统）必须具备的基本功能，也是知识图谱数据管理的主要研究内容。

课程复习使用。</code></pre>
<h2 id="一.符号化知识图谱数据管理">一.符号化知识图谱数据管理</h2>
<h3 id="知识图谱数据模型">1.1 知识图谱数据模型</h3>
<p>数据模型主要包含<strong>逻辑组织结构、操作、约束</strong>三部分，它决定了数据管理所采取的方法和策略，对于存储管理、查询处理、查询语言设计均至关重要。常见的数据模型有层次数据模型，网状数据模型，系数据模型。</p>
<ul>
<li>逻辑组织结构（数据结构）：描述数据的类型、内容、性质以及数据间的联系等。</li>
<li>数据操作：描述在相应的数据结构上的操作类型和操作方式。</li>
<li>数据约束：描述数据结构内数据间的语法、词义联系、他们之间的制约和依存关系，以及数据动态变化的规则，以保证数据的正确、有效和相容。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理1.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理2.png" alt="图片"></p>
<h3 id="知识图谱数据的存储">1.2 知识图谱数据的存储</h3>
<ul>
<li>基于表结构的存储：关系数据库。</li>
<li>基于图结构的存储：常见的图数据库存储系统，如Neo4j, OrientDB,
HyperGraphDB, InfiniteGraph, InfoGrid.</li>
</ul>
<h3 id="知识图谱数据的检索查询">1.3 知识图谱数据的检索（查询）</h3>
<p>知识图谱查询语言可分为
<strong>声明式语言</strong>（描述“是什么”而不是“怎么做”，它关注的是结果而不是实现结果的过程），<strong>过程式语言</strong>（描述“怎么做”，它定义了一系列的步骤或指令来实现目标，如图遍历、导航式游走）。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理3.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理4.png" alt="图片"></p>
<p>这些查询语言都有点类似于sql，可借助sql进行进一步理解。</p>
<h2 id="二.参数化知识图谱大模型数据管理">二.参数化知识图谱（大模型）数据管理</h2>
<h3 id="大模型知识存储">2.1 大模型知识存储</h3>
<p>一个流行的观点是：PLM的<strong>FFN</strong>（Feed Forward Nerual
Network）模块存储了大量知识。</p>
<h3 id="大模型的知识编辑检索与更新">2.2
大模型的知识编辑（检索与更新）</h3>
<ul>
<li>知识编辑的目标：定向更新模型中具有的知识，该过程应当尽可能地保证有效、能泛化、避免对无关知识产生不良影响</li>
<li>逻辑研究对象：三元组</li>
<li>评估方法：提示生成，看结果是否符合预期</li>
<li>评估指标：有效性，泛化性，专一性，流畅度</li>
<li>知识编辑的实现方法</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理5.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识图谱数据管理6.png" alt="图片"></p>
<h2 id="三.参考资料">三.参考资料</h2>
<p>中国科学院大学陈玉博老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱构建</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="一-半结构化文本中的知识抽取">一.半结构化文本中的知识抽取</h2>
<p>目标：从百科普通条目半结构化网页中抽取实体属性名以及实体属性值。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA1.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA2.png" alt="图片"></p>
<h2 id="二-非结构化文本中的知识抽取">二.非结构化文本中的知识抽取</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA3.png" alt="图片"></p>
<h2 id="三-知识图谱众包构建">三.知识图谱众包构建</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA4.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA5.png" alt="图片"></p>
<h2 id="四-知识图谱质量控制">四.知识图谱质量控制</h2>
<p>知识图谱的质量控制指的是如何通过技术手段来确保知识图谱中知识的质量。</p>
<p><strong>评估思路</strong>：</p>
<ul>
<li>内检：利用知识图谱的内部知识进行综合推理，得到新的缺失知识，也可以发现相互矛盾的错误知识等。</li>
<li>外检：从外部知识源获得信息，然后结合知识图谱内部的知识进行比对，从而补全、修正或者更新知识图谱中的知识。</li>
</ul>
<p><strong>评估指标</strong>：准确性，一致性，完整性，时效性。</p>
<p><strong>评估方法</strong>：人工抽样检测法，一致性检测法，基于外部知识的对比评估法。</p>
<h2 id="五-参考资料">五.参考资料</h2>
<p>中国科学院大学陈玉博老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>知识建模与知识融合</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E5%BB%BA%E6%A8%A1%E4%B8%8E%E7%9F%A5%E8%AF%86%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<pre><code>课程复习使用，这章没有进行细致整理。

一. 知识建模

1.1 知识体系概述

1.2 典型知识体系

1.3 知识体系手工建模方法

1.4 知识体系自动建模方法

二. 知识融合

2.1 知识融合概述

2.2 知识体系融合方法

2.3 知识实例融合方法

三. 大模型中的知识融合

3.1 大模型对齐技术概述

3.2大模型对齐方法</code></pre>
<h2 id="一.-知识建模-知识融合">一. 知识建模 &amp; 知识融合</h2>
<p><a href="https://lwl1751.github.io/pdf/知识建模_知识融合_拼接.pdf">查看对应ppt</a></p>
<h2 id="二.大模型的知识融合">二.大模型的知识融合</h2>
<p>SFT，RLHF，DPO。</p>
<h2 id="三.参考资料">三.参考资料</h2>
<p>中国科学院大学陈玉博老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>知识推理</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86/</url>
    <content><![CDATA[<pre><code>知识工程的生命周期：知识表示，知识建模，知识融合，知识管理，知识推理，知识应用。
</code></pre>
<h2 id="一-知识推理概述">一.知识推理概述</h2>
<p>概念区分：<strong>推理 reasoning</strong>，指的是通过已知知识推断出未知知识的过程。而<strong>推断 inference</strong> 是推理的一个步骤，指的是神经网络中的前向计算。</p>
<p><strong>按新知识推出途径的分类</strong>：</p>
<ul>
<li>归纳推理（特殊-&gt;一般），归纳推理所推出的结论没有包含在前提内容中。这种由个别事物或现象推出一般性知识的过程，是增加新知识的过程。</li>
<li>演绎推理（一般-&gt;特殊），演绎推理只不过是将已有事实揭示出来，因此它不能增加新知识。</li>
<li>缺省推理，也称默认推理，在知识不完全的情况下作出的推理，通常的形式：如果没有足够的证据证明结论不成立，则认为结论是正确的。</li>
<li>溯因推理，也称反绎推理、反向推理。，是推理到最佳解释的过程。它是开始于事实的集合，并推导出其最佳解释的推理过程。</li>
</ul>
<p><strong>按前提与结论的联系性质的分类</strong>：</p>
<ul>
<li>必然性推理，前提与结论有必然性联系，即前提蕴含结论。传统逻辑中通过直言命题变形的直接推理（换质法、换位法推理等）、通过命题间对应关系所进行的直接推理、三段论推理、各种假言推理、选言推理以及完全归纳推理等等，都属于必然性推理。</li>
<li>或然性推理，前提与结论无蕴含关系。简单枚举归纳推理、类比推理、回溯推理等等都属于或然性推理。例如，P：房间里有物品 → C：房子会着火，前提P只是结论C的“疑似”必要条件。</li>
</ul>
<p><strong>按推理过程单调性的分类</strong>：</p>
<ul>
<li>单调推理，是指在推理过程中随着推理的向前推进以及新知识的加入，推出的结论呈单调增加的趋势并越来越接近最终目标，且在推理过程中不会出现反复的情况，即不会因新知识的加入而否定前面推出的结论，从而使推理又退回到前面的某一步。</li>
<li>非单调性推理，是指在推理过程中，由于新知识的加入，不仅没有加强已经推出的结论，反而要否定它，使其需要退回到之前步骤。</li>
</ul>
<p><strong>知识确定性的分类</strong>：</p>
<ul>
<li>确定性推理大多指确定性逻辑推理，它具有完备的推理过程和充分的表达能力，可以严格地按照专家预先定义好的规则准确地推导出最终结论。但是确定性推理很难应对真实世界中，尤其是存在于网络大规模知识图谱中的不确定甚至不正确的事实和知识。</li>
<li>不确定性推理：并不是严格地按照规则进行推理，而是根据以往的经验和分析，结合专家先验知识构建概率模型，并利用统计计数、最大化后验概率等统计学习的手段对推理假设进行验证或推测。</li>
</ul>
<p><strong>按实现技术</strong>：</p>
<ul>
<li>逻辑推理，过程包含了严格的约束和推理过程（研究较多）。</li>
<li>非逻辑推理，自然语言推理，推理过程相对模糊。</li>
<li>符号推理，符号推理的特点就是在知识图谱中的实体和关系符号上直接进行推理。确定性和不确定性逻辑推理都属于符号推理。</li>
<li>数值推理，使用数值计算，尤其是向量矩阵计算的方法，捕捉知识图谱上隐式的关联，模拟推理的进行。</li>
</ul>
<p><strong>应用</strong>：知识图谱补全，知识问答，搜索与推荐，行业应用。</p>
<h2 id="二-演绎推理：推理具体事实，一般-特殊">二.演绎推理：推理具体事实，一般-&gt;特殊</h2>
<ul>
<li>经典逻辑推理：命题逻辑推理。</li>
<li>基于产生式规则的推理</li>
<li>基于概率逻辑学习的推理：马尔可夫逻辑网</li>
<li>自然语言演绎推理。</li>
</ul>
<h2 id="三-归纳推理：学习推理规则">三.归纳推理：学习推理规则</h2>
<ul>
<li>归纳推理概述</li>
<li>归纳推理逻辑程序设计</li>
<li>路径排序算法（PRA）</li>
<li>关联规则挖掘算法（AMIE）</li>
</ul>
<h2 id="四-基于深度学习的知识推理方法">四.基于深度学习的知识推理方法</h2>
<ul>
<li>基于表示学习</li>
<li>基于强化学习</li>
</ul>
<p><a href="https://lwl1751.github.io/pdf/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86_%E6%8B%BC%E6%8E%A5.pdf">查看 演绎推理，归纳推理，基于深度学习的知识推理方法 对应PPT</a></p>
<h2 id="五-大模型的推理方法">五.大模型的推理方法</h2>
<p>相比于传统方法的优势：由于LLM本身已经具备了出色的各类能力（e.g. 工具调用、知识生<br>
成等），因此LLM推理相比于传统推理有更多的形式和种类；CoT工作指出可以简单通过ICL的方式激发LLM的推理能力，因此与传统方式的大量训练相比，LLM的推理成本低、效率高、泛化性强。</p>
<p>相比于传统方法的劣势：部分LLM为黑盒模型，只能调整输入输出，推理过程的不透明度更高；LLM参数量大，幻觉现象严重，导致推理的输出更不可控且不稳定。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%861.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%862.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%863.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%864.png" alt="图片"></p>
<h2 id="六-参考资料">六.参考资料</h2>
<p>中国科学院大学老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>知识获取</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E8%8E%B7%E5%8F%96/</url>
    <content><![CDATA[<pre><code>信息抽取：从自然语言文本中抽取指定类型的实体、关系、事件等事实信息，并形成结构化数据输出的文本处理技术。
</code></pre>
<h2 id="1-命名实体识别">1.命名实体识别</h2>
<h3 id="1-1-基于词典的方法">1.1 基于词典的方法</h3>
<p>典型方法包括正向匹配方法，反向匹配方法。原理：按照一定的策略将待分析的汉字串与一个充分大的词典中的词条进行匹配，若在词典中找到某个字符串，则匹配成功。</p>
<h3 id="1-2-基于统计的方法">1.2 基于统计的方法</h3>
<ul>
<li>生成式方法，首先建立学习样本的生成模型，再利用模型对预测结果进行间接推理，如HMM。</li>
<li>判别式方法，基于由字构词的命名实体识别理念，将NER问题转化为判别式分类问题(序列标注问题)，如Maxent，SVM，CRF，CNN，RNN，LSTM+CRF。CRF做解码善于捕捉近距离的标签依赖，LSTM可以捕捉长距离的标签依赖。</li>
</ul>
<h3 id="1-3-基于大模型的方法">1.3 基于大模型的方法</h3>
<p>难点1: 任务形式差距。命名实体识别通常建模为序列标注任务，而大模型往往用于完成文本<br>
生成任务。难点2: 大模型存在较为严重的幻觉问题。</p>
<h2 id="2-关系知识抽取">2.关系知识抽取</h2>
<p>关系抽取：旨在自动识别由一对概念和联系这对概念的关系构成的相关三元组。如CEO(比尔盖茨，微软)。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%8E%B7%E5%8F%961.png" alt="图片"></p>
<h2 id="3-事件知识抽取">3.事件知识抽取</h2>
<p>事件是发生在某个特定的时间点或时间段、某个特定的地域范围内，由一个或者多个角色参与的一个或者多个动作组成的事情或者状态的改变。</p>
<p>事件关系：共指，时序，因果，子事件。</p>
<h2 id="4-参考资料">4.参考资料</h2>
<p>中国科学院大学赵军老师 知识工程课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>知识计算</title>
    <url>/2024/05/15/%E7%9F%A5%E8%AF%86%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<h2 id="一.-命题逻辑">一. 命题逻辑</h2>
<h3 id="基本概念">1.1 基本概念</h3>
<p><span style="color: purple;">知识库</span>：KB,
利用形式化语言定义的句子的集合。</p>
<p><span style="color: purple;">逻辑</span>：用于表示信息的形式化语言。</p>
<p><span style="color: purple;">语法</span>：句子的形式化结构。</p>
<p><span style="color: purple;">语义</span>：语句在每个可能模型中的真值。</p>
<p><span style="color: purple;">模型</span>： m, m是语句 <span class="math inline">\(\alpha\)</span> 的一个模型，表示语句在模型m
中为真，也称m 满足 <span class="math inline">\(\alpha\)</span>。</p>
<p><span style="color: purple;">逻辑</span>：用于表示信息的形式语言。</p>
<p><span style="color: purple;">逻辑蕴涵</span>：某语句在逻辑上跟随另一个语句，如
<span class="math inline">\(\alpha \models \beta\)</span>，当且仅当在
<span class="math inline">\(\alpha\)</span> 为真的模型中，<span class="math inline">\(\beta\)</span> 也为真，即 <span class="math inline">\(M(\alpha) \subseteq
M(\beta)\)</span>。同样的，对于知识库 <span class="math inline">\(KB
\models \alpha\)</span>，则有 <span class="math inline">\(M(KB)
\subseteq M(\alpha)\)</span>。如果算法i 可以根据KB推导出 <span class="math inline">\(\alpha\)</span>，记为 <span class="math inline">\(KB\vdash _i \alpha\)</span>。</p>
<p><span style="color: purple;">可靠性</span>：只能生成被蕴含的语句。即永远不会返回一个错误的结果。</p>
<p><span style="color: purple;">完备性</span>：生成所有被蕴含的语句。即返回的结果总能覆盖所有正确的解。</p>
<p><span style="color: purple;">命题逻辑</span>：应用一套形式化规则对以符号表示的描述性陈述进行推理的系统。</p>
<p><span style="color: purple;">原子命题</span>：一个或真或假的描述性陈述语句，并且无法再分解为更简单的命题
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/命题逻辑3.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/命题逻辑1.png" alt="图片"></p>
<p>理解：<span class="math inline">\(S_1\)</span> 不成立时，相当于 <span class="math inline">\(S_1\)</span>
为空集，空集可以被其他所有集合包含，因此 <span class="math inline">\(S_1\)</span> 不成立时 <span class="math inline">\(S_1 \Rightarrow S_2\)</span> 为真。</p>
<p><span style="color: purple;">逻辑等价</span>：命题p 和命题q
在所有情况下都具有相同的真假结果。 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/命题逻辑2.png" alt="图片"></p>
<p><span style="color: purple;">有效性</span>：一个句子在所有模型中都为真，则句子是有效的。</p>
<p><span style="color: purple;">可满足性</span>：一个句子在某些模型中为真。</p>
<h3 id="归结原理">1.2 归结原理</h3>
<p><strong>合取范式</strong>，也被称为CNF范式，以文字析取式的合取式表达的语句。</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/命题逻辑4.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>假言推理</p>
<p>在命题逻辑中，归结规则是可靠的、完备的。</p>
<p><strong>反证法</strong>：证明：<span class="math inline">\(KB\vdash  \alpha\)</span>，只需证明<span class="math inline">\(KB\wedge \neg \alpha\)</span>不可满足。</p>
<p><strong>子句集S 的归结闭包<span class="math inline">\(RC(S)\)</span></strong>：对S
中的子句或其派生子句反复使用归结规则而生成的所有子句的集合。</p>
<p><strong>限定子句</strong>：是受限形式的一种，它是指恰好只有一个正文字的析取式。</p>
<p><strong>Horn子句</strong>：包含至多一个正文字的析取式。用Horn子句判定蕴涵需要的时间与知识库的大小呈线性关系。如前向链接与反向链接。</p>
<p><strong>前向链接</strong>：如果蕴含式的所有前提已知，那么就把它的结论添加到已知事实集，真到查询q
被添加或者无法进一步推理。</p>
<p><strong>反向链接</strong>：从查询q 开始推理。如果查询q
为真，那么无须任何操作。否则寻找知识库中那些能以q
为结论的蕴含式。如果其中某个蕴含式的所有前提都能证明为真，那么q
为真。</p>
<h2 id="二.-谓词逻辑">二. 谓词逻辑</h2>
<p><strong>命题逻辑的局限性</strong>：
在命题逻辑中，每个陈述句是最基本的单位（即原子命题），无法对原子命题进行分解。因此，在命题逻辑中，不能表达<strong>局部与整体、一般与个别</strong>的关系，即使不同原子命题蕴含个体、群体和关系等内在丰富语义。</p>
<p><strong>谓词逻辑</strong>：将原子命题进一步细化，分解出<strong>个体、谓词和量词</strong>，来表达个体与总体的内在联系和数量关系。</p>
<p><strong>谓词</strong>：刻画个体属性或者描述个体之间关系存在性的元素,值域为{True,False}。</p>
<p><strong>量词</strong>：全称量词 <span class="math inline">\(\forall\)</span>，存在量词 <span class="math inline">\(\exists\)</span>。</p>
<p><strong>量词对偶</strong>：全称量词与存在量词可以相互转换，互相表示。</p>
<h2 id="三.-不确定性推理">三. 不确定性推理</h2>
<p><strong>效用</strong>：对不同决策结果的偏好。决策理论 = 概率理论 +
效用理论。</p>
<p><strong>不确定性推理</strong>：从不确定的初始证据出发，通过运用不确定性知识，推导出具有一定程度不确定性但合理的结论的思维过程。</p>
<p><strong>贝叶斯网</strong>：一个有向无环图模型，用简单的条件分布描述复杂的联合分布。其中，每个结点有一个条件概率分布<span class="math inline">\(P(X_i |
Parents(X_i))\)</span>，量化其父结点对该结点的影响。所有条件概率构成条件概率表。</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识计算5.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>贝叶斯网独立条件</strong>：一个结点的概率只与其父结点有关，与其它祖先结点无关。判断贝叶斯网是否独立可以利用贝叶斯球快速判断(通过、反弹、截止)。</p>
<p><strong>马尔科夫毯</strong>：一个结点的父结点、子结点、子结点的父结点。</p>
<p><strong>贝叶斯球算法</strong>：</p>
<pre><code>假设在贝叶斯网络中有一个按一定规则运动的球。已知中间结点 (或结点集合)Z，如果球不能由结点X 出发到达结点Y (或者由Y 到X )，则称X 和Y 关于Z 独立。

通过： 父结点-&gt;当前结点 方向的球，访问当前结点的任意子结点。子结点-&gt;当前结点 方向的球，访问当前结点的任意父结点。即父-&gt;子，子-&gt;父 。

反弹：父结点-&gt;当前结点 方向的球，访问当前结点的任意父结点。子结点-&gt;当前结点 方向的球，访问当前结点的任意子结点。即父-&gt;父，子-&gt;子。

截止：当前结点阻止贝叶斯球继续运动。

贝叶斯球规则：未知结点：父-&gt;子，子-&gt;父/子 。已知结点：父-&gt;父，子-&gt;截止。</code></pre>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识计算9.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>枚举推理（精确推理</strong>）：所有的变量集合X
,所有的证据变量集合E ,查询变量Q ,隐藏变量集合H = X - E- Q。则<span class="math inline">\(P(Q|E=e)=\alpha P(Q,E=e)=\alpha\sum_{H=h}
(Q,E=e,H=h)\)</span></p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识计算6.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识计算7.png" alt="图片"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/知识计算8.png" alt="图片"></p>
<p><strong>变量消元</strong>：降低贝叶斯网推理复杂度。</p>
<p><strong>近似推理</strong>：抽取样本形成采样分布，通过该分布近似后验概率。</p>
<blockquote>
<p><strong>采样方法</strong>：</p>
</blockquote>
<pre><code>先验采样：按拓扑顺序进行采样，从$P(X_i | Parents(X_i))$采样$X_i$。

优点：简单直接，可以直接从已知的先验分布中抽样，计算方便。

缺点：不适用于高维空间，不适合于复杂模型。

拒绝采样：拒绝不符合证据E 的样本，即若$X_i$与观察值不一样，放弃这个样本。

优点：容易实现。

缺点：采样效率低，因为拒绝太多的样本，随着证据变量的增多，与证据相一致的样本数量指数级下降。

似然加权采样（重要性采样）：只生成与证据一致的事件，即固定证据变量。但这会导致采样分布与实际分布不一致，因此正需要对样本进行加权，权重为该样本与证据的相似性。

优点：简单易实现，克服了拒绝采样的采样效率低的问题。

缺点：不适用于高维空间，即当证据变量的个数增加时，性能可能大幅下降。 因为大多数的样本权值都非常低/高。

吉布斯采样：固定证据变量，每次模拟一个隐藏变量的采样，从$X_i ～ P(X_i | 马尔可夫毯(X_i))$，使频率收敛到真实概率。

优点：在高维空间中通常比其他采样方法更有效，因为它逐维采样。适合于复杂模型。

缺点：收敛速度慢。依赖于条件独立性假设：需要模型条件分布容易计算。</code></pre>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/吉布斯采样1.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h2 id="四.-参考资料">四. 参考资料</h2>
<p>中国科学院大学高级人工智能，李国荣老师，课程课件</p>
<p><a href="https://www.bilibili.com/video/BV1ZY4y1J78y/?spm_id_from=333.788&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d" class="uri">https://www.bilibili.com/video/BV1ZY4y1J78y/?spm_id_from=333.788&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
]]></content>
      <tags>
        <tag>高级人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>连续状态系统基于模型的强化学习</title>
    <url>/2024/05/15/%E8%BF%9E%E7%BB%AD%E7%8A%B6%E6%80%81%E7%B3%BB%E7%BB%9F%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p>对于大规模的MDP问题，不希望使用查表（Table Lookup）的方式，通过<strong>函数近似</strong>来估计实际的价值函数的方式，既节约了资源，又能达到泛化的效果。</p>
<ul>
<li>$\hat{v}(s,w) = v_\pi (s)$</li>
<li>$\hat{q}(s,a,w) = q_\pi (s,a)$</li>
<li>$\hat{\pi}(a,s,w) = \pi (a|s)$</li>
</ul>
<p><strong>函数近似器</strong></p>
<ul>
<li>特征的线性组合</li>
<li>神经网络</li>
<li>决策树</li>
<li>最近邻方法</li>
<li>傅立叶/小波变换</li>
</ul>
</blockquote>
<span id="more"></span>
<h2 id="1-价值函数近似-Value-Fuction-Approximation-VFA">1. 价值函数近似, Value Fuction Approximation, VFA</h2>
<p>近似函数逼近的类型：</p>
<ul>
<li>input: s, output: $\hat{v}(s,w)$</li>
<li>input: s, output: $\hat{q}(s,a,w)$</li>
<li>input: s, output: $\hat{q}(s,a_1,w),\dots,\hat{q}(s,a_m,w)$</li>
</ul>
<h3 id="1-1-线性函数近似">1.1 线性函数近似</h3>
<p>近似价值函数: $\hat{v}(s,w)=x(s)^Tw$</p>
<p>目标函数: 均方误差。由于实际的价值函数不可知，用样本近似期望损失。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%80%BC%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC2.png" alt="图1"></p>
<h3 id="1-2-神经网络值函数近似">1.2 神经网络值函数近似</h3>
<p>参看 深度强化学习 部分。</p>
<h3 id="1-3-基于模型的近似值迭代算法">1.3 基于模型的近似值迭代算法</h3>
<h3 id="1-4-模型无关的近似值迭代算法">1.4 模型无关的近似值迭代算法</h3>
<h2 id="2-近似策略迭代">2. 近似策略迭代</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%80%BC%E5%87%BD%E6%95%B0%E8%BF%91%E4%BC%BC1.png" alt="图2"></p>
<p><strong>参考资料</strong>：</p>
<p>中国科学院大学林姝老师 强化学习课程课件</p>
<p>深度强化学习：基础、研究与应用 (董豪 等)</p>
<p>Reinforcement Learning An Introduction (Adaptive Computation and Machine Learning series) (Sutton, Richard S., Barto, Andrew G.)</p>
<p><a href="https://www.bilibili.com/video/BV11V411f7bi/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d">https://www.bilibili.com/video/BV11V411f7bi/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
]]></content>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>群体智能</title>
    <url>/2024/05/31/%E7%BE%A4%E4%BD%93%E6%99%BA%E8%83%BD/</url>
    <content><![CDATA[<blockquote>
<p>知识点：</p>
<ul>
<li>演化计算：蚁群优化算法、粒子群优化算法</li>
<li>博弈论</li>
<li>课程复习使用</li>
</ul>
</blockquote>
<h2 id="一-群体智能">一. 群体智能</h2>
<p><strong>群体智能</strong>：Social/Colletive Intelligence, “无智能”或者仅具有相对简单智能的个体通过合作表现出更高智能行为的特性。其中的“无智能”/简单智能并不是绝对意义上的智能，而是相对于群体表现出来的相对智能。（众人拾材火焰高）</p>
<p><strong>集群智能</strong>：Swarm Intelligence, 众多无智能的个体，通过相互之间的简单合作，所表现出来的智能行为。<br>
特点：</p>
<ul>
<li>分布式，无中心控制</li>
<li>随机性，非确定性</li>
<li>自适应，个体根据环境进行策略调整</li>
<li>正反馈，个体好的尝试会对个体产生正反馈</li>
<li>自发涌现，会在群体层面涌现出一种智能</li>
</ul>
<p><strong>博弈</strong>： Game Theory, 具备一定智能的理性个体，按照某种机制行动，群体层面表现出的智能。</p>
<p><strong>众包</strong>：Crowdsourcing, 设计合适的机制，激励个体参与，从而实现单个个体不具备的社会智能。</p>
<h2 id="二-演化计算">二. 演化计算</h2>
<h3 id="2-1-蚁群优化算法">2.1 蚁群优化算法</h3>
<p>Ant Colony Optimization, AOC. <strong>在图上寻找最优路径问题</strong>。</p>
<p><strong>形式化</strong>：蚂蚁(智能体) 依据一定的概率选择位置进行移动，途中会留下信息素，信息素会随时间挥发，且信息素浓度与该位置被选择的概率成正相关。</p>
<p><span style="color:purple;">用蚁群优化算法求解TSP问题</span>：</p>
<ul>
<li><strong>TSP问题描述</strong>：给定n个城市及每对城市之间的距离，求解访问每个城市一次、并回到起点的最短回路。</li>
<li><strong>符号表示</strong>：n个城市的有向图$G = (V,E)$，其中 $V={1,2,\dots,n}$,$E={(i,j)|i,j\in V}$,$d_{ij}$为节点之间的距离</li>
<li><strong>目标函数</strong>：$min f(w)=\sum_{l=1}^{n} d_{i_{l}i_{l+1}}$,其中，$s=(i_{1},\dots,i_{n})$</li>
<li><strong>根据信息素来选择下一个城市的概率计算为</strong>：</li>
</ul>
<p>$$<br>
p_{i j}^{k}(t)=\left{\begin{array}{ll}<br>
\frac{\left(\tau_{i j}(t)\right)^{\alpha}\left(\eta_{i j}(t)\right)^{\beta}}{\sum_{k \in \text { allowed }}\left(\tau_{i k}(t)\right)^{\alpha}\left(\eta_{i k}(t)\right)^{\beta}} &amp; j \in \text { allowed } \<br>
0, &amp; \text { otherwise }<br>
\end{array}\right.<br>
$$</p>
<p>其中，i为当前城市,j为下一城市，$\tau_{i j}(t)$为边$(i,j)$上的信息素浓度, $\eta_{i j}(t)=1/d_{i j}$是根据距离定义的启发式函数，$\alpha$，$\beta$反映了信息素与启发信息的相对重要性。</p>
<ul>
<li><strong>信息素更新</strong></li>
</ul>
<p>$$\begin{array}{l}\Delta \tau_{i j}^{k}=f(x)=\left{\begin{array}{cc}\frac{Q}{L_{k}}, &amp; (i, j) \in w_{k} \0, &amp; \text { otherwise }\end{array}\right. \\tau_{i j}(t+1)=\rho \cdot \tau_{i j}(t+1)+\Delta \tau_{i j} \\Delta \tau_{i j}=\sum_{k=1}^{m} \Delta \tau_{i j}^{k}\end{array}$$</p>
<p>其中：$Q$ 为常数，$w_k$ 表示第 $k$ 只蚂蚁在本轮迭代中走过的路径，$L_k$ 为路径长度，$\rho$ 为小于 1 的常数，反映信息素挥发速度。即路径越长，信息素越小。</p>
<ul>
<li><strong>算法流程</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> 初始化 随机放置蚂蚁</span><br><span class="line"><span class="number">2.</span> 迭代过程</span><br><span class="line">    t = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> t &lt;= ItCount do (执行迭代)</span><br><span class="line">        <span class="keyword">for</span> k = <span class="number">1</span> to m do (对 m 只蚂蚁循环)</span><br><span class="line">            <span class="keyword">for</span> j = <span class="number">1</span> to n - <span class="number">1</span> do (对 n 个城市循环)</span><br><span class="line">                根据概率选择下一个城市；</span><br><span class="line">                将 j 置入禁忌表，蚂蚁转移到 j；</span><br><span class="line">            end <span class="keyword">for</span></span><br><span class="line">            计算每只蚂蚁的路径长度 \( L_k \);</span><br><span class="line">        end <span class="keyword">for</span></span><br><span class="line">        更新所有蚂蚁路径上的信息量；</span><br><span class="line">        t = t + <span class="number">1</span>;</span><br><span class="line">    end <span class="keyword">while</span></span><br><span class="line"><span class="number">3.</span> 输出结果</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>缺点</strong>：收敛速度慢（与m,n取值相关），容易陷入局部最优解(探索与开发的平衡)，不适于求解连续空间的优化问题。</li>
</ul>
<h3 id="1-2-粒子群优化算法">1.2 粒子群优化算法</h3>
<p>Particle Swarm Optimization, PSO. 求解<strong>连续解空间</strong>的优化问题，主要启发来源于对⻦群群体运动行为的研究。</p>
<ul>
<li><strong>形式化</strong>：每一只鸟(称为粒子，代表一个可行解解) 都有自己的状态信息：位置与速度，同时可以获得领域内其它鸟的信息，根据这些信息不断的改变自己的状态，去更好的适应环境，最终能找到最近最优解。</li>
<li><strong>算法流程</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%951.png" alt="图1"></p>
<p>其中，$x_{n}^{(i)}$为粒子i 在第 n 轮的位置，$v_{n}^{(i)}$为粒子i 在第 n 轮的速度，$p_{best}^{(i)}$为粒子i 的历史最好位置,$g_{best}^{(i)}$全局最好的历史位置。</p>
<p>速度更新公式包含三项，第一项为<strong>惯性项</strong>（保持原速度不变的倾向），第二项为<strong>记忆项</strong>（回到历史最好位置的倾向），第三项为<strong>社会项</strong>（走向粒子群全局最好位置的倾向）。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%952.png" alt="图2"></p>
<ul>
<li>
<p><strong>算法终止条件</strong>：迭代次数，最佳位置连续为更新的次数，适应度函数的值达到预期要求。</p>
</li>
<li>
<p><strong>优化</strong>：对惯性项加上一个权重</p>
</li>
<li>
<p><strong>优点</strong>：收敛速度快，所需微粒群规模较小</p>
</li>
<li>
<p><strong>缺点</strong>：不保证收敛到全局最优解</p>
<p>蚁群算法和粒子群算法的相同点：都基于自然界的生物行为；都使用多个个体（蚂蚁或粒子）组成的群体来寻找全局最优解；都可用于解决各种优化问题；都是不确定算法。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%953.png" alt="图3"></p>
<h2 id="三-博弈">三. 博弈</h2>
<ul>
<li>
<p><strong>局中人</strong>：在博弈中有权决定自己行动方案的博弈参加者。重要假设：局中人是自私的理性人。</p>
</li>
<li>
<p><strong>策略</strong>：博弈中可供局中人选择的行动方案。</p>
</li>
<li>
<p><strong>策略集合</strong>：局中人可以选择的策略的集合。</p>
</li>
<li>
<p><strong>局势</strong>：所有局中人选择的策略形成的策略组。</p>
</li>
<li>
<p><strong>博弈类型</strong></p>
<p>静态博弈（同时选择策略） vs 动态博弈（按顺序选择策略）</p>
<p>竞争博弈（炒股） vs 合作博弈（结盟）</p>
<p>完全信息博弈（每个局中人对所有局中人的策略及效用充分了解） vs 不完全信息博弈</p>
</li>
<li>
<p><strong>效用函数</strong>，payoff，通常用$U$来表示，是局势、时间（动态博弈中）的函数。每个局中人都有自己的效用函数。希望效用函数越大越好。</p>
</li>
<li>
<p><strong>最佳应对</strong>：对局中人1，若 $U_1(s,t) \ge U_1(s’,t)$ ，其中 s’ 是局中人除 s 外的其它策略，t 为局中人2的策略，$U_{1}(s,t)$为局中人1 从这组决策中获得的收益，则称策略 𝑠 是局中人1对局中人2的策略 t 的最佳应对。</p>
</li>
<li>
<p><strong>最优策略</strong>：如果一个局中人的某个策略对其它局中人的任何策略都是最佳应对，那么这个策略就是该局中人的占优策略。</p>
</li>
<li>
<p><strong>纳什均衡</strong>：如果一个局势下，每个局中人的策略都是相对其他局中人当前策略的最佳应对，则称该局势是一个纳什均衡。也就是博弈进入了僵局。不存在纯策略的纳什均衡。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%887.png" alt="图4"></p>
<ul>
<li><strong>混合策略</strong>：每个局中人以某个概率分布在其策略集合中选择策略。</li>
<li><strong>混合策略纳什均衡</strong>：给定其他局中人的策略选择概率分布的情况下， 当前局中人选择任意一个(纯)策略获得的期望效用相等。</li>
<li><strong>纳什定理</strong>：任何有限博弈都至少存在一个纳什均衡。但寻找博弈的纳什均衡是困难的。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%886.png" alt="图5"></p>
<ul>
<li><strong>帕累托最优</strong>：对于一组策略选择(局势)，若不存在其他策略选择 使<strong>所有参与者</strong>得到至少和目前一样高的回报，且至少一个参与者会得到严格较高的回报，则这组策略选择为帕累托最优。</li>
<li><strong>社会最优</strong>：使参与者的回报之和最大的策略选择(局势)。社会最优的结果一定也是帕累托最优的结果，但帕累托最优不一定是社会最优。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%885.png" alt="图6"></p>
<ul>
<li>
<p><strong>机制设计</strong>：设计一个博弈，使其达到预期结果，如实现社会最优。</p>
</li>
<li>
<p><strong>maxmin策略</strong>，以我为主，最小化损失，抑制风险<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%881.png" alt="图7"></p>
</li>
<li>
<p><strong>minmax策略</strong>，抑制对手<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%882.png" alt="图8"></p>
</li>
<li>
<p><strong>匹配市场</strong></p>
<p>匹配定理：对于左右两部节点数相同的二部图，如果其不存在完全匹配（刚好一一对应），那么该二部图一定包含一个受限集。</p>
<p>匹配的效用：成功匹配的估价之和，称为匹配的效用。</p>
<p>最优匹配：效用最大的匹配。最优匹配对于个体而言不一定是最优的，甚至是最差的。</p>
<p>市场结清：每个卖方和买方都成交了。市场结清价格总是存在，且使得买卖双方总效用最优。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%883.png" alt="图9"></p>
</li>
<li>
<p><strong>中介市场</strong></p>
<p>买方和卖方通过中介交易。竞争不充分的地方，中介垄断价格。竞争充分的地方，中介的收益趋近于0。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%8D%9A%E5%BC%884.png" alt="图10"></p>
<ul>
<li>
<p><strong>议价权</strong></p>
<p>问题描述：给定一个网络，每个节点代表一个人，达成议价约定的两个人可以分配价值为1的东西。</p>
<p>不稳定边：对于结局中未参与配对的边，如果边的两个端点获得的收益之和小于1，则称这条边为不稳定边。</p>
<p>稳定结局：不存在不稳定边。</p>
<p>有备选项的议价：A、B两人议价，确定分配比例。A的备选项收益为x ，B的备选项为y 。要求 $x+y\le 1$，否则A和B达不成交易。则定义剩余价值为$s=1-x-y$。</p>
<p>纳什议价解：A的收益 $x+\frac{s}{2}=\frac{1+x-y}{2}$, B的收益 $y+\frac{s}{2}=\frac{1-x+y}{2}$。</p>
<p>均衡结局：结局中的任意一个参与配对的边都满足纳什议价解的条件。</p>
</li>
</ul>
<h2 id="四-参考资料">四. 参考资料</h2>
<p>中国科学院大学 计院高级人工智能课程课件</p>
<p><a href="https://www.zhihu.com/question/633226340/answer/3466364119">https://www.zhihu.com/question/633226340/answer/3466364119</a></p>
]]></content>
      <tags>
        <tag>高级人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>数值化知识表示</title>
    <url>/2024/06/01/%E6%95%B0%E5%80%BC%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/</url>
    <content><![CDATA[<pre><code>语言模型发展四范式：形式语言模型，统计语言模型，神经语言模型，预训练语言模型。

课程复习使用。
</code></pre>
<h2 id="一-语言的分布表示">一. 语言的分布表示</h2>
<ul>
<li>
<p><strong>Harris分布假说</strong>：上下文相似的词，其语义也相似。认为词的语义可以根据上下文统计获得，词之间的相似性可以通过向量距离衡量。</p>
</li>
<li>
<p><strong>word2vect</strong>: 词嵌入，上下文预测目标词</p>
</li>
<li>
<p><strong>CBOW</strong>：目标词预测上下文。</p>
</li>
</ul>
<h2 id="二-知识的分布表示">二. 知识的分布表示</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%95%B0%E5%80%BC%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA1.png" alt="图1"></p>
<ul>
<li>
<p>打分函数：</p>
<p>位移距离模型。位移距离模型 (translational distance models)：基于位移假设，即头尾实体的表示存在位移关系，采用基于“头尾实体表示的位移”与“关系表示”的距离作为打分函数来衡量三元组成立的可能性。</p>
<p>语义匹配模型。无上述假设，直接利用头实体、关系和尾实体的数值表示进行计算，采用基于相似度的打分函数来衡量三元组成立的可能性。</p>
</li>
<li>
<p>模型训练：</p>
<p>封闭世界假设，但凡未在知识图谱中出现的事实都是错误的。</p>
<p>开放世界假设，知识图谱只包括正确的事实，那些不在其中出现的事实要么是错误的，要么是缺失的。</p>
</li>
</ul>
<h2 id="三-预训练语言模型">三. 预训练语言模型</h2>
<ul>
<li>Elmo: Embeddings from Language Models，首次使用大规模语料训练一个两层双向的RNN。</li>
<li>Bert: Bidirectional Encoder Representations from Transformers, transformer结构的encoder。</li>
<li>GPT: Generative Pre-Training,transformer结构的decoder。</li>
<li>In-context learning, CoT, few-shot learning, SFT, RLHF。由于对llm 部分比较了解，此处省略。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%95%B0%E5%80%BC%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA2.png" alt="图2"></p>
<h2 id="四-讨论：预训练语言模型能否作为世界模型">四. 讨论：预训练语言模型能否作为世界模型</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%95%B0%E5%80%BC%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA3.png" alt="图3"></p>
<p>相关论文：</p>
<p>Language Models Represent Space and Time, ICLR2024, MIT.</p>
<p>Reasoning with Language Model is Planning with World Model, EMNLP 2023, US San Diego.</p>
<p>Language Models Meet World Models, AAAI 2024, UC San Diego</p>
<h2 id="五-讨论：预训练语言模型能否作为知识库">五. 讨论：预训练语言模型能否作为知识库</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E6%95%B0%E5%80%BC%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA4.png" alt="图4"></p>
<h2 id="六-参考文献">六. 参考文献</h2>
<p>中国科学院大学赵军老师 知识工程 课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>符号化知识表示</title>
    <url>/2024/06/01/%E7%AC%A6%E5%8F%B7%E5%8C%96%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/</url>
    <content><![CDATA[<blockquote>
<p>四种知识建模方式：严格结构化符号表示，松散结构化/自由形式 符号表示，数值化表示，数值与符号融合表示。</p>
<p>表示方法的衡量：表达能力、推理能力、计算能力、可读性。</p>
<p>目前的语义网革命并不是在科学上有革命性的突破，而大部分是工程上的挑战，其中标准化、规模化、系统开发与集成、用户交互等都是语义网技术面临的挑战。</p>
<p>课程复习使用。</p>
</blockquote>
<h2 id="一-经典知识表示理论">一. 经典知识表示理论</h2>
<h3 id="1-1-产生式规则">1.1 产生式规则</h3>
<ul>
<li>
<p><strong>产生式规则</strong>：用于表示事物之间的因果关系。</p>
</li>
<li>
<p><strong>确定性规则</strong>：P-&gt;Q。</p>
</li>
<li>
<p><strong>不确定性规则</strong>：P-&gt;Q(置信度)。当事实与前提条件不能精确匹配时，按照置信度的要求模糊匹配，并按特定算法将不确定性传递到结论。</p>
</li>
<li>
<p><strong>产生式系统</strong>：由数据库、规则库和推理机三部分组成。</p>
</li>
</ul>
<blockquote>
<p>数据库：用来存放问题的初始状态、已知事实、推理的中间结果和最终结论等。</p>
<p>规则库：用来存放与求解问题有关的所有规则。</p>
<p>推理机：用来控制整个系统的运行，决定问题求解的线路，包括匹配、冲突消解、路径解释等。</p>
<p>正向推理：类似于命题逻辑（查看<a href="https://lwl1751.github.io/2024/05/15/%E7%9F%A5%E8%AF%86%E8%AE%A1%E7%AE%97/">知识计算</a>）中的前向链接，从事实出发，通过规则获取结论。</p>
<p>反向推理：类似于命题逻辑中的反向链接，从目标出发，反向使用规则，求得已知事实</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA1.png" alt="图1"></p>
<h3 id="1-2-语义网络">1.2 语义网络</h3>
<ul>
<li>
<p><strong>语义网络</strong>：一种将相关概念联系起来的 有向图表示的 知识系统。</p>
</li>
<li>
<p><strong>语义基元</strong>：语义网络中最基本的语义单元，用三元组形式表示，&lt;节点1，关系，节点2&gt;。</p>
</li>
<li>
<p><strong>语义网络系统</strong>：由知识库和推理机组成。</p>
</li>
<li>
<p><strong>优点</strong>：使用直观的图结构来描述知识，表达自然，而且方便于计算机的存储和检索，有较为成熟的应用。</p>
</li>
<li>
<p><strong>缺点</strong>：由于缺少形式化的语义定义，不同的语义网络之间难以互相操作，表示不完善。推理过程复杂。</p>
</li>
</ul>
<h3 id="1-3-框架">1.3 框架</h3>
<p>框架是一种描述所论对象属性的数据结构。</p>
<ul>
<li><strong>框架名</strong>：用来指代某一类或某一个对象。</li>
<li><strong>槽</strong>：用来表示对象的某个方面的属性，<strong>语义网络中的三元组也可看作槽结构</strong>。</li>
<li><strong>侧面</strong>：从不同侧面描述某个属性。</li>
<li><strong>值</strong>：槽/侧面的取值。</li>
<li><strong>类型</strong>：类框架，实例框架。</li>
<li><strong>层次结构</strong>：子类-subclass of-&gt;父类，示例-instance of-&gt;类。</li>
<li><strong>推理</strong>：继承推理（下层框架继承上层框架的信息），匹配推理（安装条件进行推理）。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA2.png" alt="图2"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA3.png" alt="图3"></p>
<h3 id="1-4-脚本">1.4 脚本</h3>
<p>脚本与框架类似，由一组槽组成，用来表示特定领域内一些事件的发生序列。但脚本表示的知识有明确的时间或因果顺序，因此它描述的是一个<strong>过程</strong>而非静态知识。</p>
<p>脚本的结构化表示包括：进入条件，角色，道具，场景，结果。</p>
<h3 id="1-5-一阶谓词逻辑">1.5 一阶谓词逻辑</h3>
<p>由于语义网络、框架、脚本缺少形式化定义，不同网络之间难以相互操作，且推理过程复杂。因此引入了一阶谓词逻辑。参看<a href="https://lwl1751.github.io/2024/05/15/%E7%9F%A5%E8%AF%86%E8%AE%A1%E7%AE%97/">知识计算</a>。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA4.png" alt="图4"></p>
<h3 id="1-6-描述逻辑">1.6 描述逻辑</h3>
<p>通过<strong>概念类别</strong>来描述物理世界，没有一阶谓词逻辑中变量和谓词的概念，但具有形式化定义。描述逻辑有概念描述、属性、个体三个基础部分组成。</p>
<ul>
<li><strong>概念描述</strong>：表示一类事物。</li>
<li><strong>概念构造器</strong>：用两个概念描述构造出一个新的概念，有交集构造器、并集构造器、否定构造器。</li>
<li><strong>属性</strong>：作用于概念，必须搭配全称量词 $\forall$，或存在量词 $\exists$使用。</li>
<li><strong>个体</strong>：概念示例。</li>
<li><strong>知识库</strong>：包括术语（TBox，描述概念定义、公理），断言（ABox，描述个体知识）两部分。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA5.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA6.png" alt="图6"></p>
<h2 id="二-语义网的知识描述体系">二.语义网的知识描述体系</h2>
<ul>
<li><strong>本质</strong>：以Web数据的内容（即语义）为核心，用机器能够理解和处理的方式链接起来的海量分布式数据库。</li>
<li><strong>特征</strong>：Web上的事物拥有唯一的URI（通用资源标识符），事物之间存在显示链接，事物链接又具有不同的语义类型。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA7.png" alt="图7"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA8.png" alt="图8"></p>
<ul>
<li><strong>XML</strong>：由起始标签、元素内容和结尾标签构成，并且元素具有嵌套结构，同时没有约束嵌套的深度。</li>
<li><strong>RDF</strong>：Resource Description Framework。由于XML只定义了文档结构和数据类型，没有定义数据的语义，机器仍然无法理解文档的内容。为了让应用程序理解数据的语义，定义了RDF。RDF利用Web标识符（URI）来标识事物，并通过指定的属性和相应的值描述资源的性质或资源之间的关系。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA9.png" alt="图9"></p>
<p>注意：RDF并不是一种语言，只是一种书写规范。</p>
<ul>
<li>
<p><strong>RDFs</strong><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA10.png" alt="图10"></p>
</li>
<li>
<p><strong>OWL</strong>: Web Ontology Language，相比于RDFS，添加了更多用于描述类和属性的建模原语，支持更加丰富的语义表达并支持推理。</p>
</li>
<li>
<p><strong>RIF</strong>: Rule Interchange Format，一种不同的规则语言和推理引擎之间的交换格式。</p>
</li>
</ul>
<h2 id="三-参考资料">三. 参考资料</h2>
<p>中国科学院大学陈玉博老师 知识工程 课程课件</p>
]]></content>
      <tags>
        <tag>知识工程</tag>
      </tags>
  </entry>
  <entry>
    <title>高级人工智能复习绪论-机器学习部分</title>
    <url>/2024/06/02/%E9%AB%98%E7%BA%A7%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%8D%E4%B9%A0%E7%BB%AA%E8%AE%BA-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%83%A8%E5%88%86/</url>
    <content><![CDATA[<p>课程复习使用。之前已经学过模式识别与机器学习课程，对这部分内容掌握较好，此处只整理相关考试知识点PPT。<a href="https://lwl1751.github.io/pdf/高级人工智能复习绪论-机器学习部分.pdf">点击查看PPT</a></p>
<p>参考资料：中国科学院大学高级人工智能课程</p>
]]></content>
      <tags>
        <tag>高级人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM训练</title>
    <url>/2024/06/05/LLM%20%E5%A2%9E%E9%87%8F%E9%A2%84%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h2 id="一-DeepSpeed">一.DeepSpeed</h2>
<p>DeepSpeed 是由Mircrosoft 提供的<strong>分布式训练工具</strong>，DeepSpeed Zero（零冗余优化器）是大规模模型训练优化的技术，目的是<strong>减少模型的内存占用</strong>。<strong>Zero将模型参数分成三个部分</strong>：</p>
<ul>
<li>Optimizer States, 优化器在进行梯度更新的时候需要用到的数据</li>
<li>Gradient, 在反向转播过程中产生的数据，其决定参数的更新方向</li>
<li>Model Parameter, 模型参数，在模型训练过程中通过数据“学习”的信息</li>
</ul>
<p><strong>Zero 的级别如下</strong>：</p>
<ul>
<li>Zero-0, 不使用所有类型的分片，仅使用DeepSpeed作为DDP</li>
<li>Zero-1, 分割Optimizer States， 减少4倍内存，通信容量和数据并行性相同</li>
<li>Zero-2, 分割Optimizer States和Gradients，减少8倍内存，通信容量和数据并行性相同</li>
<li>Zero-3, 分割Optimizer States、gradients、Parametes，内存减少与数据并行度呈线性关系。例如，在64个GPU（Nd=64）之间进行拆分将产生64倍的内存缩减。通信量有50%的适度增长</li>
<li>Zero-Infinity, Zero-Infinity是Zero-3的扩展，它允许通过使用 NVMe 固态硬盘扩展 GPU 和 CPU 内存来训练大型模型</li>
</ul>
<h2 id="二-参数设置">二. 参数设置</h2>
<ul>
<li>lr_scheduler_type：学习率变化策略。如[linear, cosine, cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau]
<ul>
<li>linear, 学习率从一个较高的初始值开始，然后随着时间线性地减少到一个较低的值。</li>
<li>cosine, 学习率按照余弦曲线的形状进行周期性调整，这种周期性的起伏有助于模型在不同的训练阶段探索参数空间。</li>
<li>cosine_with_restarts, 这是余弦调整的一种变体，每当学习率达到一个周期的最低点时，会突然重置到最高点，然后再次减少。</li>
<li>polynomial, 学习率按照一个多项式函数减少，通常是一个幂次递减的形式。</li>
<li>constant_with_warmup, 开始时使用较低的学习率“预热”模型，然后切换到一个固定的较高学习率。</li>
<li>inverse_sqrt, 学习率随训练步数的增加按逆平方根递减。</li>
<li>reduce_lr_on_plateau, 当模型的验证性能不再提升时，自动减少学习率。</li>
</ul>
</li>
<li>warmup_steps：warmup步数。学习率经过多少步，增长到指定的数值。</li>
<li>warmup_ratio：用于指定线性warmup 占总训练步骤的比例，如果设置了warmup_steps，将会忽略warmup_ratio。</li>
<li>weight_decay：权重衰减，防止模型过拟合。</li>
<li>optim：优化器。<a href="https://mp.weixin.qq.com/s/nW6PpFsIbc0SwgI3QPKHFg">优化策略梯度下降算法：SGD、MBGD、Momentum、Adam、AdamW</a></li>
<li>lora_rank：lora矩阵的秩。一般设置为8、16、32、64等。</li>
<li>lora_alpha: lora中的缩放参数。一般设为16、32即可。</li>
<li>target_modules: lora训练模块，q_proj、k_proj、v_proj、o_proj、up_proj、down_proj。分别对应自注意力机制中的查询、键、值和输出投影层，以及LoRA特有的上投影和下投影层。</li>
<li>fp16：使用使用fp16混合精度。V100建议开启。</li>
<li>bf16：使用使用bf16混合精度。A100建议开启。</li>
<li>preprocessing_num_workers：数据预处理时的工作进程数量。</li>
<li>block_size：块大小，即输入序列的最大长度。</li>
<li>group_by_length：是否根据输入序列的长度进行分组。</li>
<li>gradient_checkpointing：梯度检查点。</li>
<li>ddp_timeout：ddp超时时间设置，若某些节点在规定时间内没有响应，则训练会报错并中止。</li>
<li>ddp_find_unused_parameters：是否在DDP中寻找未使用的参数。如果模型中存在未被使用的参数，该选项可以帮助检测到，以避免不必要的计算和资源浪费。</li>
<li>evaluation_strategy：训练期间采用的评估策略，[‘no’,‘steps’,‘eppoch’]，[不评估，每个eval_step后评估，每个epoch后评估]</li>
</ul>
<h2 id="三-参考资料">三.参考资料</h2>
<p><a href="https://mp.weixin.qq.com/s/qvhzagFFgNdtb3sSymhAdA">https://mp.weixin.qq.com/s/qvhzagFFgNdtb3sSymhAdA</a></p>
<p><a href="http://t.csdnimg.cn/Z2S9h">http://t.csdnimg.cn/Z2S9h</a></p>
]]></content>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>图的基础知识</title>
    <url>/2024/06/24/%E5%9B%BE%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<pre><code>课程知识复习使用。
</code></pre>
<h2 id="1-基本概念">1.基本概念</h2>
<ul>
<li><strong>图</strong>：一系列的点和对应的连接边。</li>
<li><strong>度数</strong>：顶点v的连接边数目。有向图中, 节点度数分为入度和出度。一个节点度数是其入度和出度的和。</li>
<li><strong>连通图</strong>：对于一个无向图，任意两个顶点之间都存在一条路径，则称之为连通图，否则为非连通图。</li>
<li><strong>最大连通区域</strong>：一个非连图由多个部分组成，其中规模最大的被称为最大连通区域。</li>
<li><strong>强连通图</strong>：对于一个有向图，对于任意一对节点A和B，存在从A到B的有向路径，同时也存在从B到A的一条有向路径，则称为强连通图。</li>
<li><strong>弱连通图</strong>：对于一个有向图，忽略边的方向，这个图在无向图的概念中是连通的，则这个有向图被称为弱连通图。</li>
<li><strong>完全图（团）</strong>：任意两个节点间都连接有边。</li>
<li><strong>二部图</strong>：节点分为两个不相交的集合𝑈和𝑉，每条边都分别连接集合𝑈和𝑉中的一个点。</li>
<li><strong>多重图</strong>：含有平行边或者自环边的图，即图中某两个顶点之间的边数不止一条，又允许顶点通过一条边与本身关联，则该图被称为多重图。</li>
<li><strong>自环图</strong>：无平行边而只存在自环边的图又被称为自环图。</li>
<li><strong>图的表示</strong>：邻接矩阵，邻接表，压缩稀疏表达$（CSR）$。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%9B%BE%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%863.png" alt="图片"></li>
</ul>
<h2 id="2-图的度量">2.图的度量</h2>
<p>对一张图进行度量的四种方式：度数分布，路径长度，聚集系数，连通分量。</p>
<ul>
<li>度数分布：图中度数的概率分布。对于有向图，需要考虑入度分布和出度分布。真实图的度数分布通常近似满足幂律分布，即度数大的节点非常少，度数小的节点占了绝大多数。</li>
<li>路径长度：路径中所包含的边的数目。节点间的距离为它们的最短路径长度。</li>
</ul>
<p>引申概念：<strong>小世界图</strong>：任意两个节点之间均存在较短路径，且节点间的最短路径⻓度与总节点数目不是线性关系，而是对数关系。</p>
<ul>
<li>聚集系数：衡量节点$v_i$ 的$k_i$ 个邻居间的连接紧密程度。计算如下：</li>
</ul>
<p>$$C_{local}(v_{i}) = \frac{2E_i}{k_i(k_i-1)}$$</p>
<p>其中$E_i$ 是$v_i$ 的邻居之间两两连边的数目。度数较大的节点，其聚集系数一般是较小的，而度数较小的节点，其聚集系数一般是较大的。</p>
<ul>
<li>连通分量：无向图的极大连通子图。</li>
</ul>
<h2 id="3-静态图生成模型">3.静态图生成模型</h2>
<p>给定待生成图的节点数 𝑁 和边数 𝑀，静态图生成模型一次性生成整张图。</p>
<h3 id="3-1Erdos-Renyi-模型-E-R-模型">3.1Erdos-Renyi 模型,E-R 模型</h3>
<ul>
<li>定义：𝐺(𝑁, 𝑝)，𝑁为图中节点总数，$p$为任意两个节点之间连边的概率。</li>
<li>生成算法：首先生成$N$ 个节点，对每个节点的除它以外的$N-1$ 个节点，都以概率$p$ 连边。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%9B%BE%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%862.png" alt="图1"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E5%9B%BE%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%861.png" alt="图2"></li>
</ul>
<h3 id="3-2Watts–Strogatz-小世界模型">3.2Watts–Strogatz 小世界模型</h3>
<ul>
<li>$k$-正则图：每个节点都有$k$个邻居的图。</li>
<li>生成算法：首先生成$k$ 正则图，接着对每一条边以概率$p$ 将这条边的其中一个端点移到平均随机选取的节点上。</li>
<li>当$p=0$时，生成图为$k$ 正则图；当$p=1$时，生成图为$E-R$ 图，此时边是随机生成的。</li>
</ul>
<h3 id="3-3Kronecker-模型">3.3Kronecker 模型</h3>
<p>递归的图生成模型，其基本思想是自相似性(self-similarity)，即通过在图的部分结构中模仿其整体结构的特征递归地生成图。递归地将图的整体结构代入到子结构中，在某种程度上模仿了真实社交网络图中社区的生⻓规律。</p>
<h2 id="4-动态图生成模型">4.动态图生成模型</h2>
<p>给定待生成图的节点数$n$或边数$m$，模型建模节点和边逐步加入的过程。</p>
<h3 id="4-1Barabasi–Albert-BA-模型">4.1Barabási–Albert (BA)模型</h3>
<ul>
<li>基本思想：假设图是以节点为中心不断增⻓的，通过不断增加节点来生成图。并且存在优先连接的现象，即一个节点当前 具有的度数越大，新增加的节点就越有可能与它连边。</li>
<li>生成算法：首先生成有$m_0$ 个节点的随机图，接下来每一步生成一个新的节点，由它延伸出$m$ 条边，与之前已有的节点相连。每次连接都按照已有节点当前的度数来分配连边的概率。</li>
</ul>
<h3 id="4-2以边为中心的优先连接模型">4.2以边为中心的优先连接模型</h3>
<p>通过加入新边来实现图规模的增⻓。注意的是，每次边插入可能引入0 个、1 个或 2 个新节点。</p>
<h2 id="5-参考资料">5.参考资料</h2>
<p>中国科学院大学邹磊老师，图数据管理与应用课程课件</p>
]]></content>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>社区发现算法</title>
    <url>/2024/06/25/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<pre><code>课程知识复习使用。
</code></pre>
<p>图中的社区是指一张图中的一些子图。这些子图内部顶点直接紧密相连，而子图内部节点与外部节点之间连接是稀疏的。社区发现算法是需要找到图中所有的社区，可以分为基于层级聚类的方法和基于边介数的方法。</p>
<h2 id="1-基于层级聚类的方法">1. 基于层级聚类的方法</h2>
<ul>
<li>点关联强度：衡量两点间的关联强度。
<ul>
<li>两点间独立路径数：能够连接两点的所有互不相交(没有公共节点)的简单路径总数，即为割点数目。</li>
<li>全路径融合强度：认为节点间的关联强度与所有路径都相关，路径长度越小，强度越大。</li>
</ul>
</li>
<li>算法流程
<ul>
<li>选定并计算关联强度</li>
<li>初始化每个顶点为单个社区</li>
<li>定义两个社区的关联强度为其间<strong>所有点对的关键强度平均值</strong></li>
<li>每次合并两个关联强度最大的点对，合并关系形成层级关系</li>
<li>聚类质量达到一定程度之后不再继续</li>
</ul>
</li>
<li>衡量标准：模块度，是评估社区结果质量高低的度量方法。模块度Q 计算如下：</li>
</ul>
<p>$$Q \propto  \sum_{s\in S} [ 社区s内部的实际边数 - 社区s内部的期望边数 ] $$</p>
<p>模块度取值范围为[-1,1]，实践中，模块度达到0.3到0.7之间就说明划分质量很好。</p>
<p>不足：对度数低的点的社区分配不友好。例如一个顶点如果只有一条边，则这个顶点理应分配在其唯一邻居所在的社区，然后基于层级聚类的方法中，该点同邻居的关联强度低，很容易被排斥在邻居所属社区之外。</p>
<h2 id="2-基于边介数的方法">2. 基于边介数的方法</h2>
<ul>
<li>边介数：对于图上的一条边 $e$ 而言，$e$ 的介数是指图中所有点对的最短路径中，要经$e$ 的路径比例总和。</li>
<li>算法流程：
<ul>
<li>计算所有边的介数</li>
<li>移除介数最高边</li>
<li>重新计算所有边的介数</li>
<li>如果剩余所有边的介数都低于一定阈值则终止，否则回到步骤二</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%951.png" alt="图1"></p>
<h2 id="3-其它社区发现算法：BK-k-clique-k-core">3. 其它社区发现算法：BK,k-clique,k-core</h2>
<ul>
<li>
<p>团（完全图）：任意两个节点间都连接有边。</p>
</li>
<li>
<p>最大团：一个图中顶点数最多的团</p>
</li>
<li>
<p>极大团：加入任何其它顶点都无法在图中构成更大的完全子图的团</p>
</li>
<li>
<p>BK算法求解极大团：<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%952.png" alt="图2"></p>
</li>
<li>
<p>k-clique算法，允许社区重叠，将发现的社区定义为团联。给定一个大于1的正整数k，由一系列k-团(节点数目为k的团)互相连接形成的子图称为k-团联。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%953.png" alt="图3"></p>
</li>
<li>
<p>k-core算法：子图是连通的，且每个节点的度数均不小于k。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%954.png" alt="图4"></p>
</li>
</ul>
<h2 id="4-社区搜索">4. 社区搜索</h2>
<p>社区发现是为了找到图G中所有的社区，然而社区搜索只需找到用户所关心的社区，如找到包含用户输入的查询点/查询点集合的社区。即在图G中找到一个连通子图H，且$f(H)$在所有可能子图的得分函数中值最大。得分函数$f(H)$定义为H中最小的节点度数。</p>
<ul>
<li>
<p>贪心算法<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%955.png" alt="图5"></p>
</li>
<li>
<p>K-Truss算法：K-Truss要求子图H中任意一条边都被包含在至少(k-2)个不同的三角形中。</p>
<ul>
<li>支持度,$sup(e,G)$：包含e的三⻆形数目</li>
<li>子图 Trussness：子图H中所有边的最小支持度</li>
<li>边 Trussness：边e所在所有子图中最大的子图 Trussness</li>
<li>k 分类：图G中所有边 Trussness 为k 的边集合</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%956.png" alt="图6"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%957.png" alt="图7"></p>
<h3 id="5-图划分">5. 图划分</h3>
<p>图的划分是将图切分为多个不相交的子集，每个子集称为一个分割，并希望各个子图的大小要相对均衡。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%958.png" alt="图8"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%E7%AE%97%E6%B3%959.png" alt="图9"></p>
<p>KL 算法最大的问题是可扩展性太差，对于大图考虑所有可能的节点置换的时间复杂性太高。一种改进的算法则是METIS 算法: 通过对基于点边的融合来不断压缩原始图，当原图小到一定程度之后，再进行KL 等图分割算法，最后基于分割结果进行原图恢复。</p>
<h2 id="6-参考资料">6.参考资料</h2>
<p>中国科学院大学邹磊老师，图数据管理与应用课程课件</p>
]]></content>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>Unifying Large Language Models and Knowledge Graphs: A Roadmap</title>
    <url>/2024/07/06/Unifying-Large-Language-Models-and-Knowledge-Graphs-A-Roadmap/</url>
    <content><![CDATA[<blockquote>
<p>类型：文献综述</p>
<p>第一作者：Shirui Pan</p>
<p>作者单位：Griffith University</p>
<p>发表时间：2024/07</p>
<p>发表期刊：IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING</p>
<p>键内容：对 KG-enhanced LLMs, LLM-augmented KGs, Synergized LLMs + KGs 三种框架进行介绍</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs18.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs4.png" alt="图片"></p>
<h2 id="1-background">1. background</h2>
<p>KGs的四种分类：百科全书式知识图谱、常识知识图谱、特定领域知识图谱和多模态知识图谱。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs2.png" alt="图片"></p>
<p>LLM 与 KGs 的优缺点对比：</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs1.png" alt="图片"></p>
<p>其中，KGs 的缺点 Unseen Facts：知识图谱无法有效地对看不见的实体进行建模并表示新的事实知识。此外，知识图谱中丰富的文本信息常被忽略。</p>
<p>LLM 与 KGs 的应用示例：</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs3.png" alt="图片"></p>
<h2 id="2-KG-enhanced-LLMs">2. KG-enhanced LLMs</h2>
<h3 id="2-1-KG-Enhanced-LLM-Pre-Training">2.1 KG-Enhanced LLM Pre-Training</h3>
<blockquote>
<p><strong>2.1.1  Integrating KGs into training objective</strong></p>
</blockquote>
<p>两种方式：</p>
<ul>
<li>在预训练中暴露更多的实体，通过改变词语的掩码概率实现。如GLM中，假定在知识图谱中一定跳数内可以到达的实体是较为重要的实体，并且在预训练期间会给予它们更高的掩码概率。而在SKEP中，通过词语的情感分配不同的掩码概率。</li>
<li>更改训练训练的目标函数。如对ERNIE，目标为tokens到entity的对齐链接，如下图所示。对WKLM，首先用其他相同类型的实体替换文本中的实体，然后将它们输入 LLM，训练目标为区分实体是否已被替换。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs5.png" alt="图片"></p>
<blockquote>
<p><strong>2.1.2 Integrating KGs into LLM inputs</strong></p>
</blockquote>
<p>Colake中提出的集成方法如下图所示，需要注意的是：</p>
<ul>
<li>只有句子中的实体才能访问知识图谱中的三元组信息</li>
<li>输入句子的 tokens 形成了完全图</li>
<li>更多的关注热门实体，而忽视了低频和长尾实体。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs6.png" alt="图片"></p>
<blockquote>
<p><strong>2.1.3 KGs Instruction-tuning</strong></p>
</blockquote>
<p>KG指令微调的目的不是向LLM注入事实知识，而是让LLM更好的理解KG的结构。具体分析见 KG指令微调部分。</p>
<h3 id="2-2-KG-Enhanced-LLM-Inference">2.2 KG-Enhanced LLM Inference</h3>
<p>虽然通过训练确实可以为LLM注入大量的知识，但是这些知识缺乏时效性，且模型训练需要消耗大量资源，因此可以借助KGs 在LLM推理时注入知识。两种方式：</p>
<ul>
<li>RAG，Retrieval-Augmented Knowledge Fusion<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs7.png" alt="图片"></li>
<li>KGs Prompting，设计提示，将结构化的知识图谱转换为文本序列，然后将其作为上下文输入到LLM中。但通常设计提示需要耗费大量人力。</li>
</ul>
<h3 id="2-3-KG-Enhanced-LLM-Interpretability">2.3 KG-Enhanced LLM Interpretability</h3>
<p>LLM 可解释性是指对其内部工作和决策过程的理解和解释。研究人员试图利用知识图谱来提高LLM的可解释性，大致可以分为两类：1）用于语言模型探测的知识图谱，2）用于语言模型分析的知识图谱。</p>
<blockquote>
<p>KGs for LLM Probing，旨在理解 LLM 中存储的知识</p>
</blockquote>
<p>下图为LAMA 使用 KGs 对 LLM 进行知识探测的示例图，首先通过预定义的提示模板将 KG 中的事实转换为完形填空语句，然后使用 LLM 来预测缺失的实体。预测结果用于评估 LLM 中存储的知识。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs8.png" alt="图片"></p>
<p>注意：可以通过优化提示来更准确的评估 LLM 中包含的知识，且研究发现 LLM 对低频/尾部事实知识的掌握较差。</p>
<blockquote>
<p>KGs for LLM Analysis，旨在分析 LLM 中的推理过程，如 LLM 如何生成结果，LLM 的功能和结构如何工作等。</p>
</blockquote>
<p>一种方式是将 LLM 在每个推理步骤中生成的结果都以知识图谱为基础。这样，LLM的推理过程就可以通过从KG中提取图结构来解释，如下所示。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs9.png" alt="图片"></p>
<h2 id="3-LLM-AUGMENTED-KGS">3. LLM-AUGMENTED KGS</h2>
<h3 id="3-1-LLM-Augmented-KG-Embedding">3.1 LLM-Augmented KG Embedding</h3>
<p>知识图嵌入（KGE）旨在将每个实体和关系映射到低维向量空间，这些嵌入包含知识图谱的语义和结构信息。通常有两种方式：1）采用 LLM 通过对实体和关系的文本描述进行编码来丰富KG的表示，2）使用 LLM 将图结构和文本信息同时合并到嵌入空间中。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs10.png" alt="图片"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs11.png" alt="图片"></p>
<h3 id="3-2-LLM-Augmented-KG-Completion">3.2 LLM-Augmented KG Completion</h3>
<p>知识图补全（KGC）旨在推断给定知识图谱中缺失的事实。与KGE类似，传统的KGC方法主要关注KG的结构，而没有考虑广泛的文本信息。然而，LLM 的集成使 KGC 方法能够编码文本或生成事实，以获得更好的 KGC 性能。这些方法根据其使用方式分为两个不同的类别：1）LLM 作为编码器（PaE），2）LLM 作为生成器（PaG）。顾名思义，将 LLM 分别作为 encoder, decoder。</p>
<blockquote>
<p>LLM as Encoders (PaE)</p>
</blockquote>
<p>优点：</p>
<ul>
<li>易于微调，在LLM基础上加上一个预测层，训练时可以冻结LLMs，只需优化预测头</li>
<li>输出可整合，预测输出易于与现有的KGC功能整合，用于不同的KGC任务</li>
</ul>
<p>缺点</p>
<ul>
<li>计算开销大，推理阶段需要为每个候选实体计算分数，计算昂贵</li>
<li>不能泛化到未见过的实体</li>
<li>需要LLMs的表示输出，但无法获取闭源LLM 的表示输出</li>
</ul>
<blockquote>
<p>LLM as Generators (PaG)</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs12.png" alt="图片"></p>
<p>优点：无需微调，能泛化到未见过的实体</p>
<p>缺点：生成的实体可能不在KGs 中，设计有效的提示需要耗费大量人力</p>
<h3 id="3-3-LLM-Augmented-KG-Construction">3.3 LLM-Augmented KG Construction</h3>
<p>知识图谱构建通常包含以下几个步骤：实体抽取，共指消解，关系抽取。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs13.png" alt="图片"></p>
<h3 id="3-4-LLM-Augmented-KG-to-Text-Generation">3.4 LLM-Augmented KG-to-Text Generation</h3>
<p>旨在生成准确一致地描述输入知识图谱信息的高质量文本，但收集大量图文并行数据具有挑战性且成本高昂，导致训练不足和生成质量差。有两种方法：1）利用 LLM 的知识，如下图所示，线性遍历知识图谱作为输入，用 LLM 获取文本输出，但存在问题是 LLM 的无监督预训练目标不一定与知识图谱到文本生成的任务很好地契合，2）构建大规模弱监督知识图谱文本语料库。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs14.png" alt="图片"></p>
<h3 id="3-5-LLM-Augmented-KG-Question-Answering">3.5 LLM-Augmented KG Question Answering</h3>
<p>知识图谱问答（KGQA）旨在根据知识图谱中存储的结构化事实找到自然语言问题的答案。可以将LLM作为实体/关系的抽取器，或是答案推理器，即根据检索到的事实进行推理。</p>
<h2 id="4-SYNERGIZED-LLMS-KGS">4. SYNERGIZED LLMS +KGS</h2>
<p>主要可以分为协同知识表示，协同推理两部分。</p>
<h3 id="4-1-Synergized-Knowledge-Representation">4.1 Synergized Knowledge Representation</h3>
<p>文本语料库和知识图谱都蕴藏着海量的知识。然而，文本语料库中的知识通常是隐式的、非结构化的，而知识图谱中的知识是显性的、结构化的。协同知识表示旨在设计一个协同模型，可以有效地表示来自 LLM 和 KG 的知识。协同模型可以更好地理解两个来源的知识，使其对许多下游任务有价值。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs15.png" alt="图片"></p>
<h3 id="4-2-Synergized-Reasoning">4.2 Synergized Reasoning</h3>
<p>可以分为 LLM-KG 融合推理（使用两个独立的 LLM 和 KG 编码器来处理文本和 KG 输入），LLM 代理推理（使用 LLM 作为与 KG 交互进行推理的 代理）两部分。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs16.png" alt="图片"></p>
<h2 id="5-FUTURE-DIRECTIONS-AND-MILESTONES">5. FUTURE DIRECTIONS AND MILESTONES</h2>
<ul>
<li>KGs for Hallucination Detection in LLMs</li>
<li>KGs for Editing Knowledge in LLMs，尽管 LLM 能够存储海量的现实世界知识，但他们无法随着现实世界情况的变化而快速更新其内部知识。有研究人员提出了一些研究工作来编辑 LLM 的知识，而无需重新训练整个模型。然而，此类解决方案仍然存在性能不佳或计算开销过大的问题。现有研究还表明，编辑单个事实会对其他相关知识产生连锁反应。因此，有必要开发一种更高效、更有效的方法来编辑 LLM 知识。最近，研究人员尝试利用知识图谱来有效地编辑 LLM 的知识。</li>
<li>KGs for Black-Box LLMs Knowledge Injection</li>
<li>Multi-Modal LLMs for KGs</li>
<li>LLMs for Understanding KG Structure，基于纯文本数据训练的 LLM 并非旨在理解知识图等结构化数据。因此， LLM 可能无法完全掌握或理解知识图谱结构传达的信息。一种直接的方法是将结构化数据线性化为 LLM 可以理解的句子。然而，知识图谱的规模使得不可能将整个知识图谱线性化为输入。此外，线性化过程可能会丢失知识图谱中的一些底层信息。因此，有必要开发能够直接理解KG结构并对其进行推理的LLM。</li>
<li>Synergized LLMs and KGs for Birectional Reasoning</li>
</ul>
<h2 id="6-CONCLUSION">6. CONCLUSION</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/unifying_llm_kgs17.png" alt="图片"></p>
<h2 id="7-参考论文">7. 参考论文</h2>
<p>Pan S, Luo L, Wang Y, et al. Unifying large language models and knowledge graphs: A roadmap[J]. IEEE Transactions on Knowledge and Data Engineering, 2024.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding</title>
    <url>/2024/07/07/Knowledge-Prompting-in-Pre-trained-Language-Model-for-Natural-Language-Understanding/</url>
    <content><![CDATA[<pre><code>第一作者：Jianing Wang
作者单位：华东师范大学
发表时间：2022/10
发表期刊：EMNLP2022
关键内容：提出了一种基于知识提示的 PLM 架构：KP-PLM。首先根据每个句子上下文的知识库构建一个知识子图，再设计多个连续提示规则，将知识子图转化为自然语言提示，对模型进行微调。并提出了两个知识感知的自监督任务：prompt relevance inspection and masked prompt modeling。前者旨在让PLM 学习多个知识提示的语义相关性，后者预测 prompt 中的屏蔽实体。
</code></pre>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM1.png" alt="图1"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM3.png" alt="图2"></p>
<h2 id="1-引言">1. 引言</h2>
<p>增强PLM知识的方法有以下几种：</p>
<ul>
<li>knowledge-masking-based methods</li>
<li>knowledge-fusion-based methods</li>
<li>graph-learning-based methods</li>
</ul>
<p>但是这些方法存在以下不足：</p>
<ul>
<li>一些方法通过堆叠复杂的模块来修改现有PLM的内部结构，增加了模型的计算成本</li>
<li>一些方法从知识库中引入冗余和不相关的知识（知识噪声），可能会降低模型的性能</li>
</ul>
<p>因此，作者提出了一种基于知识提示的 PLM 架构：KP-PLM，可以有效的解决以上两个不足，如图1、图2所示。</p>
<h2 id="2-KP-PLM-模型框架">2.KP-PLM 模型框架</h2>
<h3 id="2-1-Knowledge-Prompting">2.1 Knowledge Prompting</h3>
<p>知识提示旨在为每个句子构建知识子图，然后将事实知识转化为自然语言提示。下图分两个步骤说明了该过程。</p>
<ul>
<li>上下文知识子图构建。从每个句子中抽取中所有的实体，选择主题实体，根据该主题实体构建一个2-hop子图，再对该子图进行pruning。pruning规则：若尾实体未出现在该句子的抽取实体集合中，删除该路径。</li>
<li>Continuous prompting mapping.根据子图中的一阶和二阶结构信息设计了三种类型的提示映射规则。其中，[K]、[/K]为知识触发标记，[Pi]为伪标记。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM2.png" alt="图3"></p>
<h3 id="2-2-Model-Architecture">2.2 Model Architecture</h3>
<p>主要是对 Input Embedding Layer 进行介绍。嵌入分为 token embeddings, position embeddings and segmentation embeddings 三种类型。</p>
<ul>
<li>token embeddings，the trigger and pseudo tokens are randomly initialized while others are initialized by looking up the PLM embedding table.</li>
<li>position embeddings，为了减轻 prompt 顺序对模型性能的影响，所有 prompt 的起始位置编码相同</li>
<li>segmentation embeddings，同样的，对所有 prompt 使用相同的分段 id，并为其起始标记设置相同的位置 id。</li>
</ul>
<h3 id="2-3-Self-supervised-Pre-training-Tasks">2.3 Self-supervised Pre-training Tasks</h3>
<ul>
<li>Prompt Relevance Inspection (PRI)，由于提示可以将事实知识注入 PLM，因此它们应该在语义上与上下文序列相关。因此，作者设计了一种提示相关性检查任务，增强了模型学习提示与句子相关性的能力。对于训练语料库中的每个句子 S，生成一组相关提示集 PS。并构造一个“正”提示集 Pos。 此外，对于每个句子 S，可以从 PS 中随机选择一个提示，并从该提示中随机选择一个实体，替换为 KB 中的任意实体。最后将更新的提示标记为否定提示，并添加到“负”提示集 Neg。利用这两个提示集进行训练。</li>
<li>Masked Prompt Modeling (MPM). 与传统的实体预测相比，有两点不同：一是搜索空间不同（不是在整个 PLM 词汇库上进行搜索，而是在上下文知识子图中进行搜索），二是训练数据集的构建（给定一个训练语料库，对于每个句子 S，生成一组相关提示集 PS，在任意选择的提示 P ∈ PS 中使用 [MASK] 标记随机屏蔽实体（主题实体除外），构成训练集用于模型训练）</li>
</ul>
<h2 id="3-实验">3. 实验</h2>
<ul>
<li>基座模型：RoBERTa-base</li>
<li>数据集：使用的知识库是WikiData5M，其中包括3,085,345个实体和822个关系类型。</li>
<li>对比PLM选择：ERNIE-THU, KnowBERT, KEPLER, CoLAKE, K-Adapter, DKPLM。</li>
<li>实验设置：Knowledge-aware Tasks(使用实体类型预测、关系提取和知识探测三个任务来评估模型性能)，Performance on General NLU Tasks，Knowledge Prompting Study，Ablation Study</li>
</ul>
<h3 id="3-1-实验结果">3.1 实验结果</h3>
<ul>
<li>
<p>知识感知–实体类型预测，根据给定一个句子和相应的实体提及，预测实体的类型。模型变体 KP-PLMKNOW ，它通过直接将知识提示与每个示例连接起来，在微调阶段使用知识提示。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM4.png" alt="图4"></p>
</li>
<li>
<p>知识感知–关系抽取，根据相应的文本对两个给定实体之间的关系进行分类。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM8.png" alt="图5"></p>
</li>
<li>
<p>知识感知–知识探测，旨在评估 PLM 是否拥有零样本环境下的内在事实知识。</p>
</li>
<li>
<p>Performance on General NLU Tasks，KP-PLM 与 RoBERTa-base 在多个自然理解任务中的对比，<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM5.png" alt="图6"></p>
</li>
<li>
<p>不同知识增强PLM 架构的对比<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM6.png" alt="图7"></p>
</li>
<li>
<p>消融实验<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM7.png" alt="图8"></p>
</li>
</ul>
<h2 id="4-结论">4.结论</h2>
<p>In this paper, we presented a seminal knowledge prompting paradigm, based on which a novel knowledge-prompting-based PLM framework KPPLM was proposed. Experimental results validate the effectiveness of knowledge prompting in boosting the performance of PLMs.</p>
<h2 id="5-参考文献">5.参考文献</h2>
<p>Wang J, Huang W, Shi Q, et al. Knowledge prompting in pre-trained language model for natural language understanding[J]. arXiv preprint arXiv:2210.08536, 2022.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Ontology-enhanced Prompt-tuning for Few-shot Learning</title>
    <url>/2024/07/08/Ontology-enhanced-Prompt-tuning-for-Few-shot-Learning/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Hongbin Ye, Ningyu Zhang</p>
<p>作者单位：浙江大学</p>
<p>发表时间：2022/4</p>
<p>发表期刊：Proceedings of the ACM Web Conference 2022</p>
<p>关键内容：探索如何更好的使用预训练语言模型进行 few-shot learning 知识注入，并提出本体增强提示调优（OntoPrompt）。如何优化：将KG的本体知识转化为文本用于模型训练，并修改注意力机制以减小知识噪声，最后，对本体嵌入向量也进行参数训练。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt1.png" alt="图1"></p>
<h2 id="1-INTRODUCTION">1. INTRODUCTION</h2>
<p>few-shot learning 中存在的三个问题：</p>
<ul>
<li>知识缺失。由于外部知识库的不完整性，可能无法检索与任务相关的事实，从而无法为下游任务提供有用的信息。</li>
<li>知识噪声。先前的研究已经证明，并非所有的知识都对下游任务有益，不加区别地注入知识可能会导致负面的知识注入，从而不利于下游任务的性能。</li>
<li>知识异质性。下游任务的语言语料库与注入的知识有很大不同，导致两种独立的向量表示，即注入知识不能很好的泛化到下游任务中。</li>
</ul>
<p>针对这三个问题，作者提出了对应的解决方案：</p>
<ul>
<li>利用预定义的模板将基于外部知识图谱的本体知识转换为文本作为提示。</li>
<li>通过跨度敏感的知识注入，来选择信息知识，从而减轻噪声注入。</li>
<li>通过集体训练算法来共同优化 下游任务的语言语料库与注入知识 的表示。</li>
</ul>
<p>最后在关系提取、事件提取和知识图补全这三个任务进行测试，取得了不错的效果。</p>
<h2 id="2-METHODOLOGY">2. METHODOLOGY</h2>
<h3 id="2-1-Ontology-Transformation">2.1 Ontology Transformation</h3>
<p>针对下游任务的差异，对不同的任务利用不同的本体来源进行本体转换。首先从外部知识图中提取每个实例的本体，然后将这些本体转换为原始文本作为辅助提示，如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt2.png" alt="图2"></p>
<h3 id="2-2-Span-sensitive-Knowledge-Injection">2.2 Span-sensitive Knowledge Injection</h3>
<p>给定输入文本 $X_{in} = [x_1, x_2, …, x_L]$ 和 $L$ 个标记，作者使用可视化的矩阵来限制对输入文本的知识注入，即。在语言模型架构中，在softmax层之前添加了具​​有自注意力权重的注意力掩码矩阵。因此，作者将注意力掩模矩阵M修改如下：</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt4.png" alt="图3"></p>
<p>其中，$x$为输入文本，$x^o$为本体文本。当 $M_{ij} = -\infty$ 时，表示$token_i$ 被阻止关注$token_j$，当$M_{ij} = 0$ 时，表示$token_i$ 可以关注$token_j$。$p_k$ 表示输入文本中提到的跨度（例如，关系提取和知识图补全中的实体、触发器或事件提取中的参数）的位置。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt3.png" alt="图4"></p>
<h3 id="2-3-Collective-Training">2.3 Collective Training</h3>
<p>首先，利用真实的词嵌入初始化本体标记，并在固定的语言模型下优化这些本体标记。其次，优化模型的所有参数，包括语言模型和本体标记。</p>
<h2 id="3-EXPERIMENTS">3. EXPERIMENTS</h2>
<ul>
<li>
<p>数据集<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt5.png" alt="图5"></p>
</li>
<li>
<p>关系抽取<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt6.png" alt="图6"></p>
</li>
<li>
<p>知识图谱构建<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPromp7.png" alt="图7"></p>
</li>
<li>
<p>事件提取 + 消融实验<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt8.png" alt="图8"></p>
</li>
<li>
<p>Case Study<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt9.png" alt="图9"></p>
</li>
</ul>
<h2 id="4-参考文献">4. 参考文献</h2>
<p>Ye H, Zhang N, Deng S, et al. Ontology-enhanced Prompt-tuning for Few-shot Learning[C]//Proceedings of the ACM Web Conference 2022. 2022: 778-787.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models</title>
    <url>/2024/07/20/ChatKBQA-A-Generate-then-Retrieve-Framework-for-Knowledge-Base-Question-Answering-with-Fine-tuned-Large-Language-Models/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Haoran Luo, Haihong E</p>
<p>作者单位：北京邮电大学</p>
<p>发表时间：2024/5</p>
<p>发表期刊：ACL 2024</p>
<p>关键内容：将知识图谱与大模型结合。亮点：通常是先利用知识图谱进行检索，检索结果作为prompt的一部分输入到模型中。而ChatKBQA是先利用LLM生成逻辑形式，再通过无监督方法对实体和关系进行检索替换，从而提升答案的准确率。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_3.png" alt="图1"></p>
<h2 id="1-引言">1.引言</h2>
<p>KBQA(Knowledge Base Question Answering) 主要有两个核心问题：知识检索、语义解析。</p>
<ul>
<li>知识检索(IR)：根据知识库中的问题定位最相关的实体、关系或三元组</li>
<li>语义解析(SP)：将问题从非结构化自然语言转换为结构化逻辑形式，再将其转换为可执行的图查询，以获得精确的答案和可解释的路径</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_1.png" alt="图2"><br>
retrieve-then-generate KBQA 框架：先对问题文本进行实体和关系的检索，再进行语义解析。它的不足在于：</p>
<ul>
<li>
<p>检索效率低下</p>
<p>Traditional methods first identify the span of candidate entities and then do entity retrieval and relation retrieval. Since the structure of natural language questions differs from KB facts, most approaches require training dedicated models for extraction and linking inefficiently.</p>
</li>
<li>
<p>不正确的检索结果会导致错误的语义解析</p>
<p>Previous methods have utilized retrieved triples also as input of reference to the seq2seq model along with the original question. However, since the retrieved triples are not always accurate, they adversely impact semantic parsing outcomes. Additionally, if there are numerous retrieved triples, the seq2seq model requires a much longer context length.</p>
</li>
<li>
<p>多处理步骤使KBQA成为一项极其复杂的任务</p>
<p>Previous work decomposed the KBQA task into multiple sub-tasks, forming a complex pipeline, which made reproduction and migration challenging.</p>
</li>
</ul>
<h2 id="2-方法">2. 方法</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_2.png" alt="图3"></p>
<p>无监督检索，它的原理是：首先计算实体与其它实体的相似度，保留前 k 个及概率大于阈值 t 的相似实体，对实体进行替换，再保留前 k 个及概率大于阈值 t 的相似实体。对关系的检索替换操作类似。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_4.png" alt="图4"></p>
<h2 id="3-实验">3.实验</h2>
<p>从以下几个角度开展实验：</p>
<ul>
<li>
<p>Does ChatKBQA outperform other KBQA methods?</p>
<p>在WebQSP与CWQ两个数据集上进行测试，将ChatKBQA模型与其它模型的效果进行对比。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_5.png" alt="图5"></p>
</li>
<li>
<p>Does the main components of ChatKBQA work?</p>
<p>消融实验，如下图(a)(b)所示<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_6.png" alt="图6"></p>
</li>
<li>
<p>Why use Generate-then-Retrieve method instead of Retrieve-then-Generate method?<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_7.png" alt="图7"><br>
Topk指标：前k个预测结果中有一个为正确即为正确。结果分析：检索得到的信息会有错误的干扰信息和增加指令的Max Token，这导致LLMs对原始问题的灾难性遗忘，增加了训练的难度。</p>
</li>
<li>
<p>Why use fine-tuned open-source LLMs instead of calling ChatGPT or training traditional T5 models?</p>
<p>结果如上图©所示。</p>
</li>
<li>
<p>Does Generate-then-Retrieve method improve retrieval efficiency?</p>
<p>为了体现&quot;Generate-then-Retrieve&quot;方法对检索效率的提升，将逻辑形式生成后的实体检索( ER )和关系检索( RR )与传统的自然语言问句检索( NL-R )进行比较。我们将检索的效率定义为待检索文本与检索答案集合之间的平均相似度范围[0,1]，通过不同的检索模型对其进行评分。结果如上图(d)所示。</p>
</li>
<li>
<p>Does ChatKBQA has plug-and-play characteristics?<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_8.png" alt="图8"><br>
说明ChatKBQA框架可以适用于多种 基座模型+微调方法+检索方法 的组合搭配。</p>
</li>
</ul>
<h2 id="4-参考文献">4. 参考文献</h2>
<p>Luo H, Tang Z, Peng S, et al. Chatkbqa: A generate-then-retrieve framework for knowledge base question answering with fine-tuned large language models[J]. arXiv preprint arXiv:2310.08975, 2023.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization</title>
    <url>/2024/07/26/Agent-Pro-Learning-to-Evolve-via-Policy-Level-Reflection-and-Optimization/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Wenqi Zhang</p>
<p>作者单位：浙江大学</p>
<p>发表时间：2024/6</p>
<p>发表期刊：ACL 2024</p>
<p>关键内容：在拥有不完整的环境信息、多智能体共存的环境下，实现Agent与环境的动态交互学习。它将策略学习转化为prompt 优化过程。环境返回为世界模型和行为策略（将二者放在prompt中生成自我信念和世界信念），在训练中不断优化世界模型和行为策略、自我信念和世界信念（放在prompt中生成行动）。在二十一点、德州扑克两个游戏中进行测试。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro1.png" alt="图1"></p>
<h2 id="1-引言">1.引言</h2>
<p>LLM-based agent 存在的两个常见问题：</p>
<ul>
<li>假设agent能拥有环境的所有信息，但多数情况下不能满足这个条件。此外更多的依赖与提示工程。</li>
<li>agent 无法从与环境的交互中获得进步</li>
</ul>
<p>Agent-pro：在拥有不完整的环境信息、多智能体共存的环境下，实现与环境的动态交互学习。它将策略学习转化为prompt 优化过程，在21点、德州扑克两个游戏中进行测试。</p>
<h2 id="2-方法">2.方法</h2>
<p>self-belief：agent 的自我认知。对于德州扑克来说，Agent-Pro对自己的手牌、计划和潜在风险的理解构成了它的自我信念。</p>
<p>social-belief：agent 对环境的认知。对于德州扑克来说，Agent-Pro对对手的猜想构成了它的世界信念。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro2.png" alt="图2"></p>
<h3 id="2-1-Belief-aware-Decision-Making-Process">2.1 Belief-aware Decision-Making Process</h3>
<p>K个玩家：$op_1,op_2,\dots,our,\dots,op_K$。第$t$轮时，当前agent拥有的私人信息 $s_t$，公共信息 $o_t$，行动 $a_t$，玩家的自我信念与世界信念 $\xi$。所有玩家的行动$a^{op_1}_t,a^{op_2}_t,…,a^{op_K}_t$，前t轮的轨迹：</p>
<p>$$\begin{array}{r}\mathcal{H}<em>{0: t}=\left{\left(s</em>{0}, o_{0}, a_{0}^{o p_{1}}, a_{0}, a_{0}^{o p_{2}}, \ldots, a_{0}^{o p_{K}}\right),\right. \\vdots \\left.\left(s_{t}, a_{t}, a_{t}^{o p_{1}}, a_{t}, a_{t}^{o p_{2}}, \ldots, a_{t}^{o p_{K}}\right)\right}\end{array}$$</p>
<p>在当前行为策略的指导下，Agent-Pro根据自我信念和世界信念生成行动。</p>
<h3 id="2-2-Policy-Level-Reflection">2.2 Policy-Level Reflection</h3>
<p>对于失败的局面，检查自我信念和世界信念的合理性，并反思失败的原因。有以下四个指标：</p>
<pre><code>Correctness: Whether its beliefs about itself , the game , and its opponents align with the final results.
Consistency: Whether each belief and action is self -contradictory.
Rationality: Whether the beliefs accurately reflect the underlying intentions behind the opponents.
Reasons: Reflect on why it lost to its opponents , which beliefs are problematic , and what the underlying reasons are.
</code></pre>
<p>为了校准不正确的信念，AgentPro将这些对自身和外部世界的反思和分析总结为具体的指令：行为策略和世界建模，其中前者代表了该任务的广义行为策略，后者代表了它对自身和外部世界的理解和猜想。以德州扑克为例，Agent-Pro总结了以下内容：</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro3.png" alt="图3"></p>
<h3 id="2-3-DFS-based-Policy-Evolution">2.3 DFS-based Policy Evolution</h3>
<p>基于DFS的策略迭代：先进行策略评估，再进行策略搜索。</p>
<h2 id="3-实验">3.实验</h2>
<h3 id="3-1-二十一点">3.1 二十一点</h3>
<ul>
<li>不同模型不同策略对比。Compared to ReAct and Reflexion, Agent-Pro is more robust. We find that this is due to the effective behavioral guidelines summarized by policy-level reflection. For instance, Agent-Pro summarizes two instructions as follows: 1-When you have achieved a relatively stable total hand value, choosing not to take risks is a good decision. 2-Analyze the dealer cards in World-belief,…, excessive risk-taking can lead to unfavorable outcomes… These self-summarized instructions can alert Agent-Pro to the risks associated with action Hit, thus making more rational decisions.<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro4.png" alt="图4"></li>
<li>Agent-Pro is More Rational than Baselines. 其中，Hit为拿牌的意思，代表Agent是否愿意冒险。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro5.png" alt="图5"></li>
</ul>
<h3 id="3-2-德州扑克">3.2 德州扑克</h3>
<ul>
<li>各种基于 LLM 的Agent与其他三个玩家（DQN、DMC、GPT-3.5）的最终筹码数。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro6.png" alt="图6"></li>
<li>基于 不同LLM 的Agent 的风格分析<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro7.png" alt="图7"></li>
<li>Agent-Pro策略的演变。
<ul>
<li>Fold，弃牌</li>
<li>Raise，加注</li>
<li>PreFlop（翻牌前）：每局游戏的第一个阶段。在这个阶段，每位玩家会先拿到两张底牌（也叫暗牌），然后进行第一轮下</li>
<li>Flop（翻牌）：游戏的第二个阶段。在这个阶段，桌面上会发出三张公共牌（即大家都可以看到并使用的牌），然后进行第二轮下注。</li>
<li>Turn（转牌）：游戏的第三个阶段。在这个阶段，桌面上会再发出一张公共牌，使得公共牌的总数变为四张，然后进行第三轮下注。</li>
<li>River（河牌）：游戏的第四个阶段。在这个阶段，桌面上会发出最后一张公共牌，使得公共牌的总数变为五张，然后进行最后一轮下注。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro8.png" alt="图8"></li>
</ul>
</li>
<li>不同牌面下Agent-pro的性能分析<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/Agent-Pro9.png" alt="图9"></li>
</ul>
<h2 id="4-参考文献">4.参考文献</h2>
<p>Zhang W, Tang K, Wu H, et al. Agent-pro: Learning to evolve via policy-level reflection and optimization[J]. arXiv preprint arXiv:2402.17574, 2024.</p>
]]></content>
      <tags>
        <tag>强化学习</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>REASONING ON GRAPHS: FAITHFUL AND INTERPRETABLE LARGE LANGUAGE MODEL REASONING</title>
    <url>/2024/07/26/REASONING-ON-GRAPHS-FAITHFUL-AND-INTERPRETABLE-LARGE-LANGUAGE-MODEL-REASONING/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Linhao Luo</p>
<p>作者单位：Monash University</p>
<p>发表时间：2024/2</p>
<p>发表期刊：ICLR 2024</p>
<p>关键内容：先利用LLM 生成与问题回答 有关的关系路径，再到KGs中进行检索（实体来自问题句子，关系来自LLM生成的关系），再利用检索到的推理路径进行模型推理。亮点在于：知识图谱中的实体会动态变化，而实体间的关系是较为稳定的，通过对KG中关系路径的检索得到可靠的知识作为模型的上下文输入。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG1.png" alt="图1"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG6.png" alt="图2"></p>
<h2 id="1-引言">1.引言</h2>
<p>先前使用 KGs 和 LLMs 进行推理的方法有以下两种：</p>
<ul>
<li>语义解析，通过 LLMs 将问题转化为逻辑查询，在KGs中进行查询，与<a href="https://lwl1751.github.io/2024/07/20/ChatKBQA-A-Generate-then-Retrieve-Framework-for-Knowledge-Base-Question-Answering-with-Fine-tuned-Large-Language-Models/">ChatKBQA</a>类似。这种方法的缺点在于生成的逻辑查询不一定是可执行的。（因此，ChatKBQA会对逻辑查询中的实体/关系进行无监督检索替换，以确保逻辑查询的可执行性）</li>
<li>RAG。将KGs作为LLM推理的事实知识库，没有充分利用KGs结构信息。For instance, as shown in Figure 1, a relation path, which is a sequence of relations, “child of -&gt; has son” can be used to obtain answers to the question “Who is the brother of Justin Bieber?”.</li>
</ul>
<p>因此，不同于ChatKBQA中利用LLM生成逻辑查询，RoG是先通过LLM生成关系路径，再对KGs进行检索，最后将检索得到的推理路径作为上下文输入到LLM中进行推理。</p>
<h2 id="2-实验">2.实验</h2>
<ul>
<li>
<p>RoG与其它模型比较，其中，type 为LLM的模型并没有进行微调，同时为zero shot inference。RoG的基座模型为 LLaMA2-Chat-7B，微调数据集为WebQSP、CWQ、Freebase。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG2.png" alt="图3"></p>
</li>
<li>
<p>消融实验。w/ random plan，从KGs中随机检索推理路径，并将其输入到推理模块中；w/ vote reasoning，采用多数投票，从检索到的推理路径中选择前5个答案。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG4.png" alt="图4"></p>
<ul>
<li>
<p>探究超参数——关系路径数量的影响。关系路径数量越多，召回率越高，但也引入更多噪声，精确度下降。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG3.png" alt="图5"></p>
</li>
<li>
<p>PLUG-AND-PLAY ROG PLANNING MODULE 的验证<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG5.png" alt="图6"></p>
</li>
</ul>
<h2 id="3-参考文献">3. 参考文献</h2>
<p>Luo L, Li Y F, Haffari G, et al. Reasoning on graphs: Faithful and interpretable large language model reasoning[J]. arXiv preprint arXiv:2310.01061, 2023.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research</title>
    <url>/2024/07/26/HeCiX-Integrating-Knowledge-Graphs-and-Large-Language-Models-for-Biomedical-Research/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Prerana Sanjay Kulkarni</p>
<p>作者单位：PES University</p>
<p>发表时间：2024/7</p>
<p>发表期刊：</p>
<p>关键内容：利用Hetionet 和 ClinicalTrials.gov两个数据库构建了一个生物医药知识图谱，并将KGs与LLMs联合起来。首先利用LLM获取逻辑查询语句，在KGs中进行查询，将查询结果作为上下文输入进行模型推理，并利用LangChain实现流程化。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/HeCiX2.png" alt="图1"></p>
<h2 id="1-引言">1.引言</h2>
<p>Hetionet 数据库包含了关于疾病、基因和解剖学的大量领域知识，但缺乏关于先前进行的临床试验和实验的充分信息。相反，<a href="http://ClinicalTrials.gov">ClinicalTrials.gov</a> 数据库提供了大量关于临床试验和全球范围内进行的实验的信息，但它对疾病本身提供了有限的见解。对基础生物学和临床试验结果的理解之间的这种差异阻碍了有效的药物开发。因此作者构建了HeCiX KG。</p>
<p>HeCiX-KG 只包含六种疾病，namely Vitiligo, Atopic Dermatitis, Alopecia Areata, melanoma, Epilepsy, and Hypothyroidism. 由6,509个节点和14,377条边组成。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/HeCiX1.png" alt="图2"></p>
<p>注意这个方法与<a href="https://lwl1751.github.io/2024/07/26/REASONING-ON-GRAPHS-FAITHFUL-AND-INTERPRETABLE-LARGE-LANGUAGE-MODEL-REASONING/">RoG</a>的区别，RoG中首先要求LLM返回有助于解决问题的关系路径，在KGs上搜索到的检索结果作为模型推理输入，旨在让模型给出正确的回复。在HeCiX的pipeline中，检索结果作为输入，只是要求模型给出对结果的解释。</p>
<h2 id="2-实验">2.实验</h2>
<p>使用RAGAS 框架来评估模型的性能。该框架计算了几个关键指标：</p>
<ul>
<li>faithfulness, 生成答案相对于问题和上下文的事实一致性。</li>
<li>answer relevance, 生成答案与问题的相关程度。</li>
<li>context precision, 检索到的上下文信息与问题的相关性。</li>
<li>context recall, 检索器获取回答问题所需的所有相关信息的能力。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/HeCiX3.png" alt="图3"></p>
<h2 id="3-参考文献">3. 参考文献</h2>
<p>Kulkarni P S, Jain M, Sheshanarayana D, et al. HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research[J]. arXiv preprint arXiv:2407.14030, 2024.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models</title>
    <url>/2024/07/26/UniMEL-A-Unified-Framework-for-Multimodal-Entity-Linkingwith-Large-Language-Models/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Liu Qi, Yongyi He</p>
<p>作者单位：中国科学技术大学</p>
<p>发表时间：2024/7</p>
<p>发表期刊：CIKM 2024</p>
<p>关键内容：提出了实现多模态实体链接的一种框架UniMEL，该框架包含四个部分，LLMs-based
Entity Augmentation, MLLMs-based Mention Augmentation, Retrieval
Augmentation, Multi-choice
Selection。对于entity，认为多模态知识库中的实体描述包含较多不相关的信息，用LLM对实体描述进行精简化。对mention，充分利用图片信息和MLLM的通用能力，将mention作为MLLM的输入，以得到恰当的嵌入表示。再对候选实体集合进行粗粒度筛选，只保留与mention相似度最高的前K个实体集合，再利用LLM进行细粒度的实体单项选择。</p>
</blockquote>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL2.png" alt="图1">
<figcaption aria-hidden="true">图1</figcaption>
</figure>
<h2 id="引言">1.引言</h2>
<p>实体链接：可以分为两步，一是候选生成，二是候选排序。候选排序可以分为两步（粗粒度与细粒度）：首先是候选选择，即进行粗粒度过滤（TF-IDF，word2vect等）；二是候选实体重排序，通过衡量文本和候选实体的相关性(encoder)来排序。</p>
<p>多模态实体链接（MEL）旨在将多模态上下文中的歧义提及(ambiguous
mentions)与多模态知识库中的引用实体(entity)链接起来。</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL1.png" alt="图2">
<figcaption aria-hidden="true">图2</figcaption>
</figure>
<p>在multimodal knowledge base
(MMKB)中，每个实体的静态属性（如职业、姓名）被封装在文本描述中。相反，与文本描述相比，MMKB
中的实体图像往往表现出更广泛的动态属性（如衣服颜色）。如果采用动态属性作为文本实体的描述符，通常会导致在识别实体时误导性地关注这些属性，如下图所示。</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL4.png" alt="图3">
<figcaption aria-hidden="true">图3</figcaption>
</figure>
<p>MEL 难点：</p>
<ul>
<li>Redundant entity descriptions. Generally, the description of the
entity is usually too long, leading to a hard focus on valid information
in the process of disambiguation. In this case, it is necessary to pay
more attention to entities and mentions related parts.</li>
<li>Lack of important semantic information in mentions. the mention
textual context is a truncated piece extracted directly from documents,
lacking pivotal semantic information and sufficient evidence for linking
the mention to a specific entity effectively. How to utilize images from
mentions to supplement their lacking semantic information becomes
essential.</li>
<li>Combining the visual context with the textual context effectively is
challenging.</li>
<li>LLMs lack domain-specific knowledge. Although LLMs demonstrate
powerful general capabilities, they do not directly excel in specific
domain tasks (e.g., MEL tasks).</li>
</ul>
<p>UniMEL 提出的解决方案：</p>
<ul>
<li>LLMs-based Entity Augmentation。对于实体来说，过于详细和冗余的描述给
MEL
任务带来了极大的挑战。通过利用法学硕士的总结能力，可以获得简短而精确的新描述。</li>
<li>MLLMs-based Mention
Augmentation。对于提及，与提及相关的图像和上下文信息被处理为 MLLM
的输入，以便提取图像与其上下文之间更深层的语义关系。这种方法可以保持原始图像的完整性（即无需裁剪或编码），从而充分利用未更改的原始数据。考虑到用于预训练
MLLM 的广泛语料库，该方法有可能丰富与提及相关的具体信息。</li>
</ul>
<h2 id="方法">2.方法</h2>
<ul>
<li>LLMs-based Entity Augmentation <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL5.png" alt="图4"></li>
<li>MLLMs-based Mention Augmentation <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL6.png" alt="图5"></li>
<li>Retrieval Augmentation,
对相似度最高的K个实体进行降序排序（以避免多项选择的顺序对结果的影响），得到候选实体集合</li>
<li>Multi-choice Selection <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL7.png" alt="图6"></li>
</ul>
<p>UniMEL 采用 LLaMA3-8B 和 LLaVA-1.6 作为默认的 LLM 和 MLLM。</p>
<h2 id="实验">3.实验</h2>
<ul>
<li>实验数据集 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL8.png" alt="图7"></li>
<li>在不同模型、不同数据集、不同K值下的测试结果 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL9.png" alt="图8"></li>
<li>与SOTA模型比较，探究K值对结果的影响。Table 4
中候选实体数量为设为16，是为了与SOTA模型GEMEL进行比较。候选实体的数量越少，越容易选择链接实体。
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL10.png" alt="图9"></li>
<li>不同嵌入模型的比较 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL11.png" alt="图10"></li>
<li>不同基座 LLM 的比较 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL12.png" alt="图11"></li>
<li>消融实验 <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL13.png" alt="图12"></li>
<li>Case Study <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/UniMEL14.png" alt="图13"></li>
</ul>
<h2 id="参考文献">4.参考文献</h2>
<p>Qi L, Yongyi H, Defu L, et al. UniMEL: A Unified Framework for
Multimodal Entity Linking with Large Language Models[J]. arXiv preprint
arXiv:2407.16160, 2024.</p>
]]></content>
      <tags>
        <tag>多模态</tag>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning</title>
    <url>/2024/07/26/Self-Distillation-Bridges-Distribution-Gap-in-Language-Model-Fine-Tuning/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Zhaorui Yang</p>
<p>作者单位：浙江大学</p>
<p>发表时间：2024/5</p>
<p>发表期刊：ACL 2024</p>
<p>关键内容：Self-Distillation Fine-Tuning
(SDFT)，用模型生成的数据来对模型进行训练，弥补数据集与LLM分布的不同而导致微调带来的灾难性遗忘的问题。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/SDFT1.png" alt="图1"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/SDFT2.png" alt="图2"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/SDFT3.png" alt="图3"></p>
<p>参考文献：Yang Z, Liu Q, Pang T, et al. Self-Distillation Bridges
Distribution Gap in Language Model Fine-Tuning[J]. arXiv preprint
arXiv:2402.13669, 2024.</p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Large Language Models for Generative Information Extraction: A Survey</title>
    <url>/2024/07/27/Large-Language-Models-for-Generative-Information-Extraction-A-Survey/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Derong Xu, Wei Chen</p>
<p>作者单位：中国科学技术大学</p>
<p>发表时间：2024/6</p>
<p>发表期刊：</p>
<p>关键内容：介绍三种典型的IE技术：NER，RE，EE的代表性模型，并比较它们的性能；比较用于LLM的不同的IE技术；介绍不同领域的IE工作；提出潜在研究方向；对常用LLM和数据集进行总结。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey1.png" alt="图1"></p>
<h2 id="1-LLMs-for-Different-Information-Extraction-Tasks">1.LLMs for Different Information Extraction Tasks</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey2.png" alt="图2"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey3.png" alt="图3"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey4.png" alt="图4"></p>
<h2 id="2-Techniques-of-LLMs-for-Generative-IE">2.Techniques of LLMs for Generative IE</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey8.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey5.png" alt="图6"></p>
<ul>
<li>prompt design:
<ul>
<li>Question Answer (QA). 将prompt 修改为QA格式。</li>
</ul>
</li>
<li>zero-shot
<ul>
<li>cross-domain learning. Learn and capture the inter-task dependencies of known tasks and generalizing them to unseen tasks and domains. 对不同领域的泛化。</li>
<li>cross-type learning，对不同任务类型的泛化，如由某一事件类型泛化到另一事件类型。</li>
</ul>
</li>
<li>Constrained Decoding Generation。
<ul>
<li>起因：LLMs are primarily designed for generating free-form text and may not perform well on structured prediction tasks where only a limited set of outputs are valid. To address this challenge, researchers have explored the use of Constrained generation for better decoding.</li>
<li>含义：Constrained decoding generation in autoregressive LLMs refers to the process of generating text while adhering to specific constraints or rules</li>
</ul>
</li>
</ul>
<h2 id="3-Applications-on-Specific-Domains">3.Applications on Specific Domains</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey6.png" alt="图7"></p>
<h2 id="4-Future-Directions">4.Future Directions</h2>
<ul>
<li>Universal IE</li>
<li>Low-Resource IE</li>
<li>Prompt Design for IE。CoT, interactive prompt design 等技术。</li>
<li>Open IE, 开放信息抽取。Open IE 中抽取的谓语和实体并不是针对特定的领域，也并没有提前定义好实体类别。更一般的，开放域信息抽取的目的是抽取出所有输入的文本中的形如 &lt;主语，谓语，宾语&gt; 的三元组。开放域信息抽取对于知识的构建至关重要，可以减少人工标注的成本和时间。</li>
</ul>
<h2 id="5-Benchmarks-Backbones">5.Benchmarks &amp; Backbones</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/IE-survey7.png" alt="图8"></p>
<h2 id="6-参考文献">6.参考文献</h2>
<p>Xu D, Chen W, Peng W, et al. Large language models for generative information extraction: A survey[J]. arXiv preprint arXiv:2312.17617, 2023.</p>
<p><a href="https://cloud.tencent.com/developer/article/1817527">https://cloud.tencent.com/developer/article/1817527</a></p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
        <tag>信息抽取</tag>
      </tags>
  </entry>
  <entry>
    <title>TnT-LLM: Text Mining at Scale with Large Language Models</title>
    <url>/2024/07/27/TnT-LLM-Text-Mining-at-Scale-with-Large-Language-Models/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Mengting Wan, Tara Safavi</p>
<p>作者单位：Microsoft Corporation</p>
<p>发表时间：2024/3</p>
<p>发表期刊：</p>
<p>关键内容：借助LLM实现分类生成、文本分类的自动化。分类生成包括两个阶段：首先对每篇文档进行总结，然后设计三类prompt（类似于SGD，根据总结生成类别、评估并提出修改建议、检查输出类别的格式与质量）。文本分类是指使用LLM对文档进行分类，得到训练数据集。最后，使用该数据集对轻量级分类器进行训练，实现模型蒸馏。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TnT-LLM1.png" alt="图1"></p>
<h2 id="1-引言">1. 引言</h2>
<p>文本挖掘中两个相互关联的核心任务：</p>
<ul>
<li>分类生成：查找和组织一组描述语料库各个方面的结构化规范标签</li>
<li>文本分类：对语料库中的文本实例进行标记。</li>
</ul>
<p>传统的方法有 human-in-the-loop framework 和 无监督机器学习法。</p>
<ul>
<li>human-in-the-loop framework：首先人工确定好类别标签，在小部分语料库样本上收集人工注释，训练机器学习文本分类模型。虽然这种人机交互方法提供了较高的可解释性，但它们面临着重大的可扩展性挑战：它们需要领域专业知识并仔细考虑标签的粒度、覆盖范围和一致性，并且手动注释非常耗时且成本高昂，而且也容易出现错误和偏见。此外，必须针对每个下游用例（例如，情感分析、意图检测等）重复该过程，泛化性能较差。</li>
<li>无监督机器学习法：旨在通过文本聚类、主题建模和关键词挖掘等机器学习技术来解决文本分类问题。首先以无监督或半监督的方式将语料库样本组织成簇，再通过描述学习到的簇来导出标签分类法，从而得到分类标签和分类结果。这种方法可以具有很强的扩展性和泛化性，但以可解释且一致的方式描述文本集群是极具挑战性的。</li>
</ul>
<p>因此，作者提出了TnT-LLM，一种基于LLM的 自动化 分类生成和文本分类框架，且不需要对数据进行标注，具有较高的解释性。它被分为了两个阶段：LLM-powered taxonomy generation，LLM-augmented text classification。在第一阶段，对语料库进行小规模代表性子集采样，并受SGD迭代方式的启发，执行零样本多阶段分类法生成。在第二阶段，采样更大的数据集，并利用LLM和第一阶段生成的类别对每个实例进行分类。然后，这些 LLM 标签被视为“伪标签”，用于训练轻量级文本分类器。训练完成后，部署轻量级分类器对整个语料库进行离线标记，也可以用于在线实时分类。</p>
<h2 id="2-LLM-powered-taxonomy-generation">2. LLM-powered taxonomy generation</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TnT-LLM2.png" alt="图2"></p>
<p>Stage 1: Summarization. we first generate concise and informative summaries of each document in the sample. Specifically, we prompt an LLM to summarize each document by providing a short blurb about the intended use-case for the summary (e.g., intent detection) and a target summary length (e.g., 20 words). This stage helps reduce the size and variability of the input documents while also extracting the aspects of the document most relevant to the use-case.</p>
<p>Stage 2: Taxonomy Creation, Update, and Review. We next create and refine a label taxonomy using the summaries from the previous stage. Similar to SGD, we divide the summaries into equal-sized minibatches. We then process these minibatches with three types of zero-shot LLM reasoning prompts in sequence. The first, an initial generation prompt, takes the first minibatch and produces an initial label taxonomy as output. The second, a taxonomy update prompt, iteratively updates the intermediate label taxonomy with new minibatches, performing three main tasks in each step: 1) evaluating the given taxonomy on the new data; 2) identifying issues and suggestions based on the evaluation; and 3) modifying the taxonomy accordingly. Finally, after the taxonomy has been updated a specified number of times, we apply a review prompt that checks the formatting and quality of the output taxonomy, of which the output is regarded as the final taxonomy output by Stage 1.</p>
<p>评估指标：Taxonomy Coverage, Label Accuracy, Relevance to Use-case Instruction</p>
<h2 id="3-LLM-Augmented-Text-Classification">3. LLM-Augmented Text Classification</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/TnT-LLM3.png" alt="图3"></p>
<p>we prompt an LLM to infer the primary label (as a multiclass classification task) and all applicable labels (as a multilabel classification task) on a “medium-to-large” scale corpus sample that covers the range of labels in the taxonomy, creating a representative training dataset that can be used to build a lightweight classifier, such as a Logistic Regression model or a Multilayer Perceptron classifier.</p>
<h2 id="4-未来研究方向">4. 未来研究方向</h2>
<ul>
<li>结合LLM与embedding-based methods，以提升分类生成任务性能。</li>
<li>该框架主要用于会话领域，计划扩展到其他领域。</li>
<li>在处理数据时，需考虑隐私和道德问题。</li>
</ul>
<h2 id="5-参考文献">5. 参考文献</h2>
<p>Wan M, Safavi T, Jauhar S K, et al. TnT-LLM: Text Mining at Scale with Large Language Models[J]. arXiv preprint arXiv:2403.12173, 2024.</p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding the planning of LLM agents: A survey</title>
    <url>/2024/07/27/Understanding-the-planning-of-LLM-agents-A-survey/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Xu Huang</p>
<p>作者单位：中国科学技术大学</p>
<p>发表时间：2024/2</p>
<p>发表期刊：</p>
<p>关键内容：对LLM agentd 的 planning 进行分类：task decomposition, multi-plan selection, external module-aided planning, reflection and refinement, memory-augmented planning。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/agent_planning2.png" alt="图1"></p>
<h2 id="1-Introduction">1. Introduction</h2>
<p>Agent 的定义：Autonomous agents have been recognized as intelligent entities capable of accomplishing specific tasks, via perceiving the environment, planning, and executing actions.</p>
<p>规划(planning)：生成一系列行动的过程：</p>
<p>$$p=\left(a_{0}, a_{1}, \cdots, a_{t}\right)=\operatorname{plan}(E, g ; \Theta, \mathcal{P})$$</p>
<p>其中，$a$未所采取的行动，$E$为环境，$g$为目标任务，$\Theta$为LLM参数，$P$为prompt。</p>
<h2 id="2-Taxonomy">2. Taxonomy</h2>
<ul>
<li>Task Decomposition. 将任务分解为多个子任务。
<ul>
<li>decomposition-first method
<ul>
<li>子任务与原始任务之间的关联性更强，降低任务遗忘和幻觉的风险</li>
<li>容错率更低，因为子任务一开始就被确定好，需要额外的调整机制，否则某个步骤中的一个错误会导致任务失败</li>
</ul>
</li>
<li>Interleaved Decomposition Methods
<ul>
<li>容错率更高，根据环境动态调整分解</li>
<li>对于复杂任务，过长的轨迹可能会导致LLM产生幻觉，在后续的子任务和子规划中偏离最初的目标</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/agent_planing1.png" alt="图2"></p>
<ul>
<li>Multi-plan Selection. This kind of method focuses on leading the LLM to “think” more, generating various alternative plans for a task. Then a task-related search algorithm is employed to select one plan to execute. 即为一个任务生成多种规划，再搜索选择其一，面临资源和探索的trade-off。</li>
<li>External Planner-Aided Planning. This methodology is crafted to employ an external planner to elevate the planning procedure, aiming to address the issues of efficiency and infeasibility of generated plans, while the LLM mainly plays the role in formalizing the tasks. 即调用外部工具辅助生成规划。</li>
<li>Reflection and Refinement. It encourages LLM to reflect on failures and then refine the plan. 强化学习思想类似，对先前的规划进行反思及优化。</li>
<li>Memory-augmented Planning. 增加外部记忆模块，可以通过RAG、Embodied Memory（对模型进行微调）等技术增加模型的规划能力。</li>
</ul>
<h2 id="3-参考文献">3. 参考文献</h2>
<p>Huang X, Liu W, Chen X, et al. Understanding the planning of LLM agents: A survey[J]. arXiv preprint arXiv:2402.02716, 2024.</p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus</title>
    <url>/2024/07/28/IEPile-Unearthing-Large-Scale-Schema-Based-Information-Extraction-Corpus/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation</title>
    <url>/2024/07/28/UHGEval-Benchmarking-the-Hallucination-of-Chinese-Large-Language-Models-via-Unconstrained-Generation/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning</title>
    <url>/2024/07/28/Fine-Tuning-Large-Vision-Language-Models-as-Decision-Making-Agents-via-Reinforcement-Learning/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods </title>
    <url>/2024/07/28/Survey-on-Large-Language-Model-Enhanced-Reinforcement-Learning-Concept-Taxonomy-and-Methods/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</title>
    <url>/2024/07/30/Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Large language models as commonsense knowledge for large-scale task planning</title>
    <url>/2024/07/30/Large-language-models-as-commonsense-knowledge-for-large-scale-task-planning/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Tree of Thoughts: Deliberate Problem Solving with Large Language Models</title>
    <url>/2024/07/30/Tree-of-Thoughts-Deliberate-Problem-Solving-with-Large-Language-Models/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>基于知识图谱的大模型推理增强</title>
    <url>/2024/08/01/%E5%9F%BA%E4%BA%8E%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E5%A2%9E%E5%BC%BA/</url>
    <content><![CDATA[<blockquote>
<p>图数据课程报告</p>
</blockquote>
<h2 id="摘要">摘要</h2>
<p>大模型（Large language model, LLM）凭借其强大的涌现能力，在AI for Science、电商和生药等多个领域得到了广泛应用。然而，大模型存在幻觉、知识隐式存储等问题，如何增强其推理能力成为当前的热点研究之一。本文回顾了利用知识图谱增强LLM推理能力的相关研究，首先介绍了常见的LLM推理增强的方法，其次介绍了多种利用知识图谱增强LLM推理能力的方法，并介绍相关应用，最后提出了一些有前景的研究方向，为相关领域的研究人员提供全面的参考。</p>
<h2 id="一-引言">一. 引言</h2>
<p>作为自然语言领域的一个重要分支，KG通过存储结构化的符号知识，增加知识的可解释性，在知识推理和知识融合等领域扮演着关键角色。然而，KG缺乏自然语言理解的能力，且对事实知识的泛化性较弱。相比之下，ChatGPT、Llama、ChatGLM等LLM基于海量数据进行预训练得到，不仅存储了大量数值化知识，还具备了强大的自然语言理解和生成能力，从而克服了KG在上述两个方面的不足。同时，这些LLM的出现也极大地降低了情感分析、文本分类等传统NLP任务的复杂度，使得研究焦点转向文档问答、语音识别等下游任务。</p>
<p>尽管LLM取得了显著成就，但其内在的限制与挑战依然不容忽视。闭源LLM的黑盒特性导致推理过程不透明，难以对模型结构及参数直接进行干预和优化。同时，庞大的参数量引发了幻觉现象，即模型在生成文本时可能产生合理但不准确或无关的输出，严重影响了推理的稳定性和准确性。此外，在面对输入上下文中的歧义、知识冲突等问题时，即使具备相关知识，LLM仍可能表现出推理能力的不足，尤其是在需要复杂多步骤推理或基于事实组合进行推断的场景中。例如，LLM在处理逆转诅咒等逻辑陷阱时显得力不从心，无法准确回答基于已有知识构建的逆向问题[1]。为了克服LLM的这些局限性，研究者们不断探索新的方法以增强其推理能力。尽管few shot learning、Chain-of-Thought（CoT）等策略在一定程度上提升了模型的推理表现，但它们往往无法从根本上解决LLM在知识整合、复杂关系推理等方面的不足。因此，将知识图谱引入LLM推理过程，成为了一个备受关注的研究热点。</p>
<p>利用知识图谱增强LLM推理主要可以归结为两大类方法：语义解析与检索增强。语义解析方法通过LLM将NLP问题转化为可在KG上执行逻辑查询的语句（如SPARQL），从而直接在KG中检索答案。而检索增强方法（RAG）则侧重于从知识图谱中检索相关三元组作为知识上下文，再作为LLM输入的一部分进行推理。</p>
<p>在这篇文章中，我们主要介绍基于知识图谱的大模型推理增强的研究进展，探讨不同方法的原理、优势与挑战，并展望未来的研究方向。</p>
<h2 id="二-LLM推理增强">二. LLM推理增强</h2>
<p>LLM推理增强方法可以分为四类：工具调用、检索增强、多模型决策、优化推理路径。首先，工具调用可分为两类，一类是外部工具辅助LLM的推理过程，如ChatGPT化学助手集成了通用、分子及化学反应工具[7]，另一类是LLM仅起到转义作用，推理过程由外部工具完成。RAG是指在知识库中检索相关信息，作为上下文输入模型，增强推理的上下文相关性。多模型决策机制通过集成多个智能体的优势，实现推理能力的互补与提升。推理路径优化则专注于改进推理决策，包括前向推理、后向推理、归纳-演绎推理等。以上这四类并不是完全正交的，它们可以相互叠加应用，同时，知识图谱作为知识组织的强大工具，能够与各策略深度融合，进一步提升推理效能。</p>
<p>接下来，我们介绍了提升LLM推理能力的常见技术：</p>
<ul>
<li>零样本学习（Zero shot learning）：在没有任何示例的情况下推理生成的答案。研究发现，在prompt中添加”Let’s think step by step”可以显著提高LLM的推理能力。</li>
<li>少样本学习（few shot learning）：在prompt中增加少量示例，尤其是负例（模型尚未掌握正确答案的示例），来提升模型的推理精度。负例的引入有助于模型学习新知识，相较于冗余的正例，其对推理能力的提升更为显著。</li>
<li>CoT：不同于简单增加辅助信息，CoT方法强调在推理过程中嵌入中间步骤，引导模型逐步解析问题。这种做法不仅使推理过程透明化，便于发现并纠正错误，还显著增强了模型的推理深度和准确性。</li>
</ul>
<h2 id="三-知识图谱增强LLM推理">三. 知识图谱增强LLM推理</h2>
<p>few-shot learning 中存在知识缺失、噪声引入、知识异质性这三大挑战。首先，知识缺失源于外部知识库的不完整性，导致与特定任务相关的关键信息可能无法被检索到，从而无法为下游任务提供有用的信息。其次，并非所有的知识都对下游任务有益，不加区别地注入知识可能会导致负面的知识注入，从而引入知识噪声。最后，下游任务的语言语料库与注入的知识可能会有很大不同，导致两种独立的向量表示，即注入知识不能很好的泛化到下游任务中。为应对这些挑战，研究人员提出了OntoPrompt，包含了三个应对措施。一是采用预定义的模板技术，将基于外部KG的本体知识转换为prompt，如图1所示。二是通过修改注意力机制来筛选注入知识，从而减轻噪声。三是利用集体训练算法，同时优化下游任务的语言语料库与注入知识的嵌入表示，促进两者在向量空间中的融合与协同，增强知识的泛化能力。[2]尽管这些方法在一定程度上实现了KG与LLM的融合，但仍侧重于文本知识与嵌入优化，未能充分挖掘和利用KG中丰富的结构信息。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/OntoPrompt2.png" alt="图1 OntoPrompt的模板定义"></p>
<p>为了降低模型的推理成本、减少噪声注入，并充分利用KG中的结构信息，KP-PLM 首先根据每个句子的上下文，从相关知识库中构建了一个经过剪枝的知识子图。然后设计多个连续提示规则，将知识子图转化为提示（prompt），以增强模型的自然语言理解与推理能力。知识提示（句子转换为提示）的详细过程如图2所示。通过这种方式，KP-PLM 能够在保留关键信息的同时，显著减少在大规模知识图谱中检索的不必要开销，并降低噪声。[3]然而，该方法仅保留了 2-hop 内的相关节点，可能会忽略那些位于更远距离但同样重要的关联信息。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/KP-PLM2.png" alt="图2 KP-PLM的知识提示过程"></p>
<p>以上两种方法都是基于检索增强的方法。然而，ChatKBQA认为，RAG框架存在以下三个挑战：首先，检索效率低下，不同的KG需要采用不同的检索方法，且需要重新训练。其次，不正确的检索结果会导致错误的推理结果。最后，对于多处理步骤，使用 RAG 方法会非常复杂且易出错。ChatKBQA 采用了语义解析的方法，首先利用 LLM 生成逻辑形式，为了避免逻辑形式在KG中无法检索的情况，再通过无监督方法对实体和关系进行检索替换，从而提升推理性能。其框架如图3所示。ChatKBQA 具有灵活性（可适用于不同的基座模型和检索器）和即插即用性，并在 KBQA（Knowledge Graph Question Answering） 上实现了 SOTA 性能。[4]然而，它非常依赖于 LLM 生成的逻辑形式的准确性，无监督方法的检索替换也可能导致问题偏移，从而得到不符合要求的答案。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/ChatKBQA_3.png" alt="图3 ChatKBQA框架图"></p>
<p>不同于ChatKBQA中利用LLM直接生成逻辑查询，RoG创新性地引入了规划-检索-推理框架，如图4所示。它首先通过LLM生成关系路径，再对KG进行检索（实体来自问题句子，关系来自LLM生成），再利用检索到的推理路径进行模型推理。该方法的独特之处在于融合了语义解析和RAG的优势，但利用LLM生成的不是逻辑语句，而是关系路径。这一转变是由于KG中的实体会不断更新变化，而关系结构相对稳定。通过训练LLM掌握关系路径的推理技巧，使得RoG模型展现出了更加高效与鲁棒的性能，实验也证实了RoG 在 KG 推理任务上的SOTA性能。[5]</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/RoG1.png" alt="图4 RoG框架图"></p>
<p>与此同时，多模态知识图谱也引起了广泛的研究兴趣。UniMEL 旨在解决多模态上下文中的歧义提及（ambiguous mentions）与多模态知识图谱中的引用实体（entity）的链接问题。针对mention，充分利用图片信息和多模态语言模型（MLLM）的通用能力，将mention作为 MLLM 的输入，以获得恰当的嵌入表示。针对实体，UniMEL 认为多模态知识图谱中的实体描述包含大量不相关的信息，因此使用LLM对实体描述进行精简。 [6]通过这种方式，UniMEL 实现了较强的多模态实体链接性能。然而，该方法仅利用了多模态知识图谱中的文本和图片信息，未利用其结构信息，希望未来有更多的研究能够探索这一方面。</p>
<h2 id="四-应用">四. 应用</h2>
<p>HeCiX是知识图谱在增强模型推理领域的一个典型应用，它解决了基础生物学与临床试验数据之间的鸿沟问题。Hetionet 数据库包含了关于疾病、基因和解剖学的大量领域知识，但缺乏关于先前进行的临床试验和实验的充分信息。相反，<a href="http://ClinicalTrials.gov">ClinicalTrials.gov</a> 数据库提供了大量关于临床试验和全球范围内进行的实验的信息，但它对疾病本身提供了有限的见解。因此，研究者基于这两个数据库构建了 HeCiX-KG 知识图谱，并利用知识图谱增强模型推理，用于解决现实问题，其流程如图 5 所示。该方法融合了语义解析和 RAG 方法，首先利用 LLM 获取逻辑查询语句，随后在知识图谱中进行查询，最后将查询结果作为上下文输入到 LLM 中进行推理。[7]</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/HeCiX2.png" alt="图5 HeCiX 流程图"></p>
<h2 id="五-未来的研究方向">五. 未来的研究方向</h2>
<p>利用KG增加模型推理的透明性和可解释性。由于KG具有天然的结构化信息和语义关系，在未来的研究中，可以进一步探索如何更好地利用KG中的结构信息来增强大模型的可解释性。例如，通过可视化KG中的推理路径和节点关系，使得推理过程更加直观和易于理解。</p>
<p>多模态知识图谱。当前对多模态知识图谱的研究还不充分，通过大模型强大的生成能力，可以将多模态数据融合到知识图谱中，从而增强知识图谱的表达能力和推理能力。与此同时，多模态知识图谱还可以为大模型提供更加丰富和多样化的训练数据，进一步提升模型的推理性能。</p>
<p>强化学习和知识图谱融合。强化学习既可以减少LLM对标注数据的依赖，也可以帮助模型在复杂的推理任务中进行规划和决策，提高模型的整体推理性能。例如，在知识图谱问答系统中，RL 可以帮助模型在多步推理过程中选择最优路径，从而获得更准确和全面的答案。</p>
<p>动态更新和自适应能力。由于LLM知识的更新较为复杂，通过知识图谱的动态更新来保持模型知识的最新状态是一个有效的方法。在未来的研究中，可以探索使LLM能够根据KG的动态变化，自动进行prompt调整和优化的机制。</p>
<h2 id="六-总结">六. 总结</h2>
<p>本文介绍了 few-shot learning 和CoT等常见的 LLM 推理增强方法，然后详细探讨了多种利用KG增强 LLM 推理能力的方法，并以 HeCiX 作为示例应用进行了介绍。最后，分析并提出了未来潜在的研究方向。我们希望这项调查能够对未来的研究工作提供指导帮助。</p>
<h2 id="七-参考文献">七. 参考文献</h2>
<p>[1] Berglund L, Tong M, Kaufmann M, et al. The reversal curse: Llms trained on&quot; a is b&quot; fail to learn&quot; b is a&quot;[J]. arXiv preprint arXiv:2309.12288, 2023.</p>
<p>[2] Ye H, Zhang N, Deng S, et al. Ontology-enhanced Prompt-tuning for Few-shot Learning[C]//Proceedings of the ACM Web Conference 2022. 2022: 778-787.</p>
<p>[3] Wang J, Huang W, Shi Q, et al. Knowledge prompting in pre-trained language model for natural language understanding[J]. arXiv preprint arXiv:2210.08536, 2022.</p>
<p>[4] Luo H, Tang Z, Peng S, et al. Chatkbqa: A generate-then-retrieve framework for knowledge base question answering with fine-tuned large language models[J]. arXiv preprint arXiv:2310.08975, 2023.</p>
<p>[5] Luo L, Li Y F, Haffari G, et al. Reasoning on graphs: Faithful and interpretable large language model reasoning[J]. arXiv preprint arXiv:2310.01061, 2023.</p>
<p>[6] Kulkarni P S, Jain M, Sheshanarayana D, et al. HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research[J]. arXiv preprint arXiv:2407.14030, 2024.</p>
<p>[7] M. Bran A, Cox S, Schilter O, et al. Augmenting large language models with chemistry tools[J]. Nature Machine Intelligence, 2024: 1-11.</p>
]]></content>
      <tags>
        <tag>知识图谱</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>Agent Lumos: Unified and Modular Training for Open-Source Language Agents</title>
    <url>/2024/09/05/Agent-Lumos-Unified-and-Modular-Training-for-Open-Source-Language-Agents/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents</title>
    <url>/2024/09/05/Agent-Q-Advanced-Reasoning-and-Learning-for-Autonomous-AI-Agents/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>AgentTuning: Enabling Generalized Agent Abilities for LLMs</title>
    <url>/2024/09/05/AgentTuning-Enabling-Generalized-Agent-Abilities-for-LLMs/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</title>
    <url>/2024/09/05/AgentVerse-Facilitating-Multi-Agent-Collaboration-and-Exploring-Emergent-Behaviors/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Agents: An Open-source Framework for Autonomous Language Agents</title>
    <url>/2024/09/05/Agents-An-Open-source-Framework-for-Autonomous-Language-Agents/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning</title>
    <url>/2024/09/05/AutoAct-Automatic-Agent-Learning-from-Scratch-for-QA-via-Self-Planning/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents</title>
    <url>/2024/09/05/BOLAA-Benchmarking-and-Orchestrating-LLM-augmented-Autonomous-Agents/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>CAMEL: Communicative Agents for &quot;Mind&quot; Exploration of Large Language Model Society</title>
    <url>/2024/09/05/CAMEL-Communicative-Agents-for-Mind-Exploration-of-Large-Language-Model-Society/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models</title>
    <url>/2024/09/05/Chameleon-Plug-and-Play-Compositional-Reasoning-with-Large-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Enabling Large Language Models to Generate Text with Citations</title>
    <url>/2024/09/05/Enabling-Large-Language-Models-to-Generate-Text-with-Citations/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>FireAct: Toward Language Agent Fine-tuning</title>
    <url>/2024/09/05/FireAct-Toward-Language-Agent-Fine-tuning/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>From Text to Insight: Large Language Models for Materials Science Data Extraction</title>
    <url>/2024/09/05/From-Text-to-Insight-Large-Language-Models-for-Materials-Science-Data-Extraction/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Schilling-Wilhelmi M, Ríos-García M</p>
<p>作者单位：Friedrich Schiller University Jena, Institute of Carbon Science and Technology (INCAR)</p>
<p>发表时间：2024/7</p>
<p>发表期刊：</p>
<p>关键内容：对材料科学中基于LLM的结构化数据抽取进行了全面的综述，综合了当前的知识并概述了未来的发展方向。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/from_text_to_insight1.png" alt="图1"></p>
<p>Dealing with finite context: 处理文本长度，因为上下文窗口长度有限。</p>
<p>Beyond text: 除文本外其它类型数据。</p>
<h2 id="1-Overview-of-the-working-principles-of-LLMs">1. Overview of the working principles of LLMs</h2>
<p>对于结构化数据提取任务，温度值为0的工作通常是最好的，因为这将导致具有最相关信息的确定性输出。</p>
<h2 id="2-Structured-data-extraction-workflow">2. Structured data extraction workflow</h2>
<p>“A simple example of a system prompt for the data extraction task can be: “You are a material expert assistant and your task is to extract certain information from a given text fragment. If no information is provided for some variables, return NULL”.”</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/from_text_to_insight3.png" alt="图2"></p>
<h2 id="3-参考文献">3. 参考文献</h2>
<p>Schilling-Wilhelmi M, Ríos-García M, Shabih S, et al. From Text to Insight: Large Language Models for Materials Science Data Extraction[J]. arXiv preprint arXiv:2407.16867, 2024.</p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Large Language Models Cannot Self-Correct Reasoning Yet</title>
    <url>/2024/09/05/Large-Language-Models-Cannot-Self-Correct-Reasoning-Yet/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>ReAct: Synergizing Reasoning and Acting in Language Models</title>
    <url>/2024/09/05/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Fine-Grained Human Feedback Gives Better Rewards for Language Model Training</title>
    <url>/2024/09/05/Fine-Grained-Human-Feedback-Gives-Better-Rewards-for-Language-Model-Training/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models</title>
    <url>/2024/09/05/ReWOO-Decoupling-Reasoning-from-Observations-for-Efficient-Augmented-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Reflexion: Language Agents with Verbal Reinforcement Learning</title>
    <url>/2024/09/05/Reflexion-Language-Agents-with-Verbal-Reinforcement-Learning/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
    <url>/2024/09/05/Self-Consistency-Improves-Chain-of-Thought-Reasoning-in-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Structured information extraction from scientific text with large language models</title>
    <url>/2024/09/05/Structured-information-extraction-from-scientific-text-with-large-language-models/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：John Dagdelen</p>
<p>作者单位：Lawrence Berkeley National Laboratory</p>
<p>发表时间：2024/2</p>
<p>发表期刊：Nature Communications</p>
<p>关键内容：针对材料领域，使用少量数据对模型进行微调，完成命名实体识别和关系抽取任务。关键是定义了输出格式。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE1.png" alt="图1"></p>
<h2 id="1-引言">1.引言</h2>
<p>启发：根据不同任务定义了不同的Schema、Completion format。此外，可以参照它们所使用的数据量。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE2.png" alt="图2"></p>
<ul>
<li>Doping: identify host materials, dopants, and potentially additional related information from text passages (sentences).</li>
<li>MOFs: identify chemical formulae, applications, guest species, and further descriptions of MOF materials from text (materials science abstracts).</li>
<li>General Materials: identify inorganic materials, their formulae, acronyms, applications, phase labels, and other descriptive information from text (materials science abstracts).</li>
</ul>
<h2 id="2-实验结果">2.实验结果</h2>
<p>Schema 框架：<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE7.png" alt="图7"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE8.png" alt="图8"></p>
<p>数据标注：Human-in-the-loop annotation，先利用少量样本进行训练，得到中间模型，使用中间模型对一部分数据进行标注，人工校准，得到的这部分数据又可以用于模型训练，重复这个过程。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE5.png" alt="图5"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE6.png" alt="图6"></p>
<p>测试集：</p>
<ul>
<li>掺杂数据集：训练集由162篇摘要组成，包含413个相关句子；测试集包含232句（77 relevant by regex）。</li>
<li>一般材料数据集：训练集由约650个条目组成，使用10%的随机样本进行验证，重复了五次。</li>
<li>金属有机框架数据集：训练集由507篇摘要组成，使用重复随机拆分进行评估。</li>
</ul>
<p>实验结果：第一张图为精确匹配的结果，即target与output中的实体取值完全一致时才判对，但由于LLM的总结能力，output中的实体取值与target不一定一致，即使它们表达的是同一个意思。第二张为人工评估的结果。<br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE3.png" alt="图3"><br>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/NERRE4.png" alt="图4"></p>
<p>prompt + output示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Instruction: <span class="string">&quot;Your current task is to extract data from materials science research paper abstracts. Here is the JSON schema you MUST use. Only output the extracted data in this schema. Do not fill in any information that is not explicitly in the abstract. If you don’t know something from the context, just leave that spot blank (don’t guess!) Make a list of JSON objects. One for each individual material in the abstract. What is a material? A material is a chemical compound such as ’titania’, ’SiO2’, or ’graphene’. A material is NOT a device (e.g. ’valve-regulated lead/acid battery’. That would be an application). For composite materials, make one entry for each part of the composite and put the fact it’s a composite (and what composite) as one element in the description.&quot;</span> </span><br><span class="line"></span><br><span class="line">SCHEMA: [ </span><br><span class="line">  &#123; <span class="string">&quot;name&quot;</span>: (string) The material ’s English name <span class="keyword">or</span> other identifier (eg. copper oxide , poly -propylene , BB-<span class="number">1</span>, etc). NOT THE FORMULA OR ACRONYM!, </span><br><span class="line">  <span class="string">&quot;formula&quot;</span>: (string) The chemical formula <span class="keyword">for</span> the material (e.g. BiSTiO3). NOT THE NAME OR ACRONYM!, </span><br><span class="line">  <span class="string">&quot;acronym&quot;</span>: (string) <span class="type">Any</span> acronym used to refer to a material (e.g. PEO <span class="keyword">for</span> polyethylene oxide). NOT THE NAME OR FORMULA!, </span><br><span class="line">  <span class="string">&quot;description&quot;</span>: (<span class="built_in">list</span> of string) Descriptions of the material sample. For example , <span class="keyword">if</span> it <span class="keyword">is</span> a thin film , nanoparticles , doped <span class="keyword">with</span> an impurity , etc. </span><br><span class="line">  <span class="string">&quot;structure_or_phase&quot;</span>: (<span class="built_in">list</span> of string) <span class="type">Any</span> information that indicates the materials crystal structure <span class="keyword">or</span> phase (e.g. ’cubic ’, ’rocksalt ’, ’HCP’, ’ alpha -phase ’, etc), Also extract lattice constants <span class="keyword">and</span> angles here , <span class="keyword">if</span> present. (DO NOT put things like </span><br><span class="line">  <span class="string">&quot;nanoporous&quot;</span> that describe the physical structure. Those are descriptions .) </span><br><span class="line">  <span class="string">&quot;applications&quot;</span>: (<span class="built_in">list</span> of string) Applications the material <span class="keyword">is</span> being studied/used <span class="keyword">for</span> (e.g. ’Li-ion batteries ’, ’cathode ’, ’catalyst ’, etc) If the material <span class="keyword">is</span> a catalyst , include the reaction it catalyzes. &#125;, </span><br><span class="line">  ... </span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line">Model output:</span><br><span class="line">[ &#123; <span class="string">&quot;acronym&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;applications&quot;</span>: [ <span class="string">&quot;photovoltaics&quot;</span>, <span class="string">&quot;optoelectronics&quot;</span>, <span class="string">&quot;photodetectors&quot;</span> ], </span><br><span class="line">  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;CH3NH3PbI3&quot;</span>, </span><br><span class="line">  <span class="string">&quot;formula&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;structure_or_phase&quot;</span>: [ <span class="string">&quot;perovskite&quot;</span> ], </span><br><span class="line">  <span class="string">&quot;description&quot;</span>: [ <span class="string">&quot;single crystal&quot;</span>, <span class="string">&quot;photodetectors&quot;</span> ] &#125; </span><br><span class="line">]  </span><br></pre></td></tr></table></figure>
<h2 id="3-参考文献">3.参考文献</h2>
<p>Dagdelen J, Dunn A, Lee S, et al. Structured information extraction from scientific text with large language models[J]. Nature Communications, 2024, 15(1): 1418.</p>
]]></content>
      <tags>
        <tag>大模型</tag>
        <tag>文献笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Training Language Models to Generate Text with Citations via Fine-grained Rewards</title>
    <url>/2024/09/05/Training-Language-Models-to-Generate-Text-with-Citations-via-Fine-grained-Rewards/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Accurate structure prediction of biomolecular interactions with AlphaFold 3</title>
    <url>/2024/09/10/Accurate-structure-prediction-of-biomolecular-interactions-with-AlphaFold-3/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Assessing bioartificial organ function: the 3P model framework and its validation</title>
    <url>/2024/09/10/Assessing-bioartificial-organ-function-the-3P-model-framework-and-its-validation/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Data‐driven prediction models for forecasting multistep ahead profiles of mammalian cell culture toward bioprocess digital twins</title>
    <url>/2024/09/10/Data%E2%80%90driven-prediction-models-for-forecasting-multistep-ahead-profiles-of-mammalian-cell-culture-toward-bioprocess-digital-twins/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Harnessing the potential of machine learning for advancing “Quality by Design” in biomanufacturing</title>
    <url>/2024/09/10/Harnessing-the-potential-of-machine-learning-for-advancing-%E2%80%9CQuality-by-Design%E2%80%9D-in-biomanufacturing/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Ian Walsha, Matthew Myinta</p>
<p>作者单位：Microsoft Corporation</p>
<p>发表时间：Bioprocessing Technology Institute, Agency for Science,
Technology and Research (A*STAR), Singapore</p>
<p>发表期刊：mAbs (2区)</p>
<p>关键内容：介绍一些根据关键工艺参数去预测器官制造相关性能(使用ML)的文献。</p>
</blockquote>
<h2 id="引言">1. 引言</h2>
<p>概念介绍：Qbd, MVDA, DoE</p>
<ul>
<li>Qbd: Quality by
Design，质量源于设计。一种系统化的药品开发方法，强调通过理解产品和过程来确保药品的质量。它要求在设计阶段就明确产品的质量属性，并通过工艺设计确保这些属性满足要求。</li>
<li>MVDA: Multivariate Data
Analysis，多元数据分析。一种用于分析和解释具有多个变量的数据集的统计方法。与单变量分析不同，MVDA可以同时处理多个变量之间的相互关系，提供更全面的见解。如PCA,PLS(偏最小二乘回归)。</li>
<li>DoE: Design of
Experiments，实验设计。一种用于规划实验并通过最少的实验次数来获得最大信息的方法。它帮助研究者系统地探索多个因素的相互作用及其对结果的影响。</li>
</ul>
<h2 id="图表">2. 图表</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1080_19420862.2021.2013593_1.png" alt="图1"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1080_19420862.2021.2013593_2.png" alt="图2"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1080_19420862.2021.2013593_3.png" alt="图3"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1080_19420862.2021.2013593_4.png" alt="图4"></p>
<h2 id="参考文献">3. 参考文献</h2>
<p>Walsh I, Myint M, Nguyen-Khuong T, et al. Harnessing the potential of
machine learning for advancing “quality by design” in
biomanufacturing[C]//MAbs. Taylor &amp; Francis, 2022, 14(1):
2013593.</p>
]]></content>
      <tags>
        <tag>文献笔记</tag>
        <tag>参数预测</tag>
      </tags>
  </entry>
  <entry>
    <title>MLMD: a programming-free AI platform to predict and design materials</title>
    <url>/2024/09/10/MLMD-a-programming-free-AI-platform-to-predict-and-design-materials/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Machine Learning and Deep Learning Strategies for Chinese Hamster Ovary Cell Bioprocess Optimization</title>
    <url>/2024/09/10/Machine-Learning-and-Deep-Learning-Strategies-for-Chinese-Hamster-Ovary-Cell-Bioprocess-Optimization/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>OpenResearcher: Unleashing AI for Accelerated Scientific Research</title>
    <url>/2024/09/10/OpenResearcher-Unleashing-AI-for-Accelerated-Scientific-Research/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>UniKP: a unified framework for the prediction of enzyme kinetic parameters</title>
    <url>/2024/09/10/UniKP-a-unified-framework-for-the-prediction-of-enzyme-kinetic-parameters/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Electrospun nanofiber membrane diameter prediction using a combined response surface methodology and machine learning approach</title>
    <url>/2024/09/12/Electrospun-nanofiber-membrane-diameter-prediction-using-a-combined-response-surface-methodology-and-machine-learning-approach/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Machine learning to predict morphology, topography and mechanical properties of sustainable gelatin‑based electrospun scaffolds</title>
    <url>/2024/09/12/Machine-learning-to-predict-morphology-topography-and-mechanical-properties-of-sustainable-gelatin%E2%80%91based-electrospun-scaffolds/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Active learning streamlines development of high performance catalysts for higher alcohol synthesis</title>
    <url>/2024/09/12/Active-learning-streamlines-development-of-high-performance-catalysts-for-higher-alcohol-synthesis/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Challenges in developing cell culture media using machine learning</title>
    <url>/2024/09/12/Challenges-in-developing-cell-culture-media-using-machine-learning/</url>
    <content><![CDATA[<blockquote>
<p>第一作者：Takamasa Hashizume</p>
<p>作者单位：University of Tsukuba</p>
<p>发表时间：2024/1</p>
<p>发表期刊：Biotechnology Advances，1区</p>
<p>关键内容：综述类型文章。介绍细胞培养工程中的机器学习技术。总共从实验设计、数据获取、模型构建、培养基预测、验证开发五个方面进行详细的介绍。主要亮点是：对41篇相关文献所用的技术进行了总结。</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_1.png" alt="图1"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_2.png" alt="图2"></p>
<h2 id="数据获取">1. 数据获取</h2>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_3.png" alt="图3">
<figcaption aria-hidden="true">图3</figcaption>
</figure>
<h2 id="模型构建">2. 模型构建</h2>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_4.png" alt="图1"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_5.png" alt="图1"></p>
<h2 id="培养基预测">3. 培养基预测</h2>
<p>类比于模型超参数优化，通过搜索，找到影响模型输出（如细胞浓度或产率）的最重要的成分和最优浓度组合。</p>
<ul>
<li>Brute force approach,
穷举搜索策略，逐一评估所有可能的组合，直到找到最佳结果。</li>
<li>Surface plot,
表面图，一种可视化工具，通常用于展示两个变量之间的关系。它生成一个三维图，显示两个变量（例如培养基成分浓度）如何影响模型输出（如细胞浓度或产率）。
<ul>
<li>在培养基优化过程中，表面图用于对模型进行敏感性分析。通过敏感性分析，可以确定对细胞培养有最大影响的培养基成分。然后保持其他成分的浓度不变，只改变两个主要成分的浓度，生成一个3D表面图，展示这两个变量的不同组合如何影响细胞培养结果。通过观察表面图，可以直观地找到最优浓度组合。</li>
</ul></li>
<li>Genetic algorithm, GA</li>
<li>Particle swarm optimization, PSO</li>
</ul>
<p>其它方法：贝叶斯优化等。</p>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_6.png" alt="图6"> <img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/10.1016_j.biotechadv.2023.108293_7.png" alt="图7"></p>
<h2 id="验证开发">4. 验证开发</h2>
<p>主动学习的过程：</p>
<ol type="1">
<li>Build the ML model to predict culture results from medium
combinations.</li>
<li>Predict the cell culture by inputting the medium compositions.</li>
<li>Select the medium combinations based on the predicted cell
culture.</li>
<li>Experimentally validate the selected medium combinations.</li>
<li>Add the experimental results to the learning data.</li>
</ol>
<p>Steps 1 to 5 are repeateduntil the medium improves the ML model’s
prediction accuracy. Even with a small dataset, the medium combinations
could be finetunedto achieve high performance.</p>
<h2 id="参考文献">5. 参考文献</h2>
<p>Hashizume T, Ying B W. Challenges in developing cell culture media
using machine learning[J]. Biotechnology Advances, 2023: 108293.</p>
]]></content>
      <tags>
        <tag>文献笔记</tag>
        <tag>参数预测</tag>
      </tags>
  </entry>
  <entry>
    <title>Discovering High Entropy Alloy Electrocatalysts in Vast Composition Spaces with Multiobjective Optimization</title>
    <url>/2024/09/12/Discovering-High-Entropy-Alloy-Electrocatalysts-in-Vast-Composition-Spaces-with-Multiobjective-Optimization/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>GAM</title>
    <url>/2024/09/12/GAM/</url>
    <content><![CDATA[<p>Generalized Additive Models, 广义加性模型 GAM。</p>
<p>通过对预测变量应用平滑函数来捕捉非线性关系。GAM
扩展了传统的线性模型，使得每个预测变量对响应变量的影响可以通过非线性函数来建模。</p>
<p><a href="https://www.youtube.com/watch?v=wVGvhT151lg">GLM vs. GAM -
Generalized Additive Models</a></p>
<h2 id="gam-的基本组成">1. GAM 的基本组成</h2>
<p>广义加性模型包括以下几个主要成分：</p>
<ol type="1">
<li><strong>响应变量</strong>：<span class="math inline">\(Y\)</span>
是模型的目标变量。</li>
<li><strong>预测变量</strong>：<span class="math inline">\(X = (X_1,
X_2, \ldots, X_p)\)</span> 是自变量或特征。</li>
<li><strong>平滑函数</strong>：<span class="math inline">\(f_i(X_i)\)</span> 是每个预测变量 <span class="math inline">\(X_i\)</span>
对响应变量的影响，通过平滑函数建模。</li>
<li><strong>线性预测器</strong>：将每个预测变量的平滑函数加总起来得到模型的线性预测器。</li>
</ol>
<h2 id="gam-的模型形式">2. GAM 的模型形式</h2>
<p>GAM 的模型可以表示为： <span class="math display">\[
g(\mathbb{E}[Y]) = \beta_0 + \sum_{i=1}^p f_i(X_i)
\]</span> 其中：</p>
<ul>
<li><span class="math inline">\(g(\cdot)\)</span> 是链接函数，将期望值
<span class="math inline">\(\mathbb{E}[Y]\)</span>
与线性预测器联系起来。</li>
<li><span class="math inline">\(\beta_0\)</span> 是截距项。</li>
<li><span class="math inline">\(f_i(X_i)\)</span> 是对每个预测变量 <span class="math inline">\(X_i\)</span> 施加的平滑函数。</li>
</ul>
<h3 id="平滑函数">2.1 平滑函数</h3>
<p>平滑函数 <span class="math inline">\(f_i(X_i)\)</span>
通过使用平滑器来捕捉预测变量和响应变量之间的非线性关系。常用的平滑方法包括：</p>
<ul>
<li><strong>样条函数</strong>（Splines）</li>
<li><strong>局部回归</strong>（Local Regression）</li>
<li><strong>核平滑</strong>（Kernel Smoothing）</li>
</ul>
<h3 id="链接函数">2.2 链接函数</h3>
<p>链接函数 <span class="math inline">\(g(\cdot)\)</span> 将期望值 <span class="math inline">\(\mathbb{E}[Y]\)</span> 映射到线性预测器 <span class="math inline">\(\eta\)</span>： <span class="math display">\[
g(\mathbb{E}[Y]) = \eta
\]</span> 常见的链接函数包括：</p>
<ul>
<li><strong>恒等链接函数</strong>：用于线性回归。</li>
<li><strong>逻辑链接函数</strong>：用于逻辑回归。</li>
<li><strong>对数链接函数</strong>：用于泊松回归。</li>
</ul>
<h2 id="gam-的模型推导">3. GAM 的模型推导</h2>
<h3 id="建模步骤">3.1 建模步骤</h3>
<ol type="1">
<li><strong>选择链接函数</strong>：根据响应变量的分布选择合适的链接函数
<span class="math inline">\(g(\cdot)\)</span>。</li>
<li><strong>选择平滑函数</strong>：为每个预测变量选择适当的平滑函数
<span class="math inline">\(f_i(X_i)\)</span>。</li>
<li><strong>优化估计</strong>：通过最大似然估计或其他优化方法估计模型参数。</li>
</ol>
<h3 id="平滑函数的估计">3.2 平滑函数的估计</h3>
<p>平滑函数的估计通常通过最小化以下目标函数来实现： <span class="math display">\[
\text{Objective} = \text{Deviance} + \text{Penalized Smoothing Terms}
\]</span> 其中，Deviance 是模型的拟合优度，Penalized Smoothing Terms
是对平滑函数复杂度的惩罚，以防止过拟合。</p>
<h3 id="参数估计">3.3 参数估计</h3>
<p>通过最小化下述目标函数来估计模型参数： <span class="math display">\[
\text{GAMLSS} = \sum_{i=1}^n \text{Log-Likelihood} + \text{Penalty
Terms}
\]</span> 其中，Penalty Terms
用于控制平滑函数的复杂度，以避免过度拟合。</p>
<h2 id="gam-的优点">4. GAM 的优点</h2>
<ul>
<li><strong>灵活性</strong>：GAM
可以捕捉非线性关系，不需要对数据的具体形式做出强假设。</li>
<li><strong>可解释性</strong>：每个预测变量的影响通过平滑函数明确表示，易于解释。</li>
<li><strong>平滑</strong>：通过平滑函数处理噪声和非线性，增强模型的鲁棒性。</li>
</ul>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>GBDT</title>
    <url>/2024/09/12/GBDT/</url>
    <content><![CDATA[<p>Gradient boosting Decision Tree。</p>
<h2 id="核心思想">1. 核心思想</h2>
<p>GBDT 是一种迭代的决策树算法，它由多棵决策树组成。GBDT
的核心在于将所有决策树的输出累加作为最终结果，因此 GBDT 中的每一棵树都是
<strong>回归树</strong>，即每棵树拟合的是之前模型的残差。每次迭代都会训练一个新的树来优化先前的误差，通过这种方式，不断提升模型的整体预测能力。</p>
<h2 id="算法步骤">2. 算法步骤</h2>
<ol type="1">
<li><p><strong>初始化模型</strong>：使用常数函数初始化模型，比如将目标变量的均值作为初始预测值。</p></li>
<li><p><strong>计算残差</strong>：对于每一个样本，计算当前模型的残差，即目标值与当前预测值的差异。</p></li>
<li><p><strong>拟合残差</strong>：训练一棵决策树，使其能够拟合上一步的残差（拟合负梯度）。</p></li>
<li><p><strong>更新模型</strong>：将新树的预测结果乘上学习率（缩放系数），然后将其加到当前模型的预测值中。</p></li>
</ol>
<p><span class="math display">\[
F_m(x) = F_{m-1}(x) + \alpha h_m(x)
\]</span></p>
<p>其中，<span class="math inline">\(F_m(x)\)</span> 表示第 <span class="math inline">\(m\)</span> 次迭代后的模型，<span class="math inline">\(F_{m-1}(x)\)</span> 是前一次迭代的模型，<span class="math inline">\(h_m(x)\)</span> 是当前树的输出，<span class="math inline">\(\alpha\)</span> 是学习率。</p>
<ol start="5" type="1">
<li><strong>重复步骤
2-4</strong>：直到达到指定的迭代次数或误差收敛。</li>
</ol>
<h2 id="损失函数">3. 损失函数</h2>
<p>GBDT 可以处理 <strong>回归问题</strong> 和
<strong>分类问题</strong>，因此对应的损失函数根据任务的不同而变化：</p>
<ul>
<li><strong>回归问题</strong>：使用 <strong>均方误差（MSE, Mean Squared
Error）</strong> 作为损失函数，公式如下：</li>
</ul>
<p><span class="math display">\[
L = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
\]</span></p>
<ul>
<li><strong>分类问题</strong>：可以使用 <strong>对数损失函数</strong> 或
<strong>交叉熵损失函数</strong>：</li>
</ul>
<p><span class="math display">\[
L = - \sum_{i=1}^{n} y_i \log(\hat{y_i}) + (1 - y_i) \log(1 - \hat{y_i})
\]</span></p>
<p>GBDT
通过负梯度来估计损失函数的残差，并逐步拟合这个负梯度，从而不断减少误差。</p>
<h2 id="优势">4. 优势</h2>
<ol type="1">
<li><p><strong>高精度</strong>：GBDT 在各种任务中都有很好的表现，尤其是
<strong>回归任务</strong> 和 <strong>二分类任务</strong>。</p></li>
<li><p><strong>处理复杂非线性问题</strong>：GBDT
通过多棵回归树累积，可以处理复杂的非线性关系。</p></li>
<li><p><strong>灵活性</strong>：GBDT
可以灵活地适用于回归和分类问题，损失函数可以根据具体问题自定义。</p></li>
<li><p><strong>可扩展性</strong>：可以与其他模型（如神经网络）结合使用，增强模型的性能。</p></li>
</ol>
<h2 id="缺点">5. 缺点</h2>
<ol type="1">
<li><p><strong>训练时间较长</strong>：由于 GBDT
是一种逐步迭代的算法，且每次迭代需要构建一棵新的决策树，因此训练时间较长。</p></li>
<li><p><strong>难以并行化</strong>：由于 GBDT
每次迭代都依赖于前一次迭代的结果，无法像随机森林那样轻松地并行化处理。</p></li>
<li><p><strong>容易过拟合</strong>：如果树的深度过大或者迭代次数过多，GBDT
容易过拟合。</p></li>
<li><p><strong>对缺失值敏感</strong>：GBDT
不能像一些其他算法一样自适应处理缺失值，因此数据预处理较为重要。</p></li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>GLM</title>
    <url>/2024/09/12/GLM/</url>
    <content><![CDATA[<p>Generalized Linear Models, 广义线性模型GLM。</p>
<p>一类灵活的统计模型，用于处理不同类型的数据。GLM
扩展了传统的线性回归模型，允许响应变量（因变量）与预测变量（自变量）之间的关系通过各种分布来建模。GLM
主要包括线性回归、逻辑回归、泊松回归等模型。</p>
<h2 id="glm-的基本组成">1. GLM 的基本组成</h2>
<p>广义线性模型由以下三部分组成：</p>
<ol type="1">
<li><strong>随机成分</strong>：响应变量 <span class="math inline">\(Y\)</span>
的分布，通常假设为指数家族分布，如正态分布、二项分布、泊松分布等。</li>
<li><strong>系统成分</strong>：线性预测器 <span class="math inline">\(\eta\)</span>，即自变量的线性组合： <span class="math display">\[
\eta = X \beta
\]</span> 其中，<span class="math inline">\(X\)</span> 是设计矩阵，<span class="math inline">\(\beta\)</span> 是回归系数。</li>
<li><strong>链接函数</strong>：链接函数 <span class="math inline">\(g(\cdot)\)</span> 将线性预测器 <span class="math inline">\(\eta\)</span> 与响应变量的期望 <span class="math inline">\(\mu\)</span> 联系起来： <span class="math display">\[
g(\mu) = \eta
\]</span> 其中，<span class="math inline">\(\mu = \text{E}[Y]\)</span>
是响应变量的期望。</li>
</ol>
<h2 id="glm-的数学推导">2. GLM 的数学推导</h2>
<h3 id="随机成分">2.1 随机成分</h3>
<p>假设响应变量 <span class="math inline">\(Y\)</span>
的分布属于指数家族分布，其概率密度函数（或质量函数）可以表示为： <span class="math display">\[
f(y|\theta, \phi) = \exp \left\{ \frac{y (\theta) - b(\theta)}{\phi} +
c(y, \phi) \right\}
\]</span> 其中，<span class="math inline">\(\theta\)</span>
是自然参数，<span class="math inline">\(\phi\)</span>
是分布的扩展参数（例如方差），<span class="math inline">\(b(\theta)\)</span> 和 <span class="math inline">\(c(y, \phi)\)</span> 是特定的函数。</p>
<h3 id="系统成分">2.2 系统成分</h3>
<p>线性预测器 <span class="math inline">\(\eta\)</span> 定义为： <span class="math display">\[
\eta = X \beta
\]</span> 其中，<span class="math inline">\(X\)</span>
是设计矩阵，包含自变量，<span class="math inline">\(\beta\)</span>
是回归系数。</p>
<h3 id="链接函数">2.3 链接函数</h3>
<p>链接函数 <span class="math inline">\(g(\cdot)\)</span>
使得线性预测器与响应变量的期望 <span class="math inline">\(\mu\)</span>
之间的关系为： <span class="math display">\[
g(\mu) = \eta
\]</span> 常见的链接函数包括：</p>
<ul>
<li><strong>对数链接函数</strong>：用于泊松回归，<span class="math inline">\(g(\mu) = \log(\mu)\)</span></li>
<li><strong>逻辑链接函数</strong>：用于逻辑回归，<span class="math inline">\(g(\mu) = \log \left( \frac{\mu}{1 - \mu}
\right)\)</span></li>
<li><strong>恒等链接函数</strong>：用于线性回归，<span class="math inline">\(g(\mu) = \mu\)</span></li>
</ul>
<h3 id="估计和推断">2.4 估计和推断</h3>
<p>GLM 的参数估计通常使用最大似然估计（MLE）。最大似然函数 <span class="math inline">\(L(\beta)\)</span> 为： <span class="math display">\[
L(\beta) = \prod_{i=1}^n f(y_i|\theta_i, \phi)
\]</span> 对数似然函数为： <span class="math display">\[
\ell(\beta) = \sum_{i=1}^n \left[ \frac{y_i \theta_i -
b(\theta_i)}{\phi} + c(y_i, \phi) \right]
\]</span>
通过对对数似然函数求导数并设置为零，可以得到参数的最大似然估计值。</p>
<h2 id="glm-的模型示例">3. GLM 的模型示例</h2>
<h3 id="线性回归">3.1 线性回归</h3>
<p>线性回归模型属于 GLM 的特殊情况，其中响应变量 <span class="math inline">\(Y\)</span> 服从正态分布，链接函数为恒等函数：
<span class="math display">\[
Y \sim \text{N}(\mu, \sigma^2)
\]</span> <span class="math display">\[
g(\mu) = \mu = X \beta
\]</span></p>
<h3 id="逻辑回归">3.2 逻辑回归</h3>
<p>逻辑回归用于二分类问题，响应变量 <span class="math inline">\(Y\)</span> 服从二项分布，链接函数为逻辑函数：
<span class="math display">\[
Y \sim \text{Binomial}(n, \mu)
\]</span> <span class="math display">\[
g(\mu) = \log \left( \frac{\mu}{1 - \mu} \right) = X \beta
\]</span></p>
<h3 id="泊松回归">3.3 泊松回归</h3>
<p>泊松回归用于计数数据，响应变量 <span class="math inline">\(Y\)</span>
服从泊松分布，链接函数为对数函数： <span class="math display">\[
Y \sim \text{Poisson}(\mu)
\]</span> <span class="math display">\[
g(\mu) = \log(\mu) = X \beta
\]</span></p>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>GPR</title>
    <url>/2024/09/12/GPR/</url>
    <content><![CDATA[<p>Gaussian Process Regression, 高斯过程回归。</p>
<p>一种非参数的贝叶斯回归方法，用于建模和预测复杂的非线性函数。它利用高斯过程的先验分布来推断数据的分布，并生成预测的不确定性度量。</p>
<h2 id="高斯过程回归的基本概念">1. 高斯过程回归的基本概念</h2>
<h3 id="高斯过程">1.1 高斯过程</h3>
<p>高斯过程（Gaussian Process,
GP）是一种用于定义随机函数的统计模型，它可以看作是无穷维的高斯分布。一个高斯过程可以通过其均值函数
<span class="math inline">\(m(x)\)</span> 和协方差函数 <span class="math inline">\(k(x, x&#39;)\)</span> 完全描述： <span class="math display">\[
f(x) \sim \mathcal{GP}(m(x), k(x, x&#39;))
\]</span> 其中：</p>
<ul>
<li><span class="math inline">\(m(x)\)</span> 是均值函数，表示在点 <span class="math inline">\(x\)</span> 的预测值的期望。</li>
<li><span class="math inline">\(k(x, x&#39;)\)</span>
是协方差函数，表示在点 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(x&#39;\)</span> 之间的协方差。</li>
</ul>
<h3 id="协方差函数核函数">1.2 协方差函数（核函数）</h3>
<p>协方差函数 <span class="math inline">\(k(x, x&#39;)\)</span>
用于定义数据点之间的相关性。常见的协方差函数包括：</p>
<ul>
<li><strong>平方指数核（RBF核）</strong>： <span class="math display">\[
k(x, x&#39;) = \sigma^2 \exp \left( -\frac{(x - x&#39;)^2}{2 l^2}
\right)
\]</span></li>
<li><strong>线性核</strong>： <span class="math display">\[
k(x, x&#39;) = \sigma^2 (x \cdot x&#39; + c)
\]</span></li>
<li><strong>马特恩核</strong>： <span class="math display">\[
k(x, x&#39;) = \sigma^2 \left(1 + \frac{\sqrt{2 \nu} (x -
x&#39;)^2}{l^2}\right)^{-\nu}
\]</span></li>
</ul>
<h2 id="gpr-的模型构建">2. GPR 的模型构建</h2>
<h3 id="训练数据">2.1 训练数据</h3>
<p>假设我们有训练数据集 <span class="math inline">\(\{(x_i,
y_i)\}_{i=1}^n\)</span>，其中 <span class="math inline">\(x_i\)</span>
是输入，<span class="math inline">\(y_i\)</span> 是响应。我们希望通过
GPR 来预测新的输入 <span class="math inline">\(x_*\)</span> 对应的响应
<span class="math inline">\(y_*\)</span>。</p>
<h3 id="先验分布">2.2 先验分布</h3>
<p>假设训练数据的目标函数 <span class="math inline">\(f(x)\)</span>
服从高斯过程： <span class="math display">\[
f(x) \sim \mathcal{GP}(m(x), k(x, x&#39;))
\]</span></p>
<p>训练数据的联合分布可以表示为： <span class="math display">\[
\begin{bmatrix}
f(X) \\
f(x_*)
\end{bmatrix}
\sim \mathcal{N} \left(
\begin{bmatrix}
m(X) \\
m(x_*)
\end{bmatrix},
\begin{bmatrix}
K(X, X) &amp; K(X, x_*) \\
K(x_*, X) &amp; K(x_*, x_*)
\end{bmatrix}
\right)
\]</span> 其中：</p>
<ul>
<li><span class="math inline">\(K(X, X)\)</span>
是训练数据点之间的协方差矩阵。</li>
<li><span class="math inline">\(K(X, x_*)\)</span>
是训练数据点与测试点之间的协方差矩阵。</li>
<li><span class="math inline">\(K(x_*, x_*)\)</span>
是测试点之间的协方差矩阵。</li>
</ul>
<h3 id="后验分布">2.3 后验分布</h3>
<p>给定训练数据 <span class="math inline">\(\{(x_i,
y_i)\}_{i=1}^n\)</span>，我们可以得到目标函数在测试点 <span class="math inline">\(x_*\)</span> 的后验分布： <span class="math display">\[
f(x_*) | X, y, x_* \sim \mathcal{N} (\bar{f}(x_*), \text{Cov}(f(x_*)))
\]</span> 其中： <span class="math display">\[
\bar{f}(x_*) = m(x_*) + K(x_*, X) \left[ K(X, X) + \sigma^2 I
\right]^{-1} (y - m(X))
\]</span> <span class="math display">\[
\text{Cov}(f(x_*)) = K(x_*, x_*) - K(x_*, X) \left[ K(X, X) + \sigma^2 I
\right]^{-1} K(X, x_*)
\]</span></p>
<h2 id="高斯过程回归的推导">3. 高斯过程回归的推导</h2>
<h3 id="预测均值">3.1 预测均值</h3>
<p>预测的均值 <span class="math inline">\(\bar{f}(x_*)\)</span>
是对目标函数在测试点的预测值，它由训练数据的观测值加权得出： <span class="math display">\[
\bar{f}(x_*) = m(x_*) + K(x_*, X) \left[ K(X, X) + \sigma^2 I
\right]^{-1} (y - m(X))
\]</span></p>
<h3 id="预测方差">3.2 预测方差</h3>
<p>预测的方差 <span class="math inline">\(\text{Cov}(f(x_*))\)</span>
描述了预测的不确定性： <span class="math display">\[
\text{Cov}(f(x_*)) = K(x_*, x_*) - K(x_*, X) \left[ K(X, X) + \sigma^2 I
\right]^{-1} K(X, x_*)
\]</span></p>
<h3 id="超参数优化">3.3 超参数优化</h3>
<p>高斯过程回归模型中的核函数通常包含超参数（如长度尺度 <span class="math inline">\(l\)</span> 和噪声方差 <span class="math inline">\(\sigma^2\)</span>），这些超参数可以通过最大化边际对数似然函数来优化：
<span class="math display">\[
\log p(y | X) = -\frac{1}{2} y^\top \left[ K(X, X) + \sigma^2 I
\right]^{-1} y - \frac{1}{2} \log \left| K(X, X) + \sigma^2 I \right| -
\frac{n}{2} \log 2 \pi
\]</span></p>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>PCA</title>
    <url>/2024/09/12/PCA/</url>
    <content><![CDATA[<p>Principal Component Analysis, 主成分分析。</p>
<p>通过线性变换，将高维数据映射到低维空间，同时保留数据的主要方差信息。PCA
的主要优势在于它可以在数据降维的同时减少噪声，简化数据结构，提升模型的可解释性。</p>
<h2 id="pca-的基本思想">1. PCA 的基本思想</h2>
<p>给定数据集 <span class="math inline">\(X \in \mathbb{R}^{n \times
p}\)</span>，其中 <span class="math inline">\(n\)</span> 是样本数，<span class="math inline">\(p\)</span> 是特征数。PCA
的目标是找到新的正交基（主成分），使得数据在这些新基上的投影尽可能解释原数据的方差。</p>
<p>PCA 的核心步骤如下：</p>
<ol type="1">
<li><strong>数据中心化</strong>：将数据减去均值，使得每个特征的均值为
0。</li>
<li><strong>协方差矩阵</strong>：计算中心化数据的协方差矩阵，衡量各特征之间的线性关系。</li>
<li><strong>特征分解</strong>：对协方差矩阵进行特征分解，得到特征值和特征向量。</li>
<li><strong>主成分选择</strong>：选择特征值最大的前 <span class="math inline">\(k\)</span>
个特征向量作为新的坐标轴（主成分），将数据投影到这些主成分上。</li>
</ol>
<h2 id="pca-的数学推导">2. PCA 的数学推导</h2>
<h3 id="数据中心化">2.1 数据中心化</h3>
<p>首先，对数据 <span class="math inline">\(X\)</span>
进行中心化处理，将每个特征减去均值： <span class="math display">\[
\tilde{X} = X - \bar{X}
\]</span> 其中，<span class="math inline">\(\bar{X}\)</span> 是 <span class="math inline">\(X\)</span> 的均值向量。</p>
<h3 id="协方差矩阵">2.2 协方差矩阵</h3>
<p>对于中心化后的数据 <span class="math inline">\(\tilde{X}\)</span>，计算其协方差矩阵 <span class="math inline">\(\Sigma\)</span>： <span class="math display">\[
\Sigma = \frac{1}{n-1} \tilde{X}^\top \tilde{X}
\]</span> 协方差矩阵描述了不同特征之间的相关性。PCA
的目的是通过选择适当的基，使得投影后的数据方差最大化。</p>
<h3 id="特征分解">2.3 特征分解</h3>
<p>通过对协方差矩阵 <span class="math inline">\(\Sigma\)</span>
进行特征值分解，得到特征值和特征向量： <span class="math display">\[
\Sigma v_i = \lambda_i v_i
\]</span> 其中，<span class="math inline">\(\lambda_i\)</span>
表示协方差矩阵的第 <span class="math inline">\(i\)</span>
个特征值，<span class="math inline">\(v_i\)</span>
表示对应的特征向量。</p>
<ul>
<li><strong>特征值</strong>：表示数据在对应特征向量方向上的方差大小。特征值越大，表示该方向上方差越大，信息量越多。</li>
<li><strong>特征向量</strong>：表示主成分方向，也就是新的坐标轴。</li>
</ul>
<h3 id="主成分选择与投影">2.4 主成分选择与投影</h3>
<p>根据特征值的大小，从大到小排列，选择前 <span class="math inline">\(k\)</span>
个特征向量作为主成分，将数据投影到这些主成分方向上： <span class="math display">\[
Z = \tilde{X} V_k
\]</span> 其中，<span class="math inline">\(V_k\)</span> 是前 <span class="math inline">\(k\)</span> 个特征向量组成的矩阵，<span class="math inline">\(Z\)</span> 是降维后的数据矩阵。</p>
<h2 id="pca-的几何解释">3. PCA 的几何解释</h2>
<p>从几何角度来看，PCA
是在寻找新的正交基，使得数据在这些基上的投影具有最大方差。特征向量代表新的基方向，特征值表示投影在该基方向上的方差大小。</p>
<p>PCA
的第一主成分对应于数据方差最大的方向，第二主成分则是与第一主成分正交并且方差次大的方向，以此类推。</p>
<h2 id="pca-的步骤">4. PCA 的步骤</h2>
<ol type="1">
<li><strong>标准化数据</strong>：确保每个特征有相同的量纲。</li>
<li><strong>计算协方差矩阵</strong>：通过公式 <span class="math inline">\(\Sigma = \frac{1}{n-1} \tilde{X}^\top
\tilde{X}\)</span> 计算协方差矩阵。</li>
<li><strong>特征值分解</strong>：对协方差矩阵进行特征值分解，得到特征值和特征向量。</li>
<li><strong>选择主成分</strong>：根据特征值的大小选择前 <span class="math inline">\(k\)</span> 个主成分。</li>
<li><strong>数据投影</strong>：将数据投影到所选主成分上，得到降维后的数据。</li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>PLS</title>
    <url>/2024/09/12/PLSA/</url>
    <content><![CDATA[<p>Partial least squares regression，偏最小二乘回归。</p>
<p>PLS
的基本思想是通过在输入数据（自变量）和输出数据（因变量）之间同时构建新变量（潜变量或成分），以便最大化输入与输出的协方差，同时解决高维数据中自变量之间的多重共线性问题。</p>
<p>主成分回归（PCR）是通过主成分分析（PCA）来减少自变量维度，但它只关注自变量的方差，忽略了自变量和因变量之间的相关性。而
PLS
同时考虑自变量的方差和自变量-因变量的协方差，因此在解释能力上通常优于
PCR。</p>
<h2 id="基本思想与目标">1. 基本思想与目标</h2>
<p>PLS 的目标是在输入矩阵 <span class="math inline">\(X\)</span>
和输出矩阵 <span class="math inline">\(Y\)</span> 之间建立一个线性模型：
<span class="math display">\[
Y = X B + E
\]</span> 其中：</p>
<ul>
<li><span class="math inline">\(X \in \mathbb{R}^{n \times p}\)</span>
是自变量矩阵，有 <span class="math inline">\(n\)</span> 个样本和 <span class="math inline">\(p\)</span> 个自变量；</li>
<li><span class="math inline">\(Y \in \mathbb{R}^{n \times q}\)</span>
是因变量矩阵，有 <span class="math inline">\(q\)</span> 个因变量；</li>
<li><span class="math inline">\(B \in \mathbb{R}^{p \times q}\)</span>
是需要估计的回归系数矩阵；</li>
<li><span class="math inline">\(E\)</span> 是误差矩阵。</li>
</ul>
<p>为了避免由于 <span class="math inline">\(X\)</span>
中自变量之间的多重共线性而导致的回归不稳，PLS 将 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span>
投影到一组新的潜在变量（成分）上，通过最大化这些潜在变量的协方差来构建模型。</p>
<h2 id="潜变量模型">2. 潜变量模型</h2>
<p>PLS
通过构建一组称为<strong>潜变量</strong>的变量来替代原始变量。这些潜变量是从自变量矩阵
<span class="math inline">\(X\)</span> 和因变量矩阵 <span class="math inline">\(Y\)</span>
中提取的，同时考虑两者之间的协方差。</p>
<h3 id="自变量和因变量的线性分解">2.1 自变量和因变量的线性分解</h3>
<p>首先，将 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 表示为其主成分的线性组合： <span class="math display">\[
X = T P^\top + E_X
\]</span> <span class="math display">\[
Y = U Q^\top + E_Y
\]</span> 其中：</p>
<ul>
<li><span class="math inline">\(T \in \mathbb{R}^{n \times k}\)</span>
是 <span class="math inline">\(X\)</span>
的潜变量矩阵（得分矩阵），<span class="math inline">\(k\)</span>
是成分数；</li>
<li><span class="math inline">\(P \in \mathbb{R}^{p \times k}\)</span>
是 <span class="math inline">\(X\)</span> 的加载矩阵；</li>
<li><span class="math inline">\(U \in \mathbb{R}^{n \times k}\)</span>
是 <span class="math inline">\(Y\)</span> 的潜变量矩阵；</li>
<li><span class="math inline">\(Q \in \mathbb{R}^{q \times k}\)</span>
是 <span class="math inline">\(Y\)</span> 的加载矩阵；</li>
<li><span class="math inline">\(E_X\)</span> 和 <span class="math inline">\(E_Y\)</span> 是误差矩阵。</li>
</ul>
<h3 id="潜变量的构造">2.2 潜变量的构造</h3>
<p>在 PLS 中，我们希望找到一组潜变量，使得它们能够解释 <span class="math inline">\(X\)</span> 中最多的方差，并且与 <span class="math inline">\(Y\)</span> 之间有最大的协方差。为此，PLS
寻找潜变量 <span class="math inline">\(T\)</span> 和 <span class="math inline">\(U\)</span>，使得它们的协方差最大化： <span class="math display">\[
\text{Cov}(T, U) = \max
\]</span> 其中 <span class="math inline">\(T\)</span> 是从 <span class="math inline">\(X\)</span> 投影得到的，<span class="math inline">\(U\)</span> 是从 <span class="math inline">\(Y\)</span> 投影得到的。</p>
<h3 id="线性回归模型">2.3 线性回归模型</h3>
<p>PLS 的最终目标是通过潜变量 <span class="math inline">\(T\)</span> 对
<span class="math inline">\(Y\)</span>
进行回归，因此我们建立如下线性关系： <span class="math display">\[
Y = T B + E_Y
\]</span> 通过求解 <span class="math inline">\(T\)</span> 和 <span class="math inline">\(B\)</span>，我们就能够得到 <span class="math inline">\(Y\)</span> 的估计值。</p>
<h2 id="pls-的推导过程">3. PLS 的推导过程</h2>
<p>PLS 的推导过程可以分为以下几个步骤：</p>
<h3 id="中心化数据">3.1 中心化数据</h3>
<p>为了消除数据的尺度影响，我们通常在建模之前对 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 进行中心化处理，即减去其均值： <span class="math display">\[
\tilde{X} = X - \bar{X}, \quad \tilde{Y} = Y - \bar{Y}
\]</span> 其中 <span class="math inline">\(\bar{X}\)</span> 和 <span class="math inline">\(\bar{Y}\)</span> 分别是 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 的均值。</p>
<h3 id="潜变量的构造-1">3.2 潜变量的构造</h3>
<p>对于每个成分，我们依次从 <span class="math inline">\(X\)</span> 和
<span class="math inline">\(Y\)</span>
中提取潜变量。通常采用如下的迭代方法：</p>
<ol type="1">
<li><p>在第 <span class="math inline">\(i\)</span> 次迭代中，找到向量
<span class="math inline">\(w_i\)</span> 和 <span class="math inline">\(c_i\)</span>，使得： <span class="math display">\[
w_i = \arg\max_w \text{Cov}(X w, Y c)
\]</span> 即最大化自变量和因变量之间的协方差。</p></li>
<li><p>得到投影得分向量： <span class="math display">\[
t_i = X w_i, \quad u_i = Y c_i
\]</span></p></li>
<li><p>更新矩阵 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span>，去除已经提取的成分的影响： <span class="math display">\[
X = X - t_i p_i^\top, \quad Y = Y - t_i q_i^\top
\]</span> 其中 <span class="math inline">\(p_i\)</span> 和 <span class="math inline">\(q_i\)</span> 分别为对应的加载向量。</p></li>
</ol>
<h3 id="回归系数的计算">3.3 回归系数的计算</h3>
<p>在构造了 <span class="math inline">\(T\)</span> 和 <span class="math inline">\(U\)</span> 之后，PLS 通过回归 <span class="math inline">\(Y\)</span> 对 <span class="math inline">\(T\)</span> 来得到回归系数 <span class="math inline">\(B\)</span>： <span class="math display">\[
B = (T^\top T)^{-1} T^\top Y
\]</span></p>
<h3 id="最终模型">3.4 最终模型</h3>
<p>通过潜变量的回归模型，最终的 PLS 模型为： <span class="math display">\[
Y = X B + E_Y
\]</span> 其中 <span class="math inline">\(B\)</span> 是通过 <span class="math inline">\(X\)</span> 的潜变量和 <span class="math inline">\(Y\)</span> 之间的回归系数计算得到的。</p>
<h2 id="pls-的特点">4. PLS 的特点</h2>
<ol type="1">
<li><p><strong>处理多重共线性</strong>：PLS
通过提取潜变量代替原始变量，有效解决了多重共线性的问题，尤其适用于当
<span class="math inline">\(p \gg n\)</span> 时。</p></li>
<li><p><strong>同时考虑 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> 的信息</strong>：PLS
在寻找潜变量时，既考虑了自变量的方差最大化，也考虑了自变量和因变量之间的协方差，增强了模型的解释能力。</p></li>
<li><p><strong>可解释性强</strong>：PLS
的潜变量有明确的统计意义，能够通过加载矩阵解释原始变量的贡献。</p></li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>RF</title>
    <url>/2024/09/12/RF/</url>
    <content><![CDATA[<p>Random forest，随机森林。</p>
<h2 id="决策树">1. 决策树</h2>
<p>一种<strong>树形结构</strong>，通过学习数据中的特征，逐层对数据进行划分。每一个节点代表一个特征的决策条件，叶子节点代表最终的分类结果或回归值。</p>
<h3 id="构建步骤">1.1 构建步骤</h3>
<ol type="1">
<li>从特征中选择最优特征作为节点进行数据集划分（如基尼指数或信息增益）。</li>
<li>对每个子数据集递归地构建决策树，直到满足终止条件（如树的深度、叶子节点数等）。</li>
<li>决策树会根据训练样本中学到的规则，给出分类或回归的结果。</li>
</ol>
<h3 id="信息增益information-gain">1.2 信息增益（Information Gain）</h3>
<p>信息增益衡量的是某个特征对样本的分类效果，特征对数据集进行划分后，信息的不确定性减少的程度。</p>
<p>计算公式：</p>
<p><span class="math display">\[
Gain(D, A) = Entropy(D) - \sum_{v=1}^{V} \frac{|D_v|}{|D|} Entropy(D_v)
\]</span></p>
<p>其中： <span class="math inline">\(Gain(D, A)\)</span>是特征<span class="math inline">\(A\)</span>对数据集<span class="math inline">\(D\)</span>的信息增益， <span class="math inline">\(Entropy(D)\)</span>是数据集<span class="math inline">\(D\)</span>的熵，计算公式为：</p>
<p><span class="math display">\[
Entropy(D) = - \sum_{i=1}^{k} p_i \log_2 p_i
\]</span></p>
<p>其中： <span class="math inline">\(p_i\)</span>是第<span class="math inline">\(i\)</span>类的样本在数据集<span class="math inline">\(D\)</span>中的比例， <span class="math inline">\(k\)</span>是类别的数量。</p>
<p>信息增益的目标是通过最大化 <strong>信息增益</strong>
来选择用于分裂的特征。</p>
<h3 id="基尼指数gini-impurity">1.3 基尼指数（Gini Impurity）</h3>
<p>基尼指数用于衡量一个节点的不纯度程度，数值越高表示样本的不纯度越高。其计算公式如下：</p>
<p><span class="math display">\[
G(p) = 1 - \sum_{i=1}^{k} p_i^2
\]</span></p>
<p>其中： <span class="math inline">\(p_i\)</span>是属于第<span class="math inline">\(i\)</span>类的样本所占的比例。 <span class="math inline">\(k\)</span>是类别的总数。</p>
<p>对于某个特征<span class="math inline">\(A\)</span>的基尼指数计算公式为：</p>
<p><span class="math display">\[
Gini(D, A) = \sum_{v=1}^{V} \frac{|D_v|}{|D|} G(D_v)
\]</span></p>
<p>其中： <span class="math inline">\(D\)</span>是数据集， <span class="math inline">\(D_v\)</span>是特征<span class="math inline">\(A\)</span>取值为<span class="math inline">\(v\)</span>的子数据集， <span class="math inline">\(V\)</span>是特征<span class="math inline">\(A\)</span>的取值个数， <span class="math inline">\(G(D_v)\)</span>是子集<span class="math inline">\(D_v\)</span>的基尼指数。</p>
<h2 id="核心思想">2. 核心思想</h2>
<p>随机森林通过<strong>多棵决策树的集成</strong>来提升模型的性能。<strong>每棵树</strong>是在<strong>随机子集</strong>上构建的，这里的随机性包括以下两点：</p>
<ol type="1">
<li><strong>数据采样</strong>：使用<strong>有放回的随机抽样</strong>（即
Bootstrap）从训练数据集中采样，生成多个不同的子数据集。每棵决策树在不同的数据子集上进行训练。</li>
<li><strong>特征选择</strong>：每个节点进行决策时，从所有特征中<strong>随机选择一部分特征</strong>，然后在这些特征中选择最佳的分裂点。这一随机性避免了所有决策树过于依赖某些特定的强特征。</li>
</ol>
<h2 id="算法步骤">3. 算法步骤</h2>
<ol type="1">
<li><strong>数据随机采样</strong>：从训练集中通过<strong>Bootstrap方法</strong>随机采样，生成若干个包含放回采样的数据子集。</li>
<li><strong>训练决策树</strong>：在每个数据子集上训练一棵决策树，每次节点分裂时，随机选择部分特征进行决策。</li>
<li><strong>集成决策树</strong>：将所有训练得到的决策树组成森林，作为最终的模型。</li>
<li><strong>投票或平均</strong>：对新样本输入森林时，所有树各自给出预测结果，分类问题通过<strong>投票法</strong>确定最终类别，回归问题通过<strong>平均法</strong>确定最终值。</li>
</ol>
<h2 id="损失函数">4. 损失函数</h2>
<p>随机森林的损失函数依赖于具体任务：</p>
<ul>
<li><p>*<strong>分类问题</strong>：随机森林通常最小化<strong>基尼不纯度</strong>或<strong>信息增益</strong>，即在构建决策树时，选择能够最大化类别纯度的特征进行划分：
<span class="math display">\[
G(p) = 1 - \sum_{i=1}^{k} p_i^2
\]</span> 其中，<span class="math inline">\(p_i\)</span>是当前节点中属于第<span class="math inline">\(i\)</span>类的样本比例，<span class="math inline">\(k\)</span>是类别数量。</p></li>
<li><p><strong>回归问题</strong>：随机森林最小化的是<strong>均方误差</strong>（MSE），用来衡量预测值与真实值的差距：
<span class="math display">\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span> 其中，<span class="math inline">\(y_i\)</span>是真实值，<span class="math inline">\(\hat{y}_i\)</span>是预测值，<span class="math inline">\(n\)</span>是样本数量。</p></li>
</ul>
<h2 id="优势">优势</h2>
<ol type="1">
<li><strong>高准确率</strong>：通过集成多棵决策树，随机森林显著提高了模型的准确性，特别是在分类和回归任务中。</li>
<li><strong>抗过拟合</strong>：决策树易过拟合，但随机森林通过对多个树的集成以及引入随机性，减少了过拟合的风险。</li>
<li><strong>处理高维数据</strong>：随机森林能够很好地处理高维数据，并且在特征选择中具有较好的表现。</li>
<li><strong>处理缺失值</strong>：它可以自动处理缺失数据，并能够通过投票或平均来进行处理。</li>
<li><strong>可并行化</strong>：由于每棵树是独立训练的，因此随机森林易于并行化，训练速度快。</li>
</ol>
<h2 id="缺点">缺点</h2>
<ol type="1">
<li><strong>模型复杂度高</strong>：随机森林由许多决策树组成，模型的复杂度较高，训练和预测的时间成本较大。</li>
<li><strong>解释性差</strong>：随机森林虽然性能优异，但由于其集成了大量决策树，整体模型较为复杂，难以解释各个特征的重要性和决策路径。</li>
<li><strong>计算开销大</strong>：训练大量的决策树需要较高的计算资源，尤其是在处理大规模数据时，训练时间较长，内存开销大。</li>
<li><strong>对高噪声数据敏感</strong>：随机森林对噪声数据的鲁棒性不足，可能导致过多无效的树，影响整体预测效果。</li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM</title>
    <url>/2024/09/12/SVM/</url>
    <content><![CDATA[<p>Support Vector Machine.</p>
<h2 id="线性svm分类原理">1. 线性SVM分类原理</h2>
<p>线性SVM分类的核心思想是找到一个超平面，将不同类别的数据点分隔开，并且尽量使得分类边界到支持向量的距离最大。线性SVM适用于数据线性可分的场景。</p>
<ul>
<li><p><strong>超平面</strong>：假设我们有一组二维数据，SVM的目标是找到一条直线来分割这组数据。在高维空间中，这条直线就是超平面，定义为：</p>
<p><span class="math display">\[
w \cdot x + b = 0
\]</span></p>
<p>其中，<span class="math inline">\(w\)</span> 是超平面的法向量，<span class="math inline">\(x\)</span> 是输入数据，<span class="math inline">\(b\)</span> 是偏置。</p></li>
<li><p><strong>分类边界</strong>：为了实现分类，SVM希望找到一个能最大化分类边界的超平面。理想情况下，不同类别的数据点位于超平面两侧，即：</p>
<ul>
<li><span class="math inline">\(w \cdot x_i + b \geq 1\)</span>
对于正类样本</li>
<li><span class="math inline">\(w \cdot x_i + b \leq -1\)</span>
对于负类样本</li>
</ul></li>
<li><p><strong>边距最大化</strong>：SVM通过优化问题来最大化支持向量到超平面的边距，保证模型的泛化能力。优化问题为：</p>
<p><span class="math display">\[
\min \frac{1}{2} \|w\|^2
\]</span></p>
<p>同时满足约束条件： <span class="math display">\[
y_i(w \cdot x_i + b) \geq 1 \quad \forall i
\]</span></p></li>
</ul>
<p>其中，<span class="math inline">\(y_i\)</span> 是数据点 <span class="math inline">\(x_i\)</span>
的类别标签（+1或-1），通过求解该优化问题得到的超平面能够最大化分类边界。</p>
<h2 id="带松弛变量的svm">2. 带松弛变量的SVM</h2>
<p>在实际问题中，数据通常是线性不可分的，可能会存在一些误分类的数据点。为了应对这种情况，SVM引入了松弛变量（slack
variable）来允许一定程度的误分类，从而处理非线性可分的数据。</p>
<ul>
<li><p><strong>松弛变量 <span class="math inline">\(\xi_i\)</span></strong>：SVM通过引入松弛变量 <span class="math inline">\(\xi_i \geq 0\)</span>
来度量误分类样本的程度。对于每个数据点，松弛变量允许分类边界与样本之间有一定误差。</p>
<p>约束条件变为： <span class="math display">\[
y_i(w \cdot x_i + b) \geq 1 - \xi_i \quad \forall i
\]</span></p>
<p>这样，SVM能够处理非线性可分的数据，同时通过优化问题最小化误分类。</p></li>
<li><p><strong>目标函数</strong>：SVM的目标是同时最小化分类误差和边距。带松弛变量的SVM的优化问题为：
<span class="math display">\[
\min \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \xi_i
\]</span></p>
<p>其中，<span class="math inline">\(C\)</span>
是惩罚参数，用来控制误分类样本的惩罚程度。较大的 <span class="math inline">\(C\)</span> 值会导致模型对误分类更敏感。</p></li>
</ul>
<h2 id="对偶问题">3. 对偶问题</h2>
<p>对偶问题是优化问题的一种变换形式，通过将原始的优化问题（主问题）转化为对偶形式，简化计算。SVM的对偶问题引入拉格朗日乘子，用于将原问题转化为约束优化问题。</p>
<p>拉格朗日函数 <span class="math inline">\(L(w, b, \alpha)\)</span>
定义为：</p>
<p><span class="math display">\[
L(w, b, \alpha) = \frac{1}{2} \|w\|^2 - \sum_{i=1}^{n} \alpha_i [y_i (w
\cdot x_i + b) - 1]
\]</span></p>
<p>其中，<span class="math inline">\(\alpha_i \geq 0\)</span>
是对应于每个约束条件的拉格朗日乘子。为了最小化拉格朗日函数 <span class="math inline">\(L(w, b, \alpha)\)</span>，我们需要对 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 进行最优化。首先分别对 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 求偏导并令其等于0。</p>
<p>对 <span class="math inline">\(w\)</span> 求导：</p>
<p><span class="math display">\[
\frac{\partial L(w, b, \alpha)}{\partial w} = w - \sum_{i=1}^{n}
\alpha_i y_i x_i = 0
\]</span></p>
<p>解得：</p>
<p><span class="math display">\[
w = \sum_{i=1}^{n} \alpha_i y_i x_i
\]</span></p>
<p>这表明 <span class="math inline">\(w\)</span> 是所有支持向量（即
<span class="math inline">\(\alpha_i &gt; 0\)</span>
的数据点）的线性组合。</p>
<p>对 <span class="math inline">\(b\)</span> 求导：</p>
<p><span class="math display">\[
\frac{\partial L(w, b, \alpha)}{\partial b} = - \sum_{i=1}^{n} \alpha_i
y_i = 0
\]</span></p>
<p>因此有：</p>
<p><span class="math display">\[
\sum_{i=1}^{n} \alpha_i y_i = 0
\]</span></p>
<p>这表明支持向量的权重满足该等式。</p>
<p>将 <span class="math inline">\(w = \sum_{i=1}^{n} \alpha_i y_i
x_i\)</span> 代入拉格朗日函数 <span class="math inline">\(L(w, b,
\alpha)\)</span>，消去 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span>，我们得到新的目标函数：</p>
<p><span class="math display">\[
L(\alpha) = \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j
y_i y_j (x_i \cdot x_j) - \sum_{i=1}^{n} \alpha_i
\]</span></p>
<p>注意，此时我们将优化变量从 <span class="math inline">\(w\)</span> 和
<span class="math inline">\(b\)</span> 转化为了 <span class="math inline">\(\alpha_i\)</span>。</p>
<p>对偶问题的目标是最大化拉格朗日函数 <span class="math inline">\(L(\alpha)\)</span>，即：</p>
<p><span class="math display">\[
\max_{\alpha} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (x_i \cdot x_j)
\]</span></p>
<p>同时满足以下约束条件：</p>
<p><span class="math display">\[
\sum_{i=1}^{n} \alpha_i y_i = 0, \quad 0 \leq \alpha_i \leq C
\]</span></p>
<p>其中 <span class="math inline">\(C\)</span>
是控制松弛变量的参数，在引入松弛变量时会用到。</p>
<p>通过求解对偶问题，我们可以获得拉格朗日乘子 <span class="math inline">\(\alpha_i\)</span>。这些乘子对应的 <span class="math inline">\(\alpha_i &gt; 0\)</span>
的样本就是<strong>支持向量</strong>，这些支持向量决定了最终的分类超平面。</p>
<h2 id="核化svm模型">4. 核化SVM模型</h2>
<p>核化SVM用于处理线性不可分的数据。通过核函数将数据从低维映射到高维空间，使得在高维空间中数据变得线性可分。</p>
<p>核函数 <span class="math inline">\(K(x_i, x_j)\)</span>
用来计算两个样本点在映射到高维空间后的内积。常见的核函数有：</p>
<ul>
<li>线性核（Linear Kernel
<ul>
<li>公式：<span class="math inline">\(K(x_i, x_j) = x_i \cdot
x_j\)</span></li>
<li>适用于线性可分的数据。</li>
</ul></li>
<li>多项式核（Polynomial Kernel
<ul>
<li>公式：<span class="math inline">\(K(x_i, x_j) = (x_i \cdot x_j +
1)^d\)</span></li>
<li>其中，<span class="math inline">\(d\)</span>
是多项式的阶数。多项式核适用于处理非线性数据。</li>
</ul></li>
<li>径向基函数核（Radial Basis Function, RBF Kernel）
<ul>
<li>公式：<span class="math inline">\(K(x_i, x_j) = \exp(-\gamma \|x_i -
x_j\|^2)\)</span></li>
<li><span class="math inline">\(\gamma\)</span>
是参数，控制高斯函数的宽度。RBF核用于处理局部模式的非线性数据，是SVM中常用的核函数。</li>
</ul></li>
<li>Sigmoid核（Sigmoid Kernel）
<ul>
<li>公式：<span class="math inline">\(K(x_i, x_j) = \tanh(\kappa x_i
\cdot x_j + \theta)\)</span></li>
<li>Sigmoid核类似于神经网络中的激活函数，适用于一些特殊的非线性数据。</li>
</ul></li>
</ul>
<h2 id="smo序列最小优化算法">5. SMO序列最小优化算法</h2>
<p>SMO（Sequential Minimal
Optimization）是解决SVM对偶问题的高效算法，能够快速训练SVM模型。SMO通过将优化问题分解为一系列的二次子问题，并分别对两个拉格朗日乘子进行优化。</p>
<p>基本步骤：</p>
<ol type="1">
<li><strong>选择两个拉格朗日乘子</strong>：每次选择两个乘子 <span class="math inline">\(\alpha_1\)</span> 和 <span class="math inline">\(\alpha_2\)</span> 进行优化。</li>
<li><strong>优化这两个乘子</strong>：将其他乘子固定，对 <span class="math inline">\(\alpha_1\)</span> 和 <span class="math inline">\(\alpha_2\)</span> 进行优化更新。</li>
<li><strong>更新模型参数</strong>：根据更新后的 <span class="math inline">\(\alpha_1\)</span> 和 <span class="math inline">\(\alpha_2\)</span> 计算新的超平面参数 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span>。</li>
<li><strong>重复迭代</strong>：不断重复以上步骤，直到达到收敛条件。</li>
</ol>
<p>SMO算法的优点在于它避免了计算整个核矩阵，显著提高了大规模数据集上SVM的训练速度。</p>
<h2 id="svr">6. SVR</h2>
<p>SVM回归（SVR）通过寻找一个函数来预测连续变量，主要用于回归分析。与SVM分类类似，SVR通过控制误差边界来最小化预测误差。</p>
<ul>
<li><strong>ε-不敏感损失函数</strong>：SVR允许在误差范围内的预测值被忽略，使用不敏感损失函数控制误差。</li>
<li><strong>目标函数</strong>：SVR的目标是最小化函数复杂度和预测误差，优化问题为：
<span class="math display">\[
\min \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n (\xi_i + \xi_i^*)
\]</span> 其中，<span class="math inline">\(\xi_i\)</span> 和 <span class="math inline">\(\xi_i^*\)</span>
是松弛变量，表示上下边界的误差，<span class="math inline">\(ε\)</span>
控制误差的范围。</li>
</ul>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Sustainable biofabrication: from bioprinting to AI-driven predictive methods</title>
    <url>/2024/09/12/Sustainable-biofabrication-from-bioprinting-to-AI-driven-predictive-methods/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>XGBoost</title>
    <url>/2024/09/12/XGBoost/</url>
    <content><![CDATA[<p>Extreme Gradient Boosting，对GBDT的优化实现。</p>
<h2 id="核心思想">1. 核心思想</h2>
<p>XGBoost 继承了 GBDT
的基本思想，即通过构建多个决策树来逐步优化模型的预测能力。XGBoost
的优化改进：</p>
<ul>
<li><strong>损失函数的优化</strong>：XGBoost
使用二阶导数（Hessian）信息来优化损失函数，提升模型在拟合时的鲁棒性和精确度。</li>
<li><strong>目标函数的优化</strong>：XGBoost
不仅考虑了损失函数，还在目标函数中加入了正则化项，用来控制模型的复杂度，防止过拟合。</li>
</ul>
<h3 id="level-wise">1.1 level-wise</h3>
<h2 id="算法步骤">2. 算法步骤</h2>
<p>XGBoost 的算法流程与 GBDT 类似，包含以下步骤：</p>
<ol type="1">
<li><p><strong>初始化模型</strong>：开始时，模型初始化为常数值。通常使用目标变量的均值来初始化模型。</p></li>
<li><p><strong>逐步添加树</strong>：</p>
<ul>
<li>每一轮迭代时，基于上一轮的残差，训练一个新的回归树。</li>
<li>XGBoost
使用损失函数的<strong>一阶导数</strong>（梯度）和<strong>二阶导数</strong>（Hessian）来生成新树。</li>
</ul></li>
<li><p><strong>目标函数优化</strong>：</p>
<ul>
<li>对每棵树，XGBoost
构建时通过最小化目标函数来决定分裂节点的最佳方式。</li>
<li>目标函数考虑了模型的误差和正则化项。1</li>
</ul></li>
<li><p><strong>加法模型</strong>：</p>
<ul>
<li>新的决策树模型与之前的树累加，形成最终的模型。</li>
</ul></li>
<li><p><strong>更新预测值</strong>：</p>
<ul>
<li>根据当前的决策树，更新模型的预测值，并继续进行下一轮迭代，直到达到指定的树数或误差停止下降。</li>
</ul></li>
</ol>
<h2 id="目标函数">3. 目标函数</h2>
<p>XGBoost 的目标函数包括两个部分：损失函数和正则化项。</p>
<p><span class="math display">\[
\text{Obj}(\theta) = \sum_{i=1}^{n} L(y_i, \hat{y}_i) + \sum_{k=1}^{K}
\Omega(f_k)
\]</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline">\(L(y_i, \hat{y}_i)\)</span>
是模型的损失函数，用于衡量模型预测值 <span class="math inline">\(\hat{y}_i\)</span> 和真实值 <span class="math inline">\(y_i\)</span> 之间的差异。
<ul>
<li>对于<strong>分类问题</strong>，常用的损失函数是<strong>对数损失</strong>：
<span class="math display">\[
L(y_i, \hat{y}_i) = - \sum_{i} y_i \log(\hat{y}_i)
\]</span></li>
<li>对于<strong>回归问题</strong>，通常使用的损失函数是<strong>均方误差</strong>（MSE）：
<span class="math display">\[
L(y_i, \hat{y}_i) = \frac{1}{2}(y_i - \hat{y}_i)^2
\]</span></li>
</ul></li>
<li><span class="math inline">\(\Omega(f_k)\)</span>
是正则化项，用于控制模型的复杂度，防止过拟合。具体公式为： <span class="math display">\[
\Omega(f_k) = \gamma T + \frac{1}{2} \lambda \sum_j w_j^2
\]</span> 其中：
<ul>
<li><span class="math inline">\(T\)</span> 是树的叶子节点数。</li>
<li><span class="math inline">\(w_j\)</span>
是叶子节点的权重，表示每个叶子节点的输出值，<span class="math inline">\(w_j\)</span> 通过最小化目标函数导出的公式计算：
<span class="math display">\[
w_j = -\frac{\sum_{i \in \text{leaf } j} g_i}{\sum_{i \in \text{leaf }
j} h_i + \lambda}
\]</span> 其中 <span class="math inline">\(g_i\)</span> 和 <span class="math inline">\(h_i\)</span> 分别是一阶导数和二阶导数。</li>
<li><span class="math inline">\(\lambda\)</span>
是用于控制权重大小的正则化参数。</li>
<li><span class="math inline">\(\gamma\)</span>
控制树的叶子节点数量。</li>
</ul></li>
</ul>
<p>XGBoost
使用二阶泰勒展开对损失函数进行近似来优化树结构，具体公式为：</p>
<p><span class="math display">\[
\text{Obj}(\theta) \approx \sum_{i=1}^{n} \left[ g_i \cdot f(x_i) +
\frac{1}{2} h_i \cdot f(x_i)^2 \right] + \Omega(f)
\]</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline">\(g_i\)</span>
是损失函数的<strong>一阶导数</strong>（梯度），用于表示预测值与真实值的误差方向。</li>
<li><span class="math inline">\(h_i\)</span>
是损失函数的<strong>二阶导数</strong>（Hessian），用于描述误差变化的程度。</li>
</ul>
<p>最终目标函数计算如下：</p>
<p><span class="math display">\[
\text{Obj}(\theta) = -\frac{1}{2} \sum_{j=1}^{T} \frac{\left( \sum_{i
\in \text{leaf } j} g_i \right)^2}{\sum_{i \in \text{leaf } j} h_i +
\lambda} + \gamma T
\]</span></p>
<h2 id="优势">4. 优势</h2>
<p>XGBoost 相较于传统的 GBDT，在多个方面进行了优化，具有以下优势：</p>
<ol type="1">
<li><strong>速度快</strong>：
<ul>
<li>XGBoost 在树构建过程中使用了<strong>按列块分裂</strong>（Column
Block Splitting），通过并行计算提升了训练速度。</li>
<li>通过缓存加速（Out<em>of</em>core
Computation）支持处理超大规模数据集。</li>
</ul></li>
<li><strong>精度高</strong>：
<ul>
<li>使用了<strong>二阶导数</strong>来优化树的构建，使模型能够更精确地拟合训练数据。</li>
<li>正则化项有效防止过拟合，保证模型泛化能力。</li>
</ul></li>
<li><strong>支持多种损失函数</strong>：
<ul>
<li>除了支持常见的回归和分类损失函数，XGBoost
还允许用户自定义损失函数，具有高度的灵活性。</li>
</ul></li>
<li><strong>处理缺失值</strong>：
<ul>
<li>XGBoost
具备自动处理缺失值的功能，在构建决策树时，它会学习到缺失值的默认路径，而不需要额外的数据预处理。</li>
</ul></li>
<li><strong>树的剪枝</strong>：
<ul>
<li>XGBoost
使用<strong>最大增益剪枝</strong>算法（Shrinkage），通过限制树的深度以及叶子节点数，进一步防止过拟合。</li>
</ul></li>
<li><strong>支持早停机制</strong>：
<ul>
<li>XGBoost 可以通过早停机制（Early
Stopping）在训练过程中动态判断是否需要停止训练，防止过拟合和无效的计算。</li>
</ul></li>
</ol>
<h2 id="缺点">5. 缺点</h2>
<p>尽管 XGBoost 优势众多，但它也存在一些缺点：</p>
<ol type="1">
<li><strong>对超参数敏感</strong>：
<ul>
<li>XGBoost
拥有众多超参数，如学习率、最大深度、最小分裂样本数等，模型性能高度依赖于这些超参数的调优。</li>
<li>超参数调优复杂且耗时，通常需要使用网格搜索或随机搜索来寻找最佳参数组合。</li>
</ul></li>
<li><strong>难以解释</strong>：
<ul>
<li>由于 XGBoost
使用了多个决策树的集成结果，虽然有一定的解释性，但相比于线性模型或单棵树，模型的可解释性较低。</li>
</ul></li>
<li><strong>计算资源要求高</strong>：
<ul>
<li>尽管 XGBoost
在速度上做了很多优化，但在大规模数据集上，它的训练仍然需要大量的计算资源，尤其是在进行参数调优时。</li>
</ul></li>
<li><strong>易受噪声影响</strong>：
<ul>
<li>如果数据中存在较多的噪声，XGBoost
可能会过度拟合噪声，导致模型泛化能力下降。</li>
</ul></li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Adaboost</title>
    <url>/2024/09/13/Adaboost/</url>
    <content><![CDATA[<p>Adaptive Boosting，自适应增强。</p>
<h2 id="核心思想">1. 核心思想</h2>
<p>通过逐轮训练弱分类器，每一轮根据分类器的表现调整样本权重，最终将这些弱分类器进行加权组合，形成一个强分类器。弱分类器可以是任何表现略优于随机猜测的模型。</p>
<h2 id="算法步骤">2. 算法步骤</h2>
<ol type="1">
<li><p><strong>初始化训练样本的权值分布</strong>：最开始对每个训练样本赋予相同的权重：
<span class="math display">\[w_i^{(1)} = \frac{1}{N}, \quad
i=1,2,\dots,N\]</span> 其中，<span class="math inline">\(N\)</span>为训练样本的总数，<span class="math inline">\(w_i^{(1)}\)</span>为第 <span class="math inline">\(i\)</span>个样本在初始阶段的权重。</p></li>
<li><p><strong>训练弱分类器</strong>：在每一轮迭代中，用当前的权值分布训练一个弱分类器
<span class="math inline">\(h_t\)</span>。对于训练样本集 <span class="math inline">\(X = \{x_1, x_2, \dots, x_N\}\)</span>，若弱分类器
<span class="math inline">\(h_t\)</span>对样本 <span class="math inline">\(x_i\)</span>分类错误，权重 <span class="math inline">\(w_i\)</span>就会增加；若分类正确，则 <span class="math inline">\(w_i\)</span>减少。</p></li>
<li><p><strong>计算弱分类器的误差率</strong>：分类器 <span class="math inline">\(h_t\)</span>的分类误差率 <span class="math inline">\(\epsilon_t\)</span>为： <span class="math display">\[
\epsilon_t = \frac{\sum_{i=1}^{N} w_i^{(t)} \cdot \mathbb{I}(h_t(x_i)
\neq y_i)}{\sum_{i=1}^{N} w_i^{(t)}}
\]</span> 其中，<span class="math inline">\(\mathbb{I}(\cdot)\)</span>是指示函数，当 <span class="math inline">\(h_t(x_i) \neq y_i\)</span>时取值为 1，否则为
0。<span class="math inline">\(y_i\)</span>为样本 <span class="math inline">\(x_i\)</span>的真实标签。</p></li>
<li><p><strong>计算弱分类器的权重</strong>：根据分类误差率 <span class="math inline">\(\epsilon_t\)</span>，计算该弱分类器的权重 <span class="math inline">\(\alpha_t\)</span>，权重越高，表示该分类器的效果越好：
<span class="math display">\[
\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t}
\right)
\]</span> 其中，<span class="math inline">\(\alpha_t\)</span>反映了该分类器在最终组合分类器中的重要性。</p></li>
<li><p><strong>更新样本权重</strong>：为了让下一个弱分类器更多关注分类错误的样本，更新样本权重。更新公式为：
<span class="math display">\[
w_i^{(t+1)} = w_i^{(t)} \cdot \exp\left( \alpha_t \cdot
\mathbb{I}(h_t(x_i) \neq y_i) \right)
\]</span> 经过归一化处理后，使得所有权重之和仍然为 1： <span class="math display">\[
w_i^{(t+1)} = \frac{w_i^{(t+1)}}{\sum_{i=1}^{N} w_i^{(t+1)}}
\]</span></p></li>
<li><p><strong>构建最终分类器</strong>：在所有弱分类器训练完成后，将每个弱分类器按其权重
<span class="math inline">\(\alpha_t\)</span>进行加权投票，得到最终的强分类器：
<span class="math display">\[
H(x) = \text{sign}\left( \sum_{t=1}^{T} \alpha_t h_t(x) \right)
\]</span> 其中，<span class="math inline">\(T\)</span>是弱分类器的总数，<span class="math inline">\(\text{sign}(\cdot)\)</span>是符号函数，用于确定最终分类的正负。</p></li>
</ol>
<h2 id="损失函数">3. 损失函数</h2>
<h3 id="指数损失函数">3.1 指数损失函数</h3>
<p>在 <strong>Adaboost</strong> 中，分类问题常使用
<strong>指数损失函数</strong> 来计算损失：</p>
<p><span class="math display">\[
L(x_i) = \exp(-y_i f(x_i))
\]</span></p>
<p>其中： <span class="math inline">\(x_i\)</span>是样本数据， <span class="math inline">\(y_i\)</span>是样本的真实标签（+1 或 -1）， <span class="math inline">\(f(x_i)\)</span>是通过弱分类器的加权组合形成的决策函数。</p>
<p>当 <span class="math inline">\(y_i \cdot
f(x_i)\)</span>较大时，表示分类正确，损失较小；而当 <span class="math inline">\(y_i \cdot
f(x_i)\)</span>较小时，表示分类错误，损失会快速增加。</p>
<h3 id="均方误差">3.2 均方误差</h3>
<p>在 <strong>回归问题</strong> 中，常用的损失函数是
<strong>均方误差（MSE, Mean Squared Error）</strong>，其公式为：</p>
<p><span class="math display">\[
L = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2
\]</span></p>
<p>其中： <span class="math inline">\(y_i\)</span>是真实值， <span class="math inline">\(\hat{y_i}\)</span>是预测值。</p>
<h2 id="优势">4. 优势</h2>
<ol type="1">
<li><strong>自适应性</strong>：Adaboost
通过动态调整样本权重，使得后续分类器重点关注难以分类的样本。</li>
<li><strong>理论保障</strong>：Adaboost
有较强的理论支持，尤其是在误分类率低的情况下，能够显著提升分类性能。</li>
<li><strong>不易过拟合</strong>：尽管 Adaboost
会不断加强对误分类样本的关注，但在弱分类器性能有限的情况下，它不容易产生过拟合问题。</li>
</ol>
<h2 id="缺点">5. 缺点</h2>
<ol type="1">
<li><strong>对噪声敏感</strong>：Adaboost
在处理含有噪声的数据时可能表现不佳，因为它会过度关注那些难以分类的样本，可能导致模型偏向噪声数据。</li>
<li><strong>分类器局限</strong>：Adaboost 要求弱分类器的错误率要小于
0.5，如果弱分类器过于弱或误差率高，整个模型的效果可能较差。</li>
</ol>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Bayesian Optimization</title>
    <url>/2024/09/13/Bayesian-Optimization/</url>
    <content><![CDATA[<p>超参数优化算法。通过构建一个代理模型（通常是高斯过程，GP）来近似目标函数，并使用该模型的预测和不确定性信息来决定下一次评估目标函数的最优位置。实际上是<strong>优化对目标函数的估计</strong>，属于序贯模型优化(SMBO)的一种。</p>
<p>SMBO：一类用于优化复杂、黑箱函数的策略，它通过构建代理模型来模拟目标函数，并通过不断更新模型来引导下一步的采样。</p>
<h2 id="基本原理">1. 基本原理</h2>
<p>基本步骤：</p>
<ul>
<li>初始样本选择：首先通过随机或空间填充方法选择一些样本点，评估这些点的目标函数值f(x)。</li>
<li>代理模型构建：基于已有的样本点，利用高斯过程构建目标函数的代理模型。高斯过程不仅可以预测目标函数的值，还能提供该预测的置信区间。</li>
<li>采集函数选择：贝叶斯优化使用采集函数来决定下一个需要评估的点。采集函数平衡了探索（在高不确定性区域探索可能的最优点）和利用（在已知较优区域集中评估）。</li>
<li>目标函数评估：根据采集函数选择的下一个点，评估目标函数，并将结果纳入已有样本集。</li>
<li>模型更新：更新高斯过程模型，以包括新的采样点。</li>
<li>重复迭代：不断重复步骤3-5，直到满足停止条件（例如达到设定的评估次数或优化精度）。</li>
</ul>
<p>注意：在超参数优化过程中，需要定义的f(x)一半是交叉验证/损失函数的结果，我们清楚损失函数的表达式，但是不了解损失函数的内在规律（如单调性，最小值等），因此在超参数优化中的f(x)不能算是严格意义上的黑盒函数。</p>
<p><a href="https://blog.csdn.net/weixin_40056577/article/details/114222379?sharetype=blogdetail&amp;sharerId=114222379&amp;sharerefer=PC&amp;sharesource=weixin_46782903&amp;sharefrom=from_link">采集函数</a>：（第3步）基于最小值出现频率确定下一个观测点。</p>
<ul>
<li>概率增量PI，Probability of
improvement，希望下一个点的函数值比经验中最大的函数值多一个微小增量<span class="math inline">\(\epsilon\)</span>的<strong>概率最大</strong>。过于关注探索</li>
<li>期望增量EI，Expectation
improvement，希望下一个点的函数值离全局最优值的距离最近。</li>
<li>置信度上界，Upper Confidence
Bound，通过平衡利用（即选择预测均值高的点）和探索（即选择预测不确定性大的点）来引导优化过程。通过选择置信区间的上界最大的点，既能够确保在当前已有信息下的最优解（即利用已有数据），又能够鼓励对不确定区域的探索（因为标准差较大的点具有更大的潜在提升空间）。</li>
<li>信息熵，Entropy，希望熵在全局最优点上下降的最多，减少不确定性。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/BO1.png" alt="图1"> <a href="https://www.bilibili.com/video/BV1fY411t7hm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d">查看图片来源</a></p>
<h2 id="参考资料">2. 参考资料</h2>
<p><a href="https://blog.51cto.com/u_16099249/8326101" class="uri">https://blog.51cto.com/u_16099249/8326101</a></p>
<p><a href="https://blog.csdn.net/weixin_40056577/article/details/114222379?sharetype=blogdetail&amp;sharerId=114222379&amp;sharerefer=PC&amp;sharesource=weixin_46782903&amp;sharefrom=from_link" class="uri">https://blog.csdn.net/weixin_40056577/article/details/114222379?sharetype=blogdetail&amp;sharerId=114222379&amp;sharerefer=PC&amp;sharesource=weixin_46782903&amp;sharefrom=from_link</a></p>
<p><a href="https://www.bilibili.com/video/BV1fY411t7hm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d" class="uri">https://www.bilibili.com/video/BV1fY411t7hm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>catboost</title>
    <url>/2024/09/14/catboost/</url>
    <content><![CDATA[<p>Category Boosting, 对GBDT的优化实现。</p>
<h2 id="核心思想">1. 核心思想</h2>
<p>CatBoost的核心思想是在GBDT的基础上进行改进，主要通过以下几方面的优化：</p>
<ol type="1">
<li><strong>类别特征的高效处理</strong>：CatBoost可以直接处理类别特征，不需要进行独热编码（One-Hot
Encoding），通过统计信息和基于目标值的编码技术减少了过拟合和信息泄漏的风险。使用<strong>Ordered
Target Encoding</strong>。具体来说，假设我们正在处理一个样本 <span class="math inline">\(i\)</span>，并希望对其类别特征 <span class="math inline">\(A\)</span> 进行目标编码。CatBoost
计算的编码是基于样本 <span class="math inline">\(i\)</span>
之前的样本的目标变量：</li>
</ol>
<p><span class="math display">\[
\text{Encoded}(A_i) = \frac{\sum_{j=1}^{i-1} y_j | A_j =
A_i}{\text{count}(A_j = A_i, j &lt; i)}
\]</span></p>
<ol start="2" type="1">
<li><p><strong>避免梯度偏差</strong>：在传统GBDT中，梯度计算可能带有偏差，而CatBoost通过引入基于排序的梯度提升方法来减少这种偏差，提升模型的泛化能力。</p></li>
<li><p><strong>对称树结构</strong>：CatBoost构建对称的决策树，这意味着每个树的左右分支在相同的深度上分裂相同的特征。这种结构可以提升预测速度，并使得模型对数据顺序不敏感。</p></li>
<li><p><strong>顺序提升算法</strong>：CatBoost在训练时使用顺序提升方法，通过逐步引入数据点来减少目标编码和梯度提升中的信息泄漏。</p></li>
</ol>
<h2 id="算法步骤">2. 算法步骤</h2>
<p>CatBoost的算法步骤与传统的GBDT相似，但增加了对类别特征和数据顺序的特殊处理：</p>
<ol type="1">
<li><p><strong>初始化模型</strong>：选择初始预测值（通常是常数，如目标的均值）。</p></li>
<li><p><strong>类别特征编码</strong>：对类别特征进行统计编码，使用平均目标值或基于排序的编码方法处理类别特征，确保没有信息泄漏。</p></li>
<li><p><strong>构建对称树</strong>：基于顺序提升法和对称树结构构建决策树。在每次构建树时，CatBoost选择具有最大分裂增益的特征进行分裂。</p></li>
<li><p><strong>计算梯度和更新模型</strong>：根据当前模型的预测误差，计算梯度并更新模型参数，构建新的树。</p></li>
<li><p><strong>重复迭代</strong>：重复上述步骤，直到达到预设的树数或误差收敛。</p></li>
</ol>
<h2 id="损失函数">3. 损失函数</h2>
<p>CatBoost与GBDT类似，使用的损失函数取决于任务类型：</p>
<ul>
<li><strong>回归任务</strong>：常用均方误差（MSE）或绝对误差（MAE）作为损失函数。</li>
</ul>
<p><span class="math display">\[
  L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span></p>
<ul>
<li><strong>分类任务</strong>：常用交叉熵损失函数（Logloss）来衡量模型预测的概率分布与真实标签之间的差异。</li>
</ul>
<p><span class="math display">\[
  L(y, \hat{y}) = -\sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1 - y_i)
\log(1 - \hat{y}_i)]
\]</span></p>
<p>CatBoost的损失函数可以通过参数调整适用于不同的任务，如二分类、多分类、回归等。</p>
<h2 id="优势">4. 优势</h2>
<p>CatBoost相较于其他GBDT实现有以下优势：</p>
<ol type="1">
<li><p><strong>直接处理类别特征</strong>：无需进行独热编码，减少了内存占用和计算复杂度，同时通过顺序编码技术避免了信息泄漏。</p></li>
<li><p><strong>减少梯度偏差</strong>：使用基于排序的梯度提升方法，减少了梯度估计中的偏差，提高了模型的泛化能力。</p></li>
<li><p><strong>高效训练与预测</strong>：由于采用了对称树结构，CatBoost在训练和预测过程中都具有较高的速度，尤其在预测阶段，能够显著降低推理时间。</p></li>
<li><p><strong>对数据顺序不敏感</strong>：CatBoost采用顺序提升法，减少了训练数据的顺序对模型性能的影响，适合处理时序数据或随机排序的数据。</p></li>
<li><p><strong>支持GPU加速</strong>：CatBoost原生支持GPU加速，能够显著加快大规模数据集的训练速度。</p></li>
</ol>
<h2 id="缺点">5. 缺点</h2>
<ul>
<li>对于类别特征的处理需要大量的内存和时间。</li>
<li>不同随机数的设定对于模型预测结果有一定的影响。</li>
</ul>
<p>参考资料：</p>
<p><a href="https://cloud.tencent.com/developer/article/1546808" class="uri">https://cloud.tencent.com/developer/article/1546808</a></p>
<p><a href="https://www.youtube.com/watch?v=3Bg2XRFOTzg" class="uri">https://www.youtube.com/watch?v=3Bg2XRFOTzg</a></p>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>lightGBM</title>
    <url>/2024/09/14/lightGBM/</url>
    <content><![CDATA[<p>Light Gradient Boosting Machine。lightGBM 和
XGBoost一样，是对GBDT的优化实现，但比XGBoost更为优秀高效。GBDT
在每一次迭代的时候，都需要遍历整个训练数据多次。如果把整个训练数据一次性装进内存，会明显限制训练数据的大小。如果不装进内存，反复地读写训练数据又会消耗非常大的时间。XGboost中使用的精确贪心算法也同样存在这个问题。</p>
<p>参考资料（更加详细，有助于理解）：</p>
<p><a href="https://github.com/ExpressGit/NLP_Study_Demo/blob/main/ML/LightGBM.ipynb" class="uri">https://github.com/ExpressGit/NLP_Study_Demo/blob/main/ML/LightGBM.ipynb</a></p>
<p><a href="https://www.bilibili.com/video/BV1JK4y1L7ow/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d" class="uri">https://www.bilibili.com/video/BV1JK4y1L7ow/?spm_id_from=333.337.search-card.all.click&amp;vd_source=514a3ed3ac370caf4facad7d6f4e1a2d</a></p>
<h2 id="核心思想">1. 核心思想</h2>
<p>LightGBM是一种高效的梯度提升决策树（GBDT）实现，具有独特的优化策略以应对大规模数据和高维特征的挑战。其核心思想是通过引入基于直方图的决策树算法、梯度采样、特征捆绑等技术，优化模型的训练速度和内存使用，同时保持模型的准确性。</p>
<h3 id="基于histogram的决策树算法">1.1 基于Histogram的决策树算法</h3>
<p>LightGBM采用基于直方图的决策树算法，通过将连续特征值分桶（即构建直方图），极大地减少了寻找最佳分裂点时的计算量。同时，直方图算法的内存效率也显著提升，因为特征值只需要记录对应的分桶信息，而不必存储完整的特征值。</p>
<p>注意：</p>
<ul>
<li>使用分桶 bin 替代原始数据相当于增加了正则化。</li>
<li>使用分桶 bin
意味着很多数据的细节特征丢失，相似的数据如果划分到相同的桶中，数据之间的差异就无法捕获了。</li>
<li>分桶 bin 数量决定了正则化的程度，bin
越少惩罚越严重，欠拟合风险越高。</li>
<li>因为预先设定了 bin 的范围，构建直方图时不需要对数据进行排序。</li>
<li>直方图保存「划分阈值」、「当前 bin 内样本数」、「当前 bin
内所有样本的一阶梯度和」。</li>
<li>阈值的选取是按照直方图从小到大遍历，使用了上面的一阶梯度和，目的是得到划分之后
损失函数 最大的特征及阈值。</li>
</ul>
<h3 id="单边梯度采样goss-gradient-based-one-side-sampling-goss">1.2
单边梯度采样GOSS, Gradient-based One-Side Sampling (GOSS)</h3>
<p>GOSS是一种采样策略，旨在通过保留梯度较大的样本（即模型难以拟合的样本）来提高梯度提升的效率。GOSS会对梯度较小的样本进行下采样，减少计算量，同时保证对整体数据分布的准确把握，从而加快模型的训练速度。</p>
<figure>
<img src="https://raw.githubusercontent.com/lwl1751/Image_Hosting/main/img/lightGBM1.jpeg" alt="图1">
<figcaption aria-hidden="true">图1</figcaption>
</figure>
<h3 id="互斥特征捆绑-exclusive-feature-bundling">1.3 互斥特征捆绑
Exclusive Feature Bundling</h3>
<p>Exclusive Feature Bundling (EFB)
是一种特征压缩技术，用于减少特征的维度。LightGBM会将一些<strong>互斥的稀疏特征</strong>（即在同一个样本中不同时为非零的特征）捆绑成一个特征，极大地减少了特征维度的数量，而不会影响模型的精度。</p>
<p>算法步骤：</p>
<ul>
<li>将特征按照非零值的个数进行排序。</li>
<li>计算不同特征之间的冲突比率。</li>
<li>遍历每个特征并尝试合并特征，使冲突比率最小。</li>
</ul>
<h3 id="带深度限制的leaf-wise的叶子生长策略">1.4
带深度限制的Leaf-wise的叶子生长策略</h3>
<p>LightGBM采用叶子生长策略（Leaf-wise
Growth），即在构建决策树时优先分裂增益最大的叶子节点，而不是逐层分裂。这种策略相比传统的逐层分裂方法（level-wise），能够更快地找到更优的分裂点，但也更容易出现过拟合。为此，LightGBM引入了深度限制，防止树结构过深。</p>
<h3 id="直接支持类别特征">1.5 直接支持类别特征</h3>
<p>LightGBM直接支持类别特征，不需要对其进行独热编码（one-hot
encoding）。通过对类别特征的分裂优化，LightGBM能够在高效处理类别特征的同时减少内存和计算的开销。</p>
<p>算法步骤：</p>
<ul>
<li>在枚举分割点之前，先把直方图按每个类别的均值进行排序。</li>
<li>接着按照均值的结果依次枚举最优分割点。</li>
</ul>
<h3 id="支持高效并行">1.6 支持高效并行</h3>
<p>LightGBM支持特征并行和数据并行两种高效的并行计算方式。在特征并行中，多个特征的分裂点搜索可以并行进行；在数据并行中，使用分散规约把直方图合并的任务分摊到不同的机器上。</p>
<h3 id="cache命中率优化">1.7 Cache命中率优化</h3>
<p>LightGBM 所使用直方图算法对 Cache 天生友好：</p>
<p>首先，所有的特征都采用相同的方式获得梯度（区别于XGBoost的不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中率；
其次，因为不需要存储行索引到叶子索引的数组，降低了存储消耗，而且也不存在
Cache Miss的问题。</p>
<h2 id="算法步骤">2. 算法步骤</h2>
<p>LightGBM的基本算法流程如下：</p>
<ol type="1">
<li><p><strong>初始化</strong>：初始化模型参数，将所有样本的预测值设定为常数值（如均值）。</p></li>
<li><p><strong>构建决策树</strong>：根据残差更新样本的梯度信息，采用基于直方图的分裂方法，找到最佳分裂点。</p></li>
<li><p><strong>更新预测值</strong>：根据新构建的树，更新所有样本的预测值。</p></li>
<li><p><strong>迭代重复</strong>：根据更新后的预测值继续构建新树，重复该过程直到达到设定的迭代次数或满足早停条件。</p></li>
</ol>
<h2 id="目标函数">3. 目标函数</h2>
<p>LightGBM 的目标函数由损失函数和正则化项组成：</p>
<ul>
<li><p><strong>损失函数</strong>：通常是平方误差（用于回归问题）或交叉熵损失（用于分类问题），用于衡量模型预测值与真实值的差异。</p>
<p><span class="math display">\[
L(\theta) = \sum_i \ell(y_i, f(x_i))
\]</span></p></li>
<li><p><strong>正则化项</strong>：为了防止模型过拟合，LightGBM引入了树结构复杂度和叶子节点权重的正则化项：</p>
<p><span class="math display">\[
\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_j w_j^2
\]</span></p></li>
</ul>
<p>各参数含义与XGboost中的相同。</p>
<h2 id="优点">4. 优点</h2>
<p>速度快，占用内存少。</p>
<h2 id="缺点">5. 缺点</h2>
<p>LightGBM是基于偏差的算法，所以会对噪点较为敏感。在寻找最优解时，依据的是最优切分变量，没有将最优解是全部特征的综合这一理念考虑进去；</p>
]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title>Graph Intelligence with Large Language Models and Prompt Learning</title>
    <url>/2024/09/27/Graph-Intelligence-with-Large-Language-Models-and-Prompt-Learning/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs</title>
    <url>/2024/09/27/GraphCare-Enhancing-Healthcare-Predictions-with-Personalized-Knowledge-Graphs/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Learning Dynamic User Interest Sequence in Knowledge Graphs for Click-Through Rate Prediction</title>
    <url>/2024/09/27/Learning-Dynamic-User-Interest-Sequence-in-Knowledge-Graphs-for-Click-Through-Rate-Prediction/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Leveraging A Medical Knowledge Graph into Large Language Modelsfor Diagnosis Prediction</title>
    <url>/2024/09/27/Leveraging-A-Medical-Knowledge-Graph-into-Large-Language-Modelsfor-Diagnosis-Prediction/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Link Prediction Based on Graph Neural Networks</title>
    <url>/2024/09/27/Link-Prediction-Based-on-Graph-Neural-Networks/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions</title>
    <url>/2024/09/27/LLM-Prop-Predicting-Physical-And-Electronic-Properties-Of-Crystalline-Solids-From-Their-Text-Descriptions/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models</title>
    <url>/2024/09/27/Multi-perspective-Improvement-of-Knowledge-Graph-Completion-with-Large-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Multimodal Foundation Models: From Specialists to General-Purpose Assistants</title>
    <url>/2024/09/27/Multimodal-Foundation-Models-From-Specialists-to-General-Purpose-Assistants/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records</title>
    <url>/2024/09/27/RAM-EHR-Retrieval-Augmentation-Meets-Clinical-Predictions-on-Electronic-Health-Records/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>Towards Explainable Traffic Flow Prediction with Large Language Models</title>
    <url>/2024/09/27/Towards-Explainable-Traffic-Flow-Prediction-with-Large-Language-Models/</url>
    <content><![CDATA[
]]></content>
  </entry>
</search>
